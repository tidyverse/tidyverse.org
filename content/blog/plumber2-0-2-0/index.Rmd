---
output: hugodown::hugo_document

slug: plumber2-0-2-0
title: plumber2 0.2.0
date: 2026-01-05
author: Thomas Lin Pedersen
description: >
    The next version of plumber2 has hit CRAN. Read all about the new features 
    such as OTEL support, authentication, new tags, and performance 
    improvements here.

photo:
  url: https://unsplash.com/photos/black-and-gray-metal-pipe-4CNNH2KEjhc
  author: Sigmund

# one of: "deep-dive", "learn", "package", "programming", "roundup", or "other"
categories: [package] 
tags: [plumber2, web]
---

```{=html}
<!--
TODO:
* [x] Look over / edit the post's title in the yaml
* [x] Edit (or delete) the description; note this appears in the Twitter card
* [x] Pick category and tags (see existing with `hugodown::tidy_show_meta()`)
* [x] Find photo & update yaml metadata
* [x] Create `thumbnail-sq.jpg`; height and width should be equal
* [x] Create `thumbnail-wd.jpg`; width should be >5x height
* [x] `hugodown::use_tidy_thumbnails()`
* [ ] Add intro sentence, e.g. the standard tagline for the package
* [ ] `usethis::use_tidy_thanks()`
-->
```

We're stoked to announce the release of [plumber2](https://plumber2.posit.co) 0.2.0. plumber2 is a package for creating webservers in R based on either an annotation-based or programmatic workflow. It is the successor to the plumber package who has empowered the R community for 10 years and allowed them to share their R based functionalities with their organizations and the world.

You can install it from CRAN with:

```{r, eval = FALSE}
pak::pak("plumber2")
```

This release covers both a bunch of new features as well as some tangible improvements to performance. The headlining features are OTEL support and support for authentication which we will dive into below. In the end we will also provide a grab-bag of miscellaneous improvements for your enjoyment.

You can see a full list of changes in the [release notes](/news/index.html)

```{r setup}
library(plumber2)
```

## OTEL support

We have been hard at work at adding support for [OpenTelemetry (OTEL)](https://opentelemetry.io/) for our tools to allow easy instrumentation across our offerings, see e.g. the [shiny blog post](https://shiny.posit.co/blog/posts/shiny-r-1.12/) announcing support for it there. If you do not know what OTEL is, here is a short introduction to the subject:

OTEL describes itself as “high-quality, ubiquitous, and portable telemetry to enable effective observability”. In simpler terms, OpenTelemetry is a set of tools, APIs, and SDKs that help you collect and export telemetry data (like traces, logs, and metrics) from your applications. This data provides insights into how your applications are performing and behaving in real-world scenarios.

It captures three key types of data:

1.  **Traces:** These show the path of a request through your application.
2.  **Logs:** These are detailed event records that capture what happened at specific moments.
3.  **Metrics:** These are numerical measurements over time, like how many users are connected or how long outputs take to render.

These data types were standardized under the OTEL project, [which is supported by a large community and many companies](https://opentelemetry.io/community/marketing-guidelines/#i-opentelemetry-is-a-joint-effort). The goal is to provide a consistent way to collect and export observability data, making it easier to monitor and troubleshoot applications.

OTEL is vendor-neutral, meaning you can send your telemetry data to various local backends like [Jaeger](https://www.jaegertracing.io/), [Zipkin](https://zipkin.io/), [Prometheus](https://prometheus.io/), or cloud-based services like [Grafana Cloud](https://grafana.com/products/cloud/), [Logfire](https://pydantic.dev/logfire), and [Langfuse](https://langfuse.com/). This flexibility means you’re not locked into any particular monitoring solution.

While that may be somewhat of a mouthful the tldr; is that with OTEL you can capture what goes on in your application and use a variety of services to explore this data. This is great especially for code that is meant to be deployed and thus not readily available for introspection.

A great thing about OTEL is that traces are linked across applications. If you have multiple linked microservices based on plumber2 then you can follow a request trace as it travels between the different APIs. The same goes for a shiny app that calls into a plumber2 api or the other way around. As we build out support across our tools this benefit will only get more profound.

### OTEL in plumber2

While OTEL is integrated into plumber2 it is not activated by default. To set it up you need the otel and otelsdk installed and configured:

```{r}
#| eval: false
pak::pak(c("otel", "otelsdk"))
```

Configuration is completely code free and based on environment variables. You can e.g. add the lines below to your `.Renviron` file to setup OTEL with Logfire

``` bash
# Enable OpenTelemetry by setting Collector environment variables
OTEL_TRACES_EXPORTER=http
OTEL_LOGS_EXPORTER=http
OTEL_LOG_LEVEL=debug
OTEL_METRICS_EXPORTER=http

OTEL_EXPORTER_OTLP_ENDPOINT="https://logfire-us.pydantic.dev"
OTEL_EXPORTER_OTLP_HEADERS="Authorization=<your-write-token>"
```

You can verify that everything is set up by calling `otel::is_tracing_enabled()` which should return `TRUE` in that case.

OTEL has an extensive list of semantic conventions for telemetry of various domains so that information is captured in a standardised way. plumber2 adheres to the HTTP server conventions and supports all the required and most of the recommended [trace attributes](https://opentelemetry.io/docs/specs/semconv/http/http-spans/#http-server-span) and [metrics](https://opentelemetry.io/docs/specs/semconv/http/http-metrics/).

Within a plumber2 API a trace span is started the moment a request is received. The span is populated with the following information:

-   `http.request.method`: The method of the request (e.g. `GET`, `POST`, etc)
-   `url.path`: The exact path requested
-   `url.scheme`: The protocol used for the request
-   `http.route`: The route pattern of the last of the route handlers the request went through
-   `network.protocol.name`: The internal protocol used. Always `http`
-   `network.protocol.version`: The version of the protocol. Always `1.1`
-   `server.port`: The port the server is listening on. Can be used to distinguish multiple concurrent servers
-   `url.query`: The querystring of the request
-   `client.address`: The IP address the request comes from
-   `server.address`: The address the request was send to
-   `user_agent.original`: The user agent of the client sending the request
-   `http.request.header.<header-name>`: The value of `header-name` in the request. E.g. `http.request.header.date` will contain the value of the `Date` header

Once the request has been handled it will further get the following information:

-   `http.response.status_code`: The status code of the response
-   `http.response.header.<header-name>`: The value of `header-name` in the response. E.g. `http.response.header.content-type` will contain the value of the `Content-Type` header

In addition to these attributes, a number of metrics are also recorded.

-   `http.server.request.duration`: The duration of the request handling from it is received to it is send back
-   `http.server.active_requests`: The number of active requests being handled at the given time
-   `http.server.request.body.size`: The size of the request body
-   `http.server.response.body.size`: The size of the response body

As a child of this parent span each handler in your API will also initiate a span with the following attributes

-   `routr.route`: The path pattern of the handler. This will be recorded in the routr representation which uses `:param` instead of `{param}` format (e.g. `users/:username` instead of `users/{username}`)
-   `routr.path.param.<param-name>`: The value of the `param-name` path parameter. E.g. a request for `users/thomas` will get a `routr.path.param.username` attribute with the value `thomas` if we continue with the example from above.

Any span you initiate inside a handler will become a child of the handler span and through that be linked to the parent request span.

As you can see, the integration provides extensive information for you to use when figuring out what is going on in your application. On top of that you can also use OTEL as your logging solution by setting `logger_otel` as your logging solution:

```{r}
#| eval: false
api() |> 
  api_logger(logger_otel)
```

This ensures that all the logs from errors, warnings, etc all end up in the same place as your other recordings and further gets linked to the exact request that gave rise to the log.

We truly believe extensive OTEL support across the ecosystem will be a game changer for deployed R code and we can't wait for our users to take advantage of it!

## Auth support

The second headliner is support for various authentication schemes out of the box. This comes courtesy of of the [fireproof](https://fireproof.data-imaginist.com) package which provides an auth plugin for fiery.

Setting up authentication is twofold (we are skipping over a detail you can read about [later in the blog](#annotation-for-datastores)). First, you need to define one or more guards to use. A guard is an adaption of a specific authentication scheme such as e.g. OAuth. Currently, fireproof supports the Basic and Bearer HTTP authorization schemes, a custom key based scheme, as well as OAuth 2.0 and OpenID Connect. Setting up a challenges can be done both programmatically and with annotations:

```{r}
#| eval: false
# Programmatic
api <- api() |> 
  api_auth_guard(
    guard = fireproof::guard_key(
      key_name = "X-API-KEY",
      validate = "MY_VERY_SECRET_KEY"
    ),
    name = "key_guard"
  )
```

```{r}
#| eval: false
# Annotation

#* @authGuard key_guard
fireproof::guard_key(
  key_name = "X-API-KEY",
  validate = "MY_VERY_SECRET_KEY"
)
```

Both of these pieces of code yields the same result. You API now has a guard registered under the name `key_guard` which will (if called upon) check a request for the existence of a cookie named `X-API-KEY` with the value `MY_VERY_SECRET_KEY`.

Your handlers can now lean on that guard to protect access. Again, this can be done both programmatically and in annotation and will generally be handled when the request handler is created:

```{r}
#| eval: false
# Programmatic
api |> 
  api_get(
    path = "/admin",
    function(...) {
      # whatever you wish to protect
    },
    auth_flow = key_guard
  )

```

```{r}
#| eval: false
# Annotation

#* An example endpoint with auth
#* 
#* @get /admin
#* @auth key_guard
function(...) {
  # whatever you wish to protect
}
```

Again, both of the above do the same thing. They set up the endpoint to require the `key_guard` to be passed before further handling takes place.

### Multiple guards and requirements

The above shows the absolute simplest authentication setup, both because the key guard is by far the simplest to set up, and because only a single guard is ever in use. We can imagine a situation where we both want to allow users to log in with a username and password *or* authorize with a key and a google login. This requires defining multiple guards which can be done in sequence:

```{r}
#| eval: false
#* @authGuard key
fireproof::guard_key(
  key_name = "X-API-KEY",
  validate = "MY_VERY_SECRET_KEY"
)
#* @authGuard basic
fireproof::guard_basic(
  validate = function(username, password) {
    username == "thomas" && password == "xrCy45rWrgwq"
  }
)
#* @authGuard google
fireproof::guard_google(
  redirect_url = "https://example.com/auth",
  client_id = "MY_APP_ID",
  client_secret = "SUCHASECRET"
)
```

We now have 3 guards (of dubious quality) to reference in our handler. How do we capture the relationship of requiring either the basic to pass or the key and google to pass? Simple, with a logical expression:

```{r}
#| eval: false
#* An example endpoint with auth
#* 
#* @get /admin
#* @auth basic || (key && google)
function(...) {
  # whatever you wish to protect
}
```

As you can see the names of the guards acts as booleans and can be composed with the basic boolean operators (`||`, `&&`, and `(`/`)`).

### Scopes

Sometimes you need more granularity in your authentication. Some users may only read while others may read and write to resources. This could be solved with multiple guards but it quickly becomes unwieldy. Instead you can set scope requirements on an endpoint. Guards can then grant scopes to a user in their `validate` function by returning a character vector instead of a boolean, like this:

```{r}
#| eval: false
#* @authGuard basic
fireproof::guard_basic(
  validate = function(username, password) {
    if (username == "guest") {
      return("read")
    }
    if (username == "thomas" && password == "xrCy45rWrgwq") {
      return(c("read", "write"))
    }
    FALSE
  }
)

#* Read the calendar entries
#* 
#* @get /calendar
#* @auth basic
#* @authScope read
#* 
function(...) {
  # return calendar entries
}

#* Add a new calendar entry
#* 
#* @post /calendar
#* @auth basic
#* @authScope write
#* 
function(...) {
  # update the calendar
}
```

As you can see, the authentication provided is very flexible and will only grow as more guards are added to fireproof.

## Other news

### Annotation for datastores

While datastores through the firesale package was supported upon release, they could only be set up programmatically. This has now been corrected with the addition of the `@datastore` tag. It works like this:

```{r}
#| eval: false
#* @datastore my_store
storr::driver_environment()
```

The `my_store` proceeding the key is optional and gives the name of the datastore (defaults to `datastore`). Below the block you provide a storr driver and then you are good to go.

One of the reasons why this happens in this release (apart from it missing felt weird) is that authentication requires a datastore in order to work (it provides persistent session login). If you create your guards etc with annotation it felt natural to also do that for the datastore in use.

### More powerful report support
The report endpoint has gotten even more powerful in this release in a number of ways:

- Report endpoints can now be added programmatically as well using `api_report()`
- There is now support for quarto documents using the jupyter engine
- OpenAPI documentation is now generated automatically for the report and incorporates the standard annotation known from request handler blocks.
- Parameterised reports now has their parameters type checked and casted based on the type of the default values or on explicit type specification in the `@param` tags.
- You can now request specific named output formats through the `/{output_format}` subpath. This is in addition to the content negotiation already available. E.g. `/report/revealjs` will request the revealjs format of the report served at `/report`.
- Caches can now be user specific if the rendering includes information specific to the user requesting it
- Caches can now be cleared using a `DELETE` request

## Thank you
I want to say thanks to everyone who has given plumber2 a spin. It takes some time to reach maturity when replacing a decade old package and every test spin brings more insight. With the addition of OTEL integration and auth support plumber2 has now reached the feature set I was planning for during the initial development and the next phase will be about refinement, performance, and bug fixes. Your input and experiences will be critical there.
