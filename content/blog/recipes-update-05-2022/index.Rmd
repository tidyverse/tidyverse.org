---
output: hugodown::hugo_document

slug: recipes-update-05-20222
title: Updates for recipes extension packages
date: 2022-05-03
author: Emil Hvitfeldt
description: >
    The three extension packages for recipes were recently updated 
    on CRAN adding new steps, features and bug fixes.

photo:
  url: https://unsplash.com/photos/nAMLTEerpWI
  author: Tim Hüfner

# one of: "deep-dive", "learn", "package", "programming", "roundup", or "other"
categories: [package] 
tags: [recipes, tidymodels]
---

<!--
TODO:
* [x] Look over / edit the post's title in the yaml
* [x] Edit (or delete) the description; note this appears in the Twitter card
* [x] Pick category and tags (see existing with `hugodown::tidy_show_meta()`)
* [x] Find photo & update yaml metadata
* [x] Create `thumbnail-sq.jpg`; height and width should be equal
* [x] Create `thumbnail-wd.jpg`; width should be >5x height
* [x] `hugodown::use_tidy_thumbnails()`
* [x] Add intro sentence, e.g. the standard tagline for the package
* [x] `usethis::use_tidy_thanks()`
-->

We're tickled pink to announce the releases of extension packages that followed the recent release of  [recipes](https://recipes.tidymodels.org/) 0.2.0. recipes is a package for preprocessing data before using it in models or visualizations. You can think of it as a mash-up of `model.matrix()` and dplyr.

You can install the these updates from CRAN with:

```{r, eval = FALSE}
install.packages("embed")
install.packages("themis")
install.packages("textrecipes")
```

The `NEWS` files are linked here for each package; We will go over some of the bigger changes within and between these packages in this post. A lot of the smaller changes were done to make sure that these extension packages are up to the same standard as recipes itself.

- [themis](https://themis.tidymodels.org/news/index.html#themis-020)
- [textrecipes](https://textrecipes.tidymodels.org/news/index.html#textrecipes-051)
- [embed](https://embed.tidymodels.org/news/index.html#embed-020)

```{r, message=FALSE}
library(recipes)
library(themis)
library(textrecipes)
library(embed)
library(modeldata)
set.seed(1234)
```

## themis

A new step `step_smotenc()` was added thanks to [Robert Gregg](https://github.com/RobertGregg). This step applies the [SMOTENC algorithm](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C7&q=SMOTENC+&btnG=) to synthetically generate observations from minority classes. The SMOTENC method can handle a mix of categorical and numerical predictors, which was not possible using the existing SMOTE method which could only operate on numeric predictors. 

The `hpc_data` illustrates this use case neatly. The data set contains characteristics of HPC Unix jobs and how long they took to run (the outcome column is `class`). The outcome is not that balanced, with some classes having almost 10 times fewer observations than others. One way to deal with an imbalance like this is to over-sample the minority observations to mitigate the imbalance. 

```{r}
data(hpc_data)

hpc_data %>% count(class)
```

Using `step_smotenc()`, with the `over_ratio` argument, we can make sure that all classes are over-sampled to have no less than half of the observations of the largest class.

```{r}
up_rec <- recipe(class ~ ., data = hpc_data) %>%
  step_smotenc(class, over_ratio = 0.5) %>%
  prep()

up_rec %>%
  bake(new_data = NULL) %>%
  count(class)
```

The method that was implemented in embed now has [standalone functions](https://themis.tidymodels.org/reference/index.html#methods) to apply these algorithms without having to create a recipe.

```{r}
smotenc(hpc_data, "class", over_ratio = 0.5)
```

## textrecipes

We added the functions `all_tokenized()` and `all_tokenized_predictors()` to more easily select tokenized columns, similar to the [existing `all_numeric()` and `all_numeric_predictors()` selectors in recipes](https://recipes.tidymodels.org/reference/has_role.html).

The most important step in textrecipes is`step_tokenize()`, as you need it to generate tokens that can be modified by other steps. We have found that this function has gotten overloaded with functionality as more and more support for different types of tokenization was added. To address this, we have created new specialized tokenization steps; `step_tokenize()` has gotten cousin steps `step_tokenize_bpe()`, `step_tokenize_sentencepiece()`, and `step_tokenize_wordpiece()` which wrap [tokenizers.bpe](https://CRAN.R-project.org/package=tokenizers.bpe), [sentencepiece](https://CRAN.R-project.org/package=sentencepiece), and [wordpiece](https://CRAN.R-project.org/package=wordpiece) respectively.

In addition to being easier to manage code-wise, these new functions also allow for more compact, more readable code with better tab completion.

```{r}
data(tate_text)

# Old
tate_rec <- recipe(~., data = tate_text) %>%
 step_tokenize(
    text,
    engine = "tokenizers.bpe",
    training_options = list(vocab_size = 1000)
  )

# New
tate_rec <- recipe(~., data = tate_text) %>%
  step_tokenize_bpe(medium, vocabulary_size = 1000)
```

## embed

`step_feature_hash()` is now soft deprecated in embed in favor of `step_dummy_hash()` in textrecipes. The embed version uses TensorFlow, which for some use cases is quite a dependency. One thing to keep an eye out for when moving over is that the textrecipes version uses `num_terms` instead of `num_hash` to denote the number of columns to output.

```{r, warning=FALSE}
data(Sacramento)

# Old recipe
embed_rec <- recipe(price ~ zip, data = Sacramento) %>%
  step_feature_hash(zip, num_hash = 64)

# New recipe
textrecipes_rec <- recipe(price ~ zip, data = Sacramento) %>%
  step_dummy_hash(zip, num_terms = 64)
```

## Acknowledgements

We’d like to extend our thanks to all of the contributors who helped make these releases possible!

- themis: [&#x0040;coforfe](https://github.com/coforfe), [&#x0040;EmilHvitfeldt](https://github.com/EmilHvitfeldt), [&#x0040;emilyriederer](https://github.com/emilyriederer), [&#x0040;jennybc](https://github.com/jennybc), [&#x0040;OGuggenbuehl](https://github.com/OGuggenbuehl), and [&#x0040;RobertGregg](https://github.com/RobertGregg).

- textrecipes: [&#x0040;dgrtwo](https://github.com/dgrtwo), [&#x0040;DiabbZegpi](https://github.com/DiabbZegpi), [&#x0040;EmilHvitfeldt](https://github.com/EmilHvitfeldt), [&#x0040;jcragy](https://github.com/jcragy), [&#x0040;jennybc](https://github.com/jennybc), [&#x0040;joeycouse](https://github.com/joeycouse), [&#x0040;lionel-](https://github.com/lionel-), [&#x0040;NLDataScientist](https://github.com/NLDataScientist), [&#x0040;raj-hubber](https://github.com/raj-hubber), and [&#x0040;topepo](https://github.com/topepo).

- embed: [&#x0040;EmilHvitfeldt](https://github.com/EmilHvitfeldt), [&#x0040;juliasilge](https://github.com/juliasilge), [&#x0040;naveranoc](https://github.com/naveranoc), [&#x0040;talegari](https://github.com/talegari), and [&#x0040;topepo](https://github.com/topepo).
