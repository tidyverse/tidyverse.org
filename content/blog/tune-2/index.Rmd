---
output: hugodown::hugo_document

slug: tune-2
title: "tune version 2.0.0"
date: 2025-08-29
author: Max Kuhn, Simon Couch, Emil Hvitfeldt, Hannah Frick
description: >
    A new version of tune brings significant updates for model tuning and 
    parallel processing. 

photo:
  url: https://unsplash.com/photos/black-car-stereo-turned-on-at-7-qHbg3DKB1Y0
  author: Stephen Andrews

# one of: "deep-dive", "learn", "package", "programming", "roundup", or "other"
categories: [package] 
tags: [tidymodels,postprocessing,parallel processing]
---

```{r}
#| label: startup
#| include: false

library(tidymodels)
theme_set(theme_bw())
options(cli.width = 72, cli.ansi = FALSE)
```

We're very chuffed to announce the release of [tune](https://tune.tidymodels.org) **2.0.0**. tune is a package that can be used to resample models and/or optimize their tuning parameters 

You can install it from CRAN with:

```{r, eval = FALSE}
install.packages("tune")
```

This blog post will describe the two major updates to the package. You can see a full list of changes in the [release notes](https://tune.tidymodels.org/news/index.html#tune-200)

Those two big improvements to the package: new parallel processing features and postprocessing. 

## Using future or mirai for parallel processing

[Historically](https://www.tidyverse.org/blog/2024/04/tune-1-2-0/#modernized-support-for-parallel-processing), we've used the foreach package to run calculations in parallel. Sadly, that package is no longer under active development, so we've removed support for it and added functionality for the [future](https://future.futureverse.org/) and [mirai](https://mirai.r-lib.org/) packages. 

Previously, you would load a foreach parallel backend package, such as doParallel, doMC, or doFuture, and then register it. For  example:

```
library(doParallel)
cl <- makePSOCKcluster()
registerDoParallel(cl)
```

Instead, you can use the future package via:

```
library(future)
plan("multisession")
```

or the mirai package by using

```
library(mirai)
daemons(num_cores)
```

Each of these is configurable to run in various ways, such as on remote servers. 

## Tuning your postprocessor

A postprocessor is an operation that modifies model predictions.  For example, if your classifier can separate classes but its probability estimates are not accurate enough, you can add a _calibrator_ operation that can attempt to adjust those values. Another good example is for binary classifiers, where the default threshold for classifying a prediction as an event can be adjusted based on its corresponding probability estimate. 

Currently, we've enabled postprocessing using the [tailor package](https://www.tidyverse.org/blog/2024/10/postprocessing-preview/). The operations that are currently available: 

 - `adjust_numeric_calibration()`: Estimate and apply a calibration model for regression problems. 
 - `adjust_numeric_range()`: Truncate the range of predictions.
 - `adjust_predictions_custom()`: A general `mutate()`-like adjustment. 
 - `adjust_probability_calibration()`: Estimate and apply a calibration model for classification problems. 
 - `adjust_probability_threshold()`: Covert binary class probabilities to hard class predictions using different thresholds. 
 - `adjust_equivocal_zone()`: _Decline_ to predict a sample if its strongest class probability is low. 
 
If the operations have arguments, these can be tuned in the same way as the preprocessors (e.g., a recipe) or the supervised model. For example, let's tune the probability threshold for a random forest classifier. 

We'll simulate some data with a class imbalance: 

```{r}
#| label: sim-data
library(tidymodels)

set.seed(296)
sim_data <- sim_classification(2000, intercept = -12)
sim_data |> count(class)

# We'll resampling them via 10-fold cross-validation:
sim_rs <- vfold_cv(sim_data, strata = class)
```

We define a tailor object that tags the class probability threshold for optimization: 

```{r}
#| label: tailor
tlr_spec <- 
  tailor() |> 
  adjust_probability_threshold(threshold = tune())
```

and also specify a random forest that uses its default tuning parameters: 

```{r}
#| label: rf
#| fig-width: 5
#| fig-height: 7
#| out-width: 100%
rf_spec <- rand_forest(mode = "classification")
rf_thrsh_wflow <- workflow(class ~ ., rf_spec, tlr_spec)
rf_thrsh_wflow
```

We can see that we can improve sensitivity by _reducing_ the threshold. The rate of decay in specificity is slow compared to the gain in sensitivity until thresholds less than 10% are used. The Brier score is constant over the threshold since it only uses the estimated class probabilities, which are unaffected by the threshold. 

With a class imbalance, the default 50% threshold yields high specificity but low sensitivity. When we alter the threshold, those numbers will change, and we can select the best trade-off for our application. Let's tune the workflow: 

```{r}
#| label: tuning
cls_mtr <- metric_set(roc_auc, sensitivity, specificity)

# To run all resamples in parallel:
mirai::daemons(10)

set.seed(985)
rf_thrsh_res <- 
  rf_thrsh_wflow |> 
  tune_grid(
    resamples = sim_rs,
    grid = tibble(threshold = seq(0, 0.6, by = 0.01)),
    metrics = cls_mtr
  )
```

Let's visualize the results: 

```{r}
#| label: autoplot
autoplot(rf_thrsh_res) + lims(y = 0:1)
```

We can see that we can improve sensitivity by _reducing_ the threshold. The rate of decay in specificity is slow compared to the gain in sensitivity until thresholds less than 10% are used. The Brier score is constant over the threshold since it only uses the estimated class probabilities, which are unaffected by the threshold. 

We've taken great pains to avoid redundant calculations. In this example, for each resample, a single random forest model is trained, and then the postprocessing grid is evaluated. This _conditional execution_ strategy is already used to fit the fewest possible preprocessors, models, and postprocessors. 

For this classification example, recent updates to the [desirability2](https://desirability2.tidymodels.org/#using-with-the-tune-package) package can enable you to jointly find the best sensitivity/specificity trade-off using the threshold parameter _and_ model calibration/separation using other parameters. 

We'll add more examples and tutorials to tidymodels.org to showcase what we can do with postprocessing. 

## What's next

This had been a race towards posit::conf(2025). Our focus had to be on the two big features for this release (since we taught workshops that use them). There are a few other relatively minor issues to address as the year closes. 

One is to swap the package that we currently use for Gaussian Processes in Bayesian optimization from the GPfit package to the [GauPro](https://github.com/CollinErickson/GauPro) package. The former is not actively supported, and the latter has a few features that we'd love to have. Specifically, better kernel methods for non-numeric tuning parameters (e.g., the type of activation function used in neural networks). Hopefully, we'll have another planned release before the end of the year. 

Another near-future development goal is to have comprehensive integration for quantile regression models. We've added a few parsnip engines already and will expand the support in yardstick and tune. 

## Acknowledgements

We'd like to thanks everyone who contributed since the previous version: [&#x0040;3styleJam](https://github.com/3styleJam), [&#x0040;Diyar0D](https://github.com/Diyar0D), [&#x0040;EmilHvitfeldt](https://github.com/EmilHvitfeldt), [&#x0040;hfrick](https://github.com/hfrick), [&#x0040;MatthieuStigler](https://github.com/MatthieuStigler), [&#x0040;MattJEM](https://github.com/MattJEM), [&#x0040;mthulin](https://github.com/mthulin), [&#x0040;tjburch](https://github.com/tjburch), and [&#x0040;topepo](https://github.com/topepo).
