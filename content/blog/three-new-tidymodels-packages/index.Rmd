---
output: hugodown::hugo_document

slug: three-new-tidymodels-packages
title: "Two New tidymodels Packages"
date: 2025-11-23
author: Frances Lin, Max Kuhn
description: >
    Two new tidymodels packages focus on supervised feature selection. 

photo:
  url: https://unsplash.com/photos/three-french-macaroons-on-plate-71jYZb6Ag7M
  author: Keila Hötzel

# one of: "deep-dive", "learn", "package", "programming", "roundup", or "other"
categories: [package] 
tags: [tidymodels,feature-selection]
---

<!--
TODO:
* [ ] Look over / edit the post's title in the yaml
* [ ] Edit (or delete) the description; note this appears in the Twitter card
* [ ] Pick category and tags (see existing with `hugodown::tidy_show_meta()`)
* [ ] Find photo & update yaml metadata
* [ ] Create `thumbnail-sq.jpg`; height and width should be equal
* [ ] Create `thumbnail-wd.jpg`; width should be >5x height
* [ ] `hugodown::use_tidy_thumbnails()`
* [ ] Add intro sentence, e.g. the standard tagline for the package
* [ ] `usethis::use_tidy_thanks()`
-->

We're very chuffed to announce the release of _two_ new modeling packages: filtro and important. 

You can install them from CRAN with:

```{r, eval = FALSE}
install.packages(c("filtro", "important"))
```

This blog post will introduce both. 

## filtro

Feature selection is an important step in building machine learning models that are robust and reliable. By keeping only the most relevant predictors, we can reduce overfitting, improve model performance, and speed up computation. 

[filtro](https://filtro.tidymodels.org/) is a low-level tidy tools designed for filter-based supervised feature selection. filtro makes it easy to score, rank, and select features using a wide range of statistical and model-based metrics. The scoring metrics include: p-values, correlation, random forest feature importance, information gain, and more. 

With filtro, we can quickly rank the variables and select either the top proportion or the top number of features that best contribute to our model. It also supports multi-parameter optimization via desirability functions. filtro is a standalone tool, but it integrates with other packages, allowing it to be used within the tidymodels workflows.

Currently, filtro implements a total of six filters. Like other elements of the framework, also filtro is extensible if you want to use a score we haven't implemented yet. You can read more on how to do this on [tidymodels.org](https://www.tidymodels.org/learn/develop/filtro/).

The available score class objects are:

```{r}
#| echo: false
grep("^score_", ls("package:filtro"), value = TRUE)
```

Let's look at an example. [Kuhn and Johnson (2013)](https://www.google.com/search?q=Kuhn+and+Johnson+Applied+Predictive+Modeling+2013) described a data set where `r nrow(modeldata::chem_proc_yield)` samples were collected from a chemical manufacturing process. The goal is to predict process yield. Predictors are continuous, count, and categorical; some are correlated, and some contain missing values. 

Let’s create an initial split of the data (which are in the modeldata package):

```{r}
#| label: split
library(tidymodels)
library(filtro)

set.seed(1)
yield_split <- initial_split(modeldata::chem_proc_yield)
yield_split

yield_train <- training(yield_split)
yield_test <- testing(yield_split)
```

We’d like to estimate the strength of the relationship between these `r ncol(modeldata::chem_proc_yield)-1` predictors and the process yield. We’ll quantify that in two ways. First is the old-fashioned [Spearman rank correlation](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) statistic. We can estimate these values and rank them by the absolute value of the correlations. We can also measure their value using a random forest variable importance. One quality of the predictors is that their values are correlated, so there may be some value in using an _oblique_ random forest model. This creates a collection of tree-based models with splits that are linear combinations of the selected predictors. 

With filtro, we use the pre-made score objects for these measures along with the `fit()` method: 

```{r}
#| label: fit-cor
yield_rank_res <-
  score_cor_spearman |>
  fit(yield ~ ., data = yield_train)

# The object contains the statistics:
yield_rank_res@results |> 
  arrange(desc(abs(score)))
``` 

To score via a random forest model, we only need to switch out the score object:

```{r}
#| label: fit-orf
yield_rf_res <-
  score_imp_rf_oblique |>
  fit(yield ~ ., data = yield_train)

yield_rf_res@results |> 
  arrange(desc(abs(score)))
```

We should probably combine the scores and do a joint ranking. To combine the two sets of statistics: 

```{r}
#| label: bind

class_score_list <- list(yield_rank_res, yield_rf_res) |>
  bind_scores()

class_score_list
```

We can accomplish a joint ranking via desirability functions. Here, we set goals for each score (i.e., maximize, minimize, etc.). The algorithm rescales their values and uses a geometric mean for an overall ranking. The desirability2 package has some nice tools for this. Here's how we do it: 

```{r}
#| label: desirability
library(desirability2)
class_score_list |>
  show_best_desirability_prop(
    maximize(cor_spearman, low = 0.25, high = 1),
    maximize(imp_rf_oblique, scale = 2)
  ) |> 
  arrange(desc(.d_overall)) |> 
  select(-starts_with(".d_max_"))
```

Using the `scale = 2` option puts more weight on the random forest results. 

Now that we've looked at filtro, next up is the important package (yes, this is what we named it). 

## important

The [important](https://important.tidymodels.org/) package does two things. First, it provides yet another tool for calculating random forest-like permutation importance scores. We highly value other packages that perform these same calculations (such as [DALEX](https://modeloriented.github.io/DALEX/) and [vip](https://github.com/koalaverse/vip/)). Our rationale for creating another package for this is that we've developed interfaces for censored regression, including dynamic metrics such as Brier scores or ROC curves that evaluate models at a specific time point. These dynamic methods aren't available in other packages, and the peculiarities of these metrics make them difficult to incorporate into existing frameworks. 

Other niceties about importance scores are that any metric from the yardstick package can be used, and we have optimized parallel processing for the underlying computations. For the latter feature, we support the future and mirai packages for parallel processing. 

important also has three recipe steps for supervised feature selection (similar to what Steven Pawley did with his [colino package](https://stevenpawley.github.io/colino/)). The steps are:

- [`step_predictors_best()`](https://important.tidymodels.org/reference/step_predictor_best.html)
- [`step_predictors_retain()`](https://important.tidymodels.org/reference/step_predictor_retain.html)
- [`step_predictors_desirability()`](https://important.tidymodels.org/reference/step_predictor_desirability.html)

Let's look at the last one, which mirrors our analysis above. 

```{r}
#| label: recipe
library(important)
goals <-
  desirability(
    maximize(cor_spearman, low = 0.25, high = 1),
    maximize(imp_rf_oblique, scale = 2)
  )

yield_rec <-
  recipe(yield ~ ., data = yield_train) |>
  step_impute_knn(all_predictors(), neighbors = 10) |>
  step_predictor_desirability(
    all_predictors(),
    score = goals,
    prop_terms = 1 / 10
  )
yield_rec
```
Next up is the important package (yes, this is what we named it). When combined with a specific model, we can tune the number of neighbors as well as the proportion of predictors retained (10% above). 

`prep()` will do the appropriate estimation steps: 

```{r}
#| label: trained-recipe
trained_rec <- prep(yield_rec)
```

Which 10% of the predictors were retained? The `tidy()` method can list the scores and their rankings: 

```{r}
#| label: tidy
scores <- tidy(trained_rec, number = 2)
scores |>
  arrange(desc(.d_overall)) |>
  select(-starts_with(".d_max_"), -id)
  
# What percentage was removed?
mean(scores$removed * 100)
```


