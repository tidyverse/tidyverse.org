---
output: hugodown::hugo_document

slug: ellmer-0-4-0
title: ellmer 0.4.0
date: 2025-11-18
author: Hadley Wickham
description: >
    ellmer 0.4.0 includes important lifecycle updates, new Claude features
    (caching, file uploads, web tools), OpenAI improvements, and enhancements
    to error handling, pricing tracking, and security.
photo:
  url: https://unsplash.com/photos/a-herd-of-elephants-standing-next-to-each-other-CzIwSXedUGM
  author: Evan Jones

# one of: "deep-dive", "learn", "package", "programming", "roundup", or "other"
categories: [package]
tags: [ellmer]
---

<!--
TODO:
* [x] Look over / edit the post's title in the yaml
* [x] Edit (or delete) the description; note this appears in the Twitter card
* [x] Pick category and tags (see existing with `hugodown::tidy_show_meta()`)
* [x] Find photo & update yaml metadata
* [x] Create `thumbnail-sq.jpg`; height and width should be equal
* [x] Create `thumbnail-wd.jpg`; width should be >5x height
* [x] `hugodown::use_tidy_thumbnails()`
* [x] Add intro sentence, e.g. the standard tagline for the package
* [ ] `usethis::use_tidy_thanks()`
-->

We're very happy to announce the release of [ellmer](https://ellmer.tidyverse.org) 0.4.0. ellmer makes it easy to chat with a large language model directly from R. It supports a wide variety of providers (including OpenAI, Anthropic, Azure, Google, Snowflake, Databricks and many more), makes it easy to [extract structured data](https://ellmer.tidyverse.org/articles/structured-data.html), and to give the LLM the ability to call R functions via [tool calling](https://ellmer.tidyverse.org/articles/tool-calling.html).

You can install it from CRAN with:

```{r, eval = FALSE}
install.packages("ellmer")
```

This blog post will cover the major changes in this release, including important lifecycle updates, new features for Claude (caching, file uploads, and web tools), improvements to OpenAI support (responses API and built-in tools), and a variety of enhancements to error handling, pricing tracking, and security.

You can see a full list of changes in the [release notes](https://github.com/tidyverse/ellmer/releases/tag/v0.4.0).

```{r setup}
library(ellmer)
```

## Lifecycle

`parallel_chat()` and `batch_chat()` are no longer experimental. Based on user feedback, both `parallel_chat()` and `batch_chat()` do a much better job of handling errors, and I'm confident that they're around to stay.

Reflecting Anthropic's recent rebranding of developer tools under the Claude name, `chat_claude()` is no longer deprecated and is an alias for `chat_anthropic()`. New `models_claude()` is now an alias for `models_anthropic()`.

The following deprecated functions/arguments/methods have been removed:

  * `Chat$extract_data()` -> `chat$chat_structured()` (0.2.0)
  * `Chat$extract_data_async()` -> `chat$chat_structured_async()` (0.2.0)
  * `chat_anthropic(max_tokens)` -> `chat_anthropic(params)` (0.2.0)
  * `chat_azure()` -> `chat_azure_openai()` (0.2.0)
  * `chat_azure_openai(token)` (0.1.1)
  * `chat_bedrock()` -> `chat_aws_bedrock()` (0.2.0)
  * `chat_claude()` -> `chat_anthropic()` (0.2.0)
  * `chat_cortex()` -> `chat_snowflake()` (0.2.0)
  * `chat_gemini()` -> `chat_google_gemini()` (0.2.0)
  * `chat_openai(seed)` -> `chat_openai(params)` (0.2.0)
  * `create_tool_def(model)` -> `create_tool_def(chat)` (0.2.0)

## `chat_claude()`

`chat_claude()` gains a new `cache` parameter to control caching. By default it is set to "5m". Claude's caching model is rather difficult to understand, but I'm reasonably confident that this will reduce your costs overall. `?chat_claude` goes into the details of why I think this will save you money.

With help from @dcomputing, ellmer has gained a suite of file management helpers such as `claude_file_upload()`, `claude_file_list()`, `claude_file_delete()`, and so on. These allow you to upload [a variety of file types](https://docs.claude.com/en/docs/build-with-claude/files#file-types-and-content-blocks) for investigation.

You can now take advantage of Claude's built-in [web search](https://docs.claude.com/en/docs/agents-and-tools/tool-use/web-search-tool) and [web fetch](https://docs.claude.com/en/docs/agents-and-tools/tool-use/web-fetch-tool) with `claude_tool_web_search()` and `claude_tool_web_fetch()`. These empower Claude to perform web searches and read web pages on your behalf.

## `chat_openai()` and `chat_openai_compatible()`

`chat_openai()` now uses OpenAI's more modern "responses API". This is their now-recommended API, and unlocks the ability to use the built-in tools, such as web search with `openai_tool_web_search()`. It also gains a `service_tier` argument which allows you to request slower/cheaper or faster/more expensive results.

If you want to talk to a model provider that is OpenAI API compatible (i.e. uses the older "chat completions" API), you'll need to use `chat_openai_compatible()`.

## New features

* `parallel_chat()` and `batch_chat()` are much better at dealing with errors, and should now (by and large) succeed even if not all prompts succeeded or return badly formatted output. This does make the output from `parallel_chat()` a bit more complex, since it can now be a mix of `Chat` objects, error objects, and `NULL`, but we think the trade-off is worth it.

* `batch_chat()` and friends have a revised hashing mechanism which is used to ensure that you don't accidentally use saved results with the wrong inputs. The mechanism now only hashes the provider `name`, `model`, and `base_url`. This should provide some protection from accidentally reusing the same `.json` file with different providers, while still allowing you to use the same batch file across ellmer versions. There's also a new `ignore_hash` argument that allows you to opt out of the check if you're confident the difference only arises because ellmer itself has changed.

* There were a bunch of smaller improvements to pricing: the package now uses the latest pricing data, `batch_chat()` only records costs on retrieval, `Chat$get_tokens()` includes cost information, and the print method does a better job of matching underlying data.

* `params()` gains new `reasoning_effort` and `reasoning_tokens` so you can control the amount of effort a reasoning model spends on thinking. Initial support is provided for `chat_claude()`, `chat_google_gemini()`, and `chat_openai()`.

* `chat_*()` functions now use a `credentials` function instead of an `api_key` value. This means that API keys are never stored in the chat object (which might be saved to disk), but are instead retrieved on demand as needed. You generally shouldn't need to use the `credentials` argument directly yourself, but when you do, you should use it to dynamically retrieve the API key from some other source (i.e. never inline a secret directly into a function call).

* `tool()`s can now return image or PDF content types, with `content_image_file()` or `content_pdf()`.

* You can use the new `schema_df()` to describe the schema of a data frame to an LLM. It's designed to give a high-quality summary without spending too many tokens.

## Acknowledgements

A big thanks to everyone who contributed to this release! [&#x0040;abiyug](https://github.com/abiyug), [&#x0040;AdaemmerP](https://github.com/AdaemmerP), [&#x0040;AlmogAngel](https://github.com/AlmogAngel), [&#x0040;app2let](https://github.com/app2let), [&#x0040;benhmin](https://github.com/benhmin), [&#x0040;bensoltoff](https://github.com/bensoltoff), [&#x0040;benzipperer](https://github.com/benzipperer), [&#x0040;bianchenhao](https://github.com/bianchenhao), [&#x0040;bshor](https://github.com/bshor), [&#x0040;CChen89](https://github.com/CChen89), [&#x0040;cherylisabella](https://github.com/cherylisabella), [&#x0040;cpsievert](https://github.com/cpsievert), [&#x0040;dcomputing](https://github.com/dcomputing), [&#x0040;durraniu](https://github.com/durraniu), [&#x0040;fh-slangerman](https://github.com/fh-slangerman), [&#x0040;flaviaerius](https://github.com/flaviaerius), [&#x0040;foton263](https://github.com/foton263), [&#x0040;gadenbuie](https://github.com/gadenbuie), [&#x0040;gary-mu](https://github.com/gary-mu), [&#x0040;Green-State-Data](https://github.com/Green-State-Data), [&#x0040;hadley](https://github.com/hadley), [&#x0040;howardbaik](https://github.com/howardbaik), [&#x0040;jeroenjanssens](https://github.com/jeroenjanssens), [&#x0040;jharvey-records](https://github.com/jharvey-records), [&#x0040;joranE](https://github.com/joranE), [&#x0040;kbenoit](https://github.com/kbenoit), [&#x0040;LukasWallrich](https://github.com/LukasWallrich), [&#x0040;m20m22](https://github.com/m20m22), [&#x0040;maciekbanas](https://github.com/maciekbanas), [&#x0040;mattwarkentin](https://github.com/mattwarkentin), [&#x0040;parmsam](https://github.com/parmsam), [&#x0040;parmsam-pfizer](https://github.com/parmsam-pfizer), [&#x0040;promothesh](https://github.com/promothesh), [&#x0040;rempsyc](https://github.com/rempsyc), [&#x0040;roldanalex](https://github.com/roldanalex), [&#x0040;rplsmn](https://github.com/rplsmn), [&#x0040;schloerke](https://github.com/schloerke), [&#x0040;simonpcouch](https://github.com/simonpcouch), [&#x0040;t-kalinowski](https://github.com/t-kalinowski), [&#x0040;wklimowicz](https://github.com/wklimowicz), [&#x0040;wlandau](https://github.com/wlandau), and [&#x0040;xx02al](https://github.com/xx02al).
