<!doctype html><html><head><!doctype html><html lang=en-us><link rel=stylesheet href=/css/fonts.css><link rel=stylesheet href=/css/main-site.css><link rel=stylesheet href=/css/fa5-all.css><style type=text/css>body{background-color:#fff;color:#1a1917}a{color:#38577f}a:hover{color:#42709b}a:focus{outline-color:#42709b}.column25-left .sectionTitle a:hover:not(.current),.column16-left .sectionTitle a:hover:not(.current){color:#1a1917}.icon-attribution,.icon-attribution a{color:#1a1917;opacity:75%}#homeContent .band.first{background-color:#fff}#homeContent .band.second{background-color:#fdeba4}#homeContent .band.third{background-color:#fff}#rStudioHeader{background-color:#1a162d;color:#fff}#rStudioHeader .productName{color:#fff}#rStudioHeader .productName:hover,#rStudioHeader .productName:focus{color:#fdeba4}#rStudioHeader #menu .menuItem.a{background-color:#75aadb;color:#fff}#rStudioHeader #menu .menuItem:hover{background-color:#484557;color:#fff}#rStudioHeader #menu .menuItem.current{background-color:#fff;color:#1a162d;text-decoration:none}#rStudioFooter.band{background-color:#767381}#rStudioFooter .bandContent #copyright{color:#e3eef8}table tbody tr:nth-child(even){background-color:#f7faff}table tbody tr:nth-child(odd){background-color:#fff}.latest{border-top:.5em solid <no value>}.event{-moz-box-shadow:0 0 0 0 rgba(0,0,0,.1);-webkit-box-shadow:0 0 0 0 rgba(0,0,0,.1);box-shadow:0 0 0 0 rgba(0,0,0,.1)}.section .event{background-color:#eab0c41a}.section .event{border-top:7pt solid #a19ea936}.section .event a{color:#1a162d}.section .event{color:#404040}</style><link rel=stylesheet href=/css/tidyverse.css><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo 0.71.1"><title>bonsai 0.1.0</title><meta property="og:title" content="bonsai 0.1.0"><meta property="og:description" content="A new parsnip extension package for tree-based models is now on CRAN."><meta property="og:type" content="article"><meta property="og:url" content="https://www.tidyverse.org/blog/2022/06/bonsai-0-1-0/"><meta property="twitter:card" content="summary_large_image"><meta property="og:title" content="bonsai 0.1.0 - Tidyverse"><meta property="description" content="A new parsnip extension package for tree-based models is now on CRAN."><meta property="og:description" content="A new parsnip extension package for tree-based models is now on CRAN."><meta property="og:image" content="https://www.tidyverse.org/blog/2022/06/bonsai-0-1-0/thumbnail-sq.jpg"><meta name=twitter:image content="https://www.tidyverse.org/blog/2022/06/bonsai-0-1-0/thumbnail-wd.jpg"><link rel=apple-touch-icon sizes=180x180 href=/images/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/images/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/images/favicons/favicon-16x16.png><link rel=manifest href=/images/favicons/site.webmanifest><link rel=mask-icon href=/images/favicons/safari-pinned-tab.svg><link rel="shortcut icon" href=/images/favicons/favicon.ico><meta name=msapplication-TileColor content="#da532c"><meta name=msapplication-config href=/images/favicons/browserconfig.xml><script type=text/javascript src=/js/jquery-3.5.1.min.js></script><script type=text/javascript src=/js/site.js></script><link rel=icon href=/images/favicon.ico><script type=text/javascript src=/js/clipboard.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin=anonymous></script><script defer data-domain=tidyverse.org,all.tidyverse.org src=https://plausible.io/js/plausible.js></script></head><body><div id=appTidyverseSite class="shrinkHeader alwaysShrinkHeader"><div id=main><div id=rStudioHeader><nav class=band><div class="innards bandContent"><div><a class=productName href=/%20/>Tidyverse</a></div><div id=menu><div id=menuToggler></div><div id=menuItems><a class=menuItem href=/packages/>Packages</a>
<a class="menuItem current" href=/blog/>Blog</a>
<a class=menuItem href=/learn/>Learn</a>
<a class=menuItem href=/help/>Help</a>
<a class=menuItem href=/contribute/>Contribute</a></div></div></div></nav></div><main><div class="band padForHeader pushFooter"><div class=bandContent><div class="full splitColumns withMobileMargins"><div class=column75><h1 class=article-title>bonsai 0.1.0</h1><div class=article-header aria-hidden=true><div class=photo><img src=/blog/2022/06/bonsai-0-1-0/thumbnail-wd.jpg></div><div class=photoCredit>Photo by <a href=https://unsplash.com/photos/-OBffuUekfQ>五玄土</a></div></div><span class=article-date><i class="fas fa-calendar-day fa-fw"></i>&nbsp;&nbsp;2022/06/30</span><p style=margin-bottom:.5em;margin-top:.85em><i class="fas fa-tags"></i>&nbsp;
<a href=/tags/tidymodels/>tidymodels</a>,
<a href=/tags/parsnip/>parsnip</a>,
<a href=/tags/bonsai/>bonsai</a></p><p style=margin-top:.5em><i class="fas fa-user-circle fa-fw"></i>&nbsp;
Simon Couch</p><div class=article-content><p>We&rsquo;re super stoked to announce the first release of the
<a href=https://bonsai.tidymodels.org/ target=_blank rel=noopener>bonsai</a> package on CRAN! bonsai is a
<a href=https://parsnip.tidymodels.org/ target=_blank rel=noopener>parsnip</a> extension package for tree-based models.</p><p>You can install it from CRAN with:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf><a href=https://rdrr.io/r/utils/install.packages.html>install.packages</a></span><span class=o>(</span><span class=s>"bonsai"</span><span class=o>)</span></code></pre></div><p>Without extension packages, the parsnip package already supports fitting decision trees, random forests, and boosted trees. The bonsai package introduces support for two additional engines that implement variants of these algorithms:</p><ul><li><a href="https://CRAN.R-project.org/package=partykit" target=_blank rel=noopener>partykit</a>: conditional inference trees via
<a href=https://parsnip.tidymodels.org/reference/decision_tree.html target=_blank rel=noopener><code>decision_tree()</code></a> and conditional random forests via
<a href=https://parsnip.tidymodels.org/reference/rand_forest.html target=_blank rel=noopener><code>rand_forest()</code></a></li><li><a href="https://CRAN.R-project.org/package=lightgbm" target=_blank rel=noopener>LightGBM</a>: optimized gradient boosted trees via
<a href=https://parsnip.tidymodels.org/reference/boost_tree.html target=_blank rel=noopener><code>boost_tree()</code></a></li></ul><p>As we introduce further support for tree-based model engines in the tidymodels, new implementations will reside in this package (rather than parsnip).</p><p>To demonstrate how to use the package, we&rsquo;ll fit a few tree-based models and explore their output. First, loading bonsai as well as the rest of the tidymodels core packages:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=kr><a href=https://rdrr.io/r/base/library.html>library</a></span><span class=o>(</span><span class=nv><a href=https://bonsai.tidymodels.org/>bonsai</a></span><span class=o>)</span>
<span class=c>#&gt; Loading required package: parsnip</span>

<span class=kr><a href=https://rdrr.io/r/base/library.html>library</a></span><span class=o>(</span><span class=nv><a href=https://tidymodels.tidymodels.org>tidymodels</a></span><span class=o>)</span>
<span class=c>#&gt; ── <span style=font-weight:700>Attaching packages</span> ────────────────────────────────────── tidymodels 0.2.0 ──</span>
<span class=c>#&gt; <span style=color:#0b0>✔</span> <span style=color:#00b>broom       </span> 0.8.0          <span style=color:#0b0>✔</span> <span style=color:#00b>rsample     </span> 0.1.1     </span>
<span class=c>#&gt; <span style=color:#0b0>✔</span> <span style=color:#00b>dials       </span> 1.0.0          <span style=color:#0b0>✔</span> <span style=color:#00b>tibble      </span> 3.1.7     </span>
<span class=c>#&gt; <span style=color:#0b0>✔</span> <span style=color:#00b>dplyr       </span> 1.0.9          <span style=color:#0b0>✔</span> <span style=color:#00b>tidyr       </span> 1.2.0     </span>
<span class=c>#&gt; <span style=color:#0b0>✔</span> <span style=color:#00b>ggplot2     </span> 3.3.6          <span style=color:#0b0>✔</span> <span style=color:#00b>tune        </span> 0.2.0     </span>
<span class=c>#&gt; <span style=color:#0b0>✔</span> <span style=color:#00b>infer       </span> 1.0.2          <span style=color:#0b0>✔</span> <span style=color:#00b>workflows   </span> 0.2.6     </span>
<span class=c>#&gt; <span style=color:#0b0>✔</span> <span style=color:#00b>modeldata   </span> 0.1.1.<span style=color:#b00>9000</span>     <span style=color:#0b0>✔</span> <span style=color:#00b>workflowsets</span> 0.2.1     </span>
<span class=c>#&gt; <span style=color:#0b0>✔</span> <span style=color:#00b>purrr       </span> 0.3.4          <span style=color:#0b0>✔</span> <span style=color:#00b>yardstick   </span> 1.0.0     </span>
<span class=c>#&gt; <span style=color:#0b0>✔</span> <span style=color:#00b>recipes     </span> 0.2.0</span>
<span class=c>#&gt; ── <span style=font-weight:700>Conflicts</span> ───────────────────────────────────────── tidymodels_conflicts() ──</span>
<span class=c>#&gt; <span style=color:#b00>✖</span> <span style=color:#00b>purrr</span>::<span style=color:#0b0>discard()</span> masks <span style=color:#00b>scales</span>::discard()</span>
<span class=c>#&gt; <span style=color:#b00>✖</span> <span style=color:#00b>dplyr</span>::<span style=color:#0b0>filter()</span>  masks <span style=color:#00b>stats</span>::filter()</span>
<span class=c>#&gt; <span style=color:#b00>✖</span> <span style=color:#00b>dplyr</span>::<span style=color:#0b0>lag()</span>     masks <span style=color:#00b>stats</span>::lag()</span>
<span class=c>#&gt; <span style=color:#b00>✖</span> <span style=color:#00b>recipes</span>::<span style=color:#0b0>step()</span>  masks <span style=color:#00b>stats</span>::step()</span>
<span class=c>#&gt; <span style=color:#00b>•</span> Dig deeper into tidy modeling with R at <span style=color:#0b0>https://www.tmwr.org</span></span></code></pre></div><p>Note that we use a development version of the
<a href=https://modeldata.tidymodels.org/ target=_blank rel=noopener>modeldata</a> package to generate example data later on in this post using the new <code>sim_regression()</code> function&mdash;you can install this version of the package using <code>pak::pak(tidymodels/modeldata)</code>.</p><p>We&rsquo;ll use a
<a href=https://allisonhorst.github.io/palmerpenguins/ target=_blank rel=noopener>dataset</a> containing measurements on 3 different species of penguins as an example. Loading that data in and checking it out:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf><a href=https://rdrr.io/r/utils/data.html>data</a></span><span class=o>(</span><span class=nv>penguins</span>, package <span class=o>=</span> <span class=s>"modeldata"</span><span class=o>)</span>

<span class=nf><a href=https://rdrr.io/r/utils/str.html>str</a></span><span class=o>(</span><span class=nv>penguins</span><span class=o>)</span>
<span class=c>#&gt; tibble [344 × 7] (S3: tbl_df/tbl/data.frame)</span>
<span class=c>#&gt;  $ species          : Factor w/ 3 levels "Adelie","Chinstrap",..: 1 1 1 1 1 1 1 1 1 1 ...</span>
<span class=c>#&gt;  $ island           : Factor w/ 3 levels "Biscoe","Dream",..: 3 3 3 3 3 3 3 3 3 3 ...</span>
<span class=c>#&gt;  $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...</span>
<span class=c>#&gt;  $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...</span>
<span class=c>#&gt;  $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...</span>
<span class=c>#&gt;  $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...</span>
<span class=c>#&gt;  $ sex              : Factor w/ 2 levels "female","male": 2 1 1 NA 1 2 1 2 NA NA ...</span></code></pre></div><p>Specifically, we&rsquo;ll make use of flipper length and home island to model a penguin&rsquo;s species:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>ggplot</span><span class=o>(</span><span class=nv>penguins</span><span class=o>)</span> <span class=o>+</span>
  <span class=nf>aes</span><span class=o>(</span>x <span class=o>=</span> <span class=nv>island</span>, y <span class=o>=</span> <span class=nv>flipper_length_mm</span>, col <span class=o>=</span> <span class=nv>species</span><span class=o>)</span> <span class=o>+</span>
  <span class=nf>geom_jitter</span><span class=o>(</span>width <span class=o>=</span> <span class=m>.2</span><span class=o>)</span>
</code></pre><p><img src=figs/penguin-plot-1.png width=700px style=display:block;margin:auto></p></div><p>Looking at this plot, you might begin to imagine your own simple set of binary splits for guessing which species a penguin might be given its home island and flipper length. Given that this small set of predictors almost completely separates our outcome with only a few splits, a relatively simple tree should serve our purposes just fine.</p><h2 id=decision-trees>Decision Trees
<a href=#decision-trees><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>bonsai introduces support for fitting decision trees with partykit, which implements a variety of decision trees called conditional inference trees (CITs).</p><p>CITs differ from implementations of decision trees available elsewhere in the tidymodels in the criteria used to generate splits. The details of how these criteria differ are outside of the scope of this post.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> Practically, though, CITs offer a few notable advantages over CART- and C5.0-based decision trees:</p><ul><li><strong>Overfitting</strong>: Common implementations of decision trees are notoriously prone to overfitting, and require several well-chosen penalization (i.e. cost-complexity) and early stopping (e.g. pruning, max depth) hyperparameters to fit a model that will perform well when predicting on new observations. &ldquo;Out-of-the-box,&rdquo; CITs are not as prone to these same issues and do not accept a penalization parameter at all.</li><li><strong>Selection bias</strong>: Common implementations of decision trees are biased towards selecting variables with many possible split points or missing values. CITs are natively not prone to the first issue, and many popular implementations address the second vulnerability.</li></ul><p>To define a conditional inference tree model specification, just set the modeling engine to <code>"partykit"</code> when creating a decision tree. Fitting to the penguins data, then:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nv>dt_mod</span> <span class=o>&lt;-</span>
  <span class=nf><a href=https://parsnip.tidymodels.org/reference/decision_tree.html>decision_tree</a></span><span class=o>(</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
  <span class=nf><a href=https://parsnip.tidymodels.org/reference/set_engine.html>set_engine</a></span><span class=o>(</span>engine <span class=o>=</span> <span class=s>"partykit"</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
  <span class=nf><a href=https://parsnip.tidymodels.org/reference/set_args.html>set_mode</a></span><span class=o>(</span>mode <span class=o>=</span> <span class=s>"classification"</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
  <span class=nf><a href=https://generics.r-lib.org/reference/fit.html>fit</a></span><span class=o>(</span>
    formula <span class=o>=</span> <span class=nv>species</span> <span class=o>~</span> <span class=nv>flipper_length_mm</span> <span class=o>+</span> <span class=nv>island</span>, 
    data <span class=o>=</span> <span class=nv>penguins</span>
  <span class=o>)</span>

<span class=nv>dt_mod</span>
<span class=c>#&gt; parsnip model object</span>
<span class=c>#&gt; </span>
<span class=c>#&gt; </span>
<span class=c>#&gt; Model formula:</span>
<span class=c>#&gt; species ~ flipper_length_mm + island</span>
<span class=c>#&gt; </span>
<span class=c>#&gt; Fitted party:</span>
<span class=c>#&gt; [1] root</span>
<span class=c>#&gt; |   [2] island in Biscoe</span>
<span class=c>#&gt; |   |   [3] flipper_length_mm &lt;= 203</span>
<span class=c>#&gt; |   |   |   [4] flipper_length_mm &lt;= 196: Adelie (n = 38, err = 0.0%)</span>
<span class=c>#&gt; |   |   |   [5] flipper_length_mm &gt; 196: Adelie (n = 8, err = 25.0%)</span>
<span class=c>#&gt; |   |   [6] flipper_length_mm &gt; 203: Gentoo (n = 122, err = 0.0%)</span>
<span class=c>#&gt; |   [7] island in Dream, Torgersen</span>
<span class=c>#&gt; |   |   [8] island in Dream</span>
<span class=c>#&gt; |   |   |   [9] flipper_length_mm &lt;= 192: Adelie (n = 59, err = 33.9%)</span>
<span class=c>#&gt; |   |   |   [10] flipper_length_mm &gt; 192: Chinstrap (n = 65, err = 26.2%)</span>
<span class=c>#&gt; |   |   [11] island in Torgersen: Adelie (n = 52, err = 0.0%)</span>
<span class=c>#&gt; </span>
<span class=c>#&gt; Number of inner nodes:    5</span>
<span class=c>#&gt; Number of terminal nodes: 6</span></code></pre></div><p>Do any of these splits line up with your intuition? This tree results in only 6 terminal nodes and describes the structure shown in the above plot quite well.</p><p>Read more about this implementation of decision trees in
<a href=https://parsnip.tidymodels.org/reference/details_decision_tree_partykit.html target=_blank rel=noopener><code>?details_decision_tree_partykit</code></a>.</p><h2 id=random-forests>Random Forests
<a href=#random-forests><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>One generalization of a decision tree is a <em>random forest</em>, which fits a large number of decision trees, each independently of the others. The fitted random forest model combines predictions from the individual decision trees to generate its predictions.</p><p>bonsai introduces support for random forests using the <code>partykit</code> engine, which implements an algorithm called a <em>conditional random forest</em>. Conditional random forests are a type of random forest that uses conditional inference trees (like the one we fit above!) for its constituent decision trees.</p><p>To fit a conditional random forest with partykit, our code looks pretty similar to that which we we needed to fit a conditional inference tree. Just switch out
<a href=https://parsnip.tidymodels.org/reference/decision_tree.html target=_blank rel=noopener><code>decision_tree()</code></a> with
<a href=https://parsnip.tidymodels.org/reference/rand_forest.html target=_blank rel=noopener><code>rand_forest()</code></a> and remember to keep the engine set as <code>"partykit"</code>:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nv>rf_mod</span> <span class=o>&lt;-</span> 
  <span class=nf><a href=https://parsnip.tidymodels.org/reference/rand_forest.html>rand_forest</a></span><span class=o>(</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
  <span class=nf><a href=https://parsnip.tidymodels.org/reference/set_engine.html>set_engine</a></span><span class=o>(</span>engine <span class=o>=</span> <span class=s>"partykit"</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
  <span class=nf><a href=https://parsnip.tidymodels.org/reference/set_args.html>set_mode</a></span><span class=o>(</span>mode <span class=o>=</span> <span class=s>"classification"</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
  <span class=nf><a href=https://generics.r-lib.org/reference/fit.html>fit</a></span><span class=o>(</span>
    formula <span class=o>=</span> <span class=nv>species</span> <span class=o>~</span> <span class=nv>flipper_length_mm</span> <span class=o>+</span> <span class=nv>island</span>, 
    data <span class=o>=</span> <span class=nv>penguins</span>
  <span class=o>)</span></code></pre></div><p>Read more about this implementation of random forests in
<a href=https://parsnip.tidymodels.org/reference/details_rand_forest_partykit.html target=_blank rel=noopener><code>?details_rand_forest_partykit</code></a>.</p><h2 id=boosted-trees>Boosted Trees
<a href=#boosted-trees><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>Another generalization of a decision tree is a series of decision trees where <em>each tree depends on the results of previous trees</em>&mdash;this is called a <em>boosted tree</em>. bonsai implements an additional parsnip engine for this model type called <code>"lightgbm"</code>. While fitting boosted trees is quite computationally intensive, especially with high-dimensional data, LightGBM provides an implementation of a highly efficient variant of the algorithm.</p><p>To make use of it, start out with a <code>boost_tree</code> model spec and set <code>engine = "lightgbm"</code>:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nv>bt_mod</span> <span class=o>&lt;-</span>
  <span class=nf><a href=https://parsnip.tidymodels.org/reference/boost_tree.html>boost_tree</a></span><span class=o>(</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
  <span class=nf><a href=https://parsnip.tidymodels.org/reference/set_engine.html>set_engine</a></span><span class=o>(</span>engine <span class=o>=</span> <span class=s>"lightgbm"</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
  <span class=nf><a href=https://parsnip.tidymodels.org/reference/set_args.html>set_mode</a></span><span class=o>(</span>mode <span class=o>=</span> <span class=s>"classification"</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
  <span class=nf><a href=https://generics.r-lib.org/reference/fit.html>fit</a></span><span class=o>(</span>
    formula <span class=o>=</span> <span class=nv>species</span> <span class=o>~</span> <span class=nv>flipper_length_mm</span> <span class=o>+</span> <span class=nv>island</span>, 
    data <span class=o>=</span> <span class=nv>penguins</span>
  <span class=o>)</span></code></pre></div><p>The main benefit of using LightGBM is its computational efficiency: as the number of observations in training data increases, we can observe an increasingly substantial decrease in time-to-fit when using the LightGBM engine as compared to other implementations of boosted trees, like XGBoost.</p><p>To show this, we&rsquo;ll use the <code>sim_regression()</code> function from modeldata to simulate increasingly large datasets that we can fit models to. For example, generating a dataset with 10 observations and 20 numeric predictors:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>sim_regression</span><span class=o>(</span>num_samples <span class=o>=</span> <span class=m>10</span><span class=o>)</span>
<span class=c>#&gt; <span style=color:#555># A tibble: 10 × 21</span></span>
<span class=c>#&gt;    outcome predictor_01 predictor_02 predictor_03 predictor_04 predictor_05</span>
<span class=c>#&gt;      <span style=color:#555;font-style:italic>&lt;dbl&gt;</span>        <span style=color:#555;font-style:italic>&lt;dbl&gt;</span>        <span style=color:#555;font-style:italic>&lt;dbl&gt;</span>        <span style=color:#555;font-style:italic>&lt;dbl&gt;</span>        <span style=color:#555;font-style:italic>&lt;dbl&gt;</span>        <span style=color:#555;font-style:italic>&lt;dbl&gt;</span></span>
<span class=c>#&gt; <span style=color:#555> 1</span>  41.9        -<span style=color:#b00>3.15</span>          3.72       -<span style=color:#b00>0.800</span>        -<span style=color:#b00>5.87</span>         0.265</span>
<span class=c>#&gt; <span style=color:#555> 2</span>  49.4         4.93          6.15        5.09          0.501       -<span style=color:#b00>2.45</span> </span>
<span class=c>#&gt; <span style=color:#555> 3</span>  -<span style=color:#b00>9.20</span>        0.020<span style=text-decoration:underline>0</span>       -<span style=color:#b00>2.31</span>        4.64          0.422        3.14 </span>
<span class=c>#&gt; <span style=color:#555> 4</span>  -<span style=color:#b00>0.385</span>      -<span style=color:#b00>1.97</span>         -<span style=color:#b00>2.56</span>       -<span style=color:#b00>0.018</span><span style=color:#b00;text-decoration:underline>2</span>        1.83        -<span style=color:#b00>4.23</span> </span>
<span class=c>#&gt; <span style=color:#555> 5</span>   8.08       -<span style=color:#b00>0.266</span>        -<span style=color:#b00>0.574</span>      -<span style=color:#b00>1.08</span>         -<span style=color:#b00>1.75</span>         1.57 </span>
<span class=c>#&gt; <span style=color:#555> 6</span>   3.79        0.145         3.86        3.91          3.32        -<span style=color:#b00>4.27</span> </span>
<span class=c>#&gt; <span style=color:#555> 7</span>   1.12       -<span style=color:#b00>6.35</span>         -<span style=color:#b00>2.39</span>        0.119         0.848        1.74 </span>
<span class=c>#&gt; <span style=color:#555> 8</span>   3.21        4.56          3.20       -<span style=color:#b00>2.68</span>         -<span style=color:#b00>1.11</span>         0.729</span>
<span class=c>#&gt; <span style=color:#555> 9</span>  -<span style=color:#b00>4.56</span>        2.97         -<span style=color:#b00>1.36</span>       -<span style=color:#b00>1.90</span>         -<span style=color:#b00>1.01</span>         0.557</span>
<span class=c>#&gt; <span style=color:#555>10</span>   0.140      -<span style=color:#b00>0.234</span>        -<span style=color:#b00>1.05</span>        0.551         0.861       -<span style=color:#b00>0.937</span></span>
<span class=c>#&gt; <span style=color:#555># … with 15 more variables: predictor_06 &lt;dbl&gt;, predictor_07 &lt;dbl&gt;,</span></span>
<span class=c>#&gt; <span style=color:#555>#   predictor_08 &lt;dbl&gt;, predictor_09 &lt;dbl&gt;, predictor_10 &lt;dbl&gt;,</span></span>
<span class=c>#&gt; <span style=color:#555>#   predictor_11 &lt;dbl&gt;, predictor_12 &lt;dbl&gt;, predictor_13 &lt;dbl&gt;,</span></span>
<span class=c>#&gt; <span style=color:#555>#   predictor_14 &lt;dbl&gt;, predictor_15 &lt;dbl&gt;, predictor_16 &lt;dbl&gt;,</span></span>
<span class=c>#&gt; <span style=color:#555>#   predictor_17 &lt;dbl&gt;, predictor_18 &lt;dbl&gt;, predictor_19 &lt;dbl&gt;,</span></span>
<span class=c>#&gt; <span style=color:#555>#   predictor_20 &lt;dbl&gt;</span></span></code></pre></div><p>Now, fitting boosted trees on increasingly large datasets with XGBoost and LightGBM and observing time-to-fit:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=c># given an engine and nrow(training_data), return the time to fit</span>
<span class=nv>time_boost_fit</span> <span class=o>&lt;-</span> <span class=kr>function</span><span class=o>(</span><span class=nv>engine</span>, <span class=nv>n</span><span class=o>)</span> <span class=o>&#123;</span>
  <span class=nv>time</span> <span class=o>&lt;-</span> 
    <span class=nf><a href=https://rdrr.io/r/base/system.time.html>system.time</a></span><span class=o>(</span><span class=o>&#123;</span>
      <span class=nf><a href=https://parsnip.tidymodels.org/reference/boost_tree.html>boost_tree</a></span><span class=o>(</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
      <span class=nf><a href=https://parsnip.tidymodels.org/reference/set_engine.html>set_engine</a></span><span class=o>(</span>engine <span class=o>=</span> <span class=nv>engine</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
      <span class=nf><a href=https://parsnip.tidymodels.org/reference/set_args.html>set_mode</a></span><span class=o>(</span>mode <span class=o>=</span> <span class=s>"regression"</span><span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
      <span class=nf><a href=https://generics.r-lib.org/reference/fit.html>fit</a></span><span class=o>(</span>
        formula <span class=o>=</span> <span class=nv>outcome</span> <span class=o>~</span> <span class=nv>.</span>, 
        data <span class=o>=</span> <span class=nf>sim_regression</span><span class=o>(</span>num_samples <span class=o>=</span> <span class=nv>n</span><span class=o>)</span>
      <span class=o>)</span>
    <span class=o>&#125;</span><span class=o>)</span>
  
  <span class=nf>tibble</span><span class=o>(</span>
    engine <span class=o>=</span> <span class=nv>engine</span>,
    n <span class=o>=</span> <span class=nv>n</span>,
    time_to_fit <span class=o>=</span> <span class=nv>time</span><span class=o>[[</span><span class=s>"elapsed"</span><span class=o>]</span><span class=o>]</span>
  <span class=o>)</span>
<span class=o>&#125;</span>

<span class=c># setup engine and n_samples combinations</span>
<span class=nv>engines</span> <span class=o>&lt;-</span> <span class=nf><a href=https://rdrr.io/r/base/rep.html>rep</a></span><span class=o>(</span><span class=nf><a href=https://rdrr.io/r/base/c.html>c</a></span><span class=o>(</span>XGBoost <span class=o>=</span> <span class=s>"xgboost"</span>, LightGBM <span class=o>=</span> <span class=s>"lightgbm"</span><span class=o>)</span>, each <span class=o>=</span> <span class=m>11</span><span class=o>)</span>
<span class=nv>n_samples</span> <span class=o>&lt;-</span> <span class=nf><a href=https://rdrr.io/r/base/Round.html>round</a></span><span class=o>(</span><span class=nf><a href=https://rdrr.io/r/base/rep.html>rep</a></span><span class=o>(</span><span class=m>10</span> <span class=o>*</span> <span class=m>10</span><span class=o>^</span><span class=o>(</span><span class=nf><a href=https://rdrr.io/r/base/seq.html>seq</a></span><span class=o>(</span><span class=m>2</span>, <span class=m>4.5</span>, <span class=m>.25</span><span class=o>)</span><span class=o>)</span>, times  <span class=o>=</span> <span class=m>2</span><span class=o>)</span><span class=o>)</span>

<span class=c># apply the function over each combination</span>
<span class=nv>fit_times</span> <span class=o>&lt;-</span> 
  <span class=nf>map2_dfr</span><span class=o>(</span>
    <span class=nv>engines</span>,
    <span class=nv>n_samples</span>,
    <span class=nv>time_boost_fit</span>
  <span class=o>)</span> <span class=o><a href=https://magrittr.tidyverse.org/reference/pipe.html>%&gt;%</a></span>
  <span class=nf>mutate</span><span class=o>(</span>
    engine <span class=o>=</span> <span class=nf><a href=https://rdrr.io/r/base/factor.html>factor</a></span><span class=o>(</span><span class=nv>engine</span>, levels <span class=o>=</span> <span class=nf><a href=https://rdrr.io/r/base/c.html>c</a></span><span class=o>(</span><span class=s>"xgboost"</span>, <span class=s>"lightgbm"</span><span class=o>)</span><span class=o>)</span>
  <span class=o>)</span>

<span class=c># visualize results</span>
<span class=nf>ggplot</span><span class=o>(</span><span class=nv>fit_times</span><span class=o>)</span> <span class=o>+</span>
  <span class=nf>aes</span><span class=o>(</span>x <span class=o>=</span> <span class=nv>n</span>, y <span class=o>=</span> <span class=nv>time_to_fit</span>, col <span class=o>=</span> <span class=nv>engine</span><span class=o>)</span> <span class=o>+</span>
  <span class=nf>geom_line</span><span class=o>(</span><span class=o>)</span> <span class=o>+</span>
  <span class=nf>scale_x_log10</span><span class=o>(</span><span class=o>)</span>
</code></pre><p><img src=figs/boost-comparison-1.png width=700px style=display:block;margin:auto></p></div><p>As we can see, the decrease in time-to-fit when using LightGBM as opposed to XGBoost becomes more notable as the number of rows in the training data increases.</p><p>Read more about this implementation of boosted trees in
<a href=https://parsnip.tidymodels.org/reference/details_boost_tree_lightgbm.html target=_blank rel=noopener><code>?details_boost_tree_lightgbm</code></a>.</p><h2 id=other-notes>Other Notes
<a href=#other-notes><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>This package is based off of
<a href=https://github.com/curso-r/treesnip target=_blank rel=noopener>the treesnip package</a> by Daniel Falbel, Athos Damiani, and Roel M. Hogervorst. Users of that package will note that we have not included support for
<a href=https://github.com/catboost/catboost target=_blank rel=noopener>the catboost package</a>. Unfortunately, the catboost R package is not on CRAN, so we&rsquo;re not able to add support for the package for now. We&rsquo;ll be keeping an eye on discussions in that development community and plan to support the package upon its release to CRAN!</p><p>Each of these model specs and engines have several arguments and tuning parameters that affect user experience and results greatly. We recommend reading about each of these parameters and tuning them when you find them relevant for your modeling use case.</p><h2 id=acknowledgements>Acknowledgements
<a href=#acknowledgements><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>A big thanks to Daniel Falbel, Athos Damiani, and Roel M. Hogervorst for their work on
<a href=https://github.com/curso-r/treesnip target=_blank rel=noopener>the treesnip package</a>, on which this package is based. We&rsquo;ve listed the treesnip authors as co-authors of bonsai in recognition of their help in laying the foundations for this project.</p><p>We&rsquo;re also grateful for the wonderful package hex sticker by Amanda Petri!</p><p>Finally, thank you to those who have tested and provided feedback on the developmental versions of the package over the last couple months.</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>For those interested, the
<a href=https://doi.org/10.1198/106186006X133933 target=_blank rel=noopener>original paper</a> introducing conditional inference trees describes and motivates these differences well. <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div></div><div class=column25><div class="section hideOnMobile"><div class=sectionTitle>Contents</div><nav id=TableOfContents><ul><li><a href=#decision-trees>Decision Trees</a></li><li><a href=#random-forests>Random Forests</a></li><li><a href=#boosted-trees>Boosted Trees</a></li><li><a href=#other-notes>Other Notes</a></li><li><a href=#acknowledgements>Acknowledgements</a></li></ul></nav></div><div class=section></div></div></div></div></div><div id=rStudioFooter class=band><div class=bandContent><div id=copyright>The tidyverse is proudly supported by <a class=rstudioLogo href=https://posit.co/ aria-label="Posit Homepage"></a></div><div id=logos><a href=https://www.tidyverse.org/google_privacy_policy>Privacy policy</a>
<a href=https://github.com/tidyverse class="footerLogo gitHub" aria-label="Tidyverse GitHub organization"></a><a href=https://twitter.com/hashtag/rstats class="footerLogo twitter" aria-label="rstats hashtag on twitter.com"></a></div></div></div></div></div><script src=/js/math-code.js></script><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script><script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type=application/javascript>var dnt=(navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack);var doNotTrack=(dnt=="1"||dnt=="yes");if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');if(window.sessionStorage){var GA_SESSION_STORAGE_KEY='ga:clientId';ga('create','UA-115082821-1',{'storage':'none','clientId':sessionStorage.getItem(GA_SESSION_STORAGE_KEY)});ga(function(tracker){sessionStorage.setItem(GA_SESSION_STORAGE_KEY,tracker.get('clientId'));});}
ga('set','anonymizeIp',true);ga('send','pageview');}</script></body></html></div></div></body></html>