<!doctype html><html><head><!doctype html><html lang=en-us><link rel=stylesheet href=/css/fonts.css><link rel=stylesheet href=/css/main-site.css><link rel=stylesheet href=/css/fa5-all.css><style type=text/css>body{background-color:#fff;color:#1a1917}a{color:#38577f}a:hover{color:#42709b}a:focus{outline-color:#42709b}.column25-left .sectionTitle a:hover:not(.current),.column16-left .sectionTitle a:hover:not(.current){color:#1a1917}.icon-attribution,.icon-attribution a{color:#1a1917;opacity:75%}#homeContent .band.first{background-color:#fff}#homeContent .band.second{background-color:#fdeba4}#homeContent .band.third{background-color:#fff}#rStudioHeader{background-color:#1a162d;color:#fff}#rStudioHeader .productName{color:#fff}#rStudioHeader .productName:hover,#rStudioHeader .productName:focus{color:#fdeba4}#rStudioHeader #menu .menuItem.a{background-color:#75aadb;color:#fff}#rStudioHeader #menu .menuItem:hover{background-color:#484557;color:#fff}#rStudioHeader #menu .menuItem.current{background-color:#fff;color:#1a162d;text-decoration:none}#rStudioFooter.band{background-color:#767381}#rStudioFooter .bandContent #copyright{color:#e3eef8}table tbody tr:nth-child(even){background-color:#f7faff}table tbody tr:nth-child(odd){background-color:#fff}.latest{border-top:.5em solid <no value>}.event{-moz-box-shadow:0 0 0 0 rgba(0,0,0,.1);-webkit-box-shadow:0 0 0 0 rgba(0,0,0,.1);box-shadow:0 0 0 0 rgba(0,0,0,.1)}.section .event{background-color:#eab0c41a}.section .event{border-top:7pt solid #a19ea936}.section .event a{color:#1a162d}.section .event{color:#404040}</style><link rel=stylesheet href=/css/tidyverse.css><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo 0.71.1"><title>Improved sparsity support in tidymodels</title><meta property="og:title" content="Improved sparsity support in tidymodels"><meta property="og:description" content="The tidymodels ecosystem now fully supports sparse data as input, output, and in creation."><meta property="og:type" content="article"><meta property="og:url" content="https://www.tidyverse.org/blog/2025/03/tidymodels-sparsity/"><meta property="twitter:card" content="summary_large_image"><meta property="og:title" content="Improved sparsity support in tidymodels - Tidyverse"><meta property="description" content="The tidymodels ecosystem now fully supports sparse data as input, output, and in creation."><meta property="og:description" content="The tidymodels ecosystem now fully supports sparse data as input, output, and in creation."><meta property="og:image" content="https://www.tidyverse.org/blog/2025/03/tidymodels-sparsity/thumbnail-sq.jpg"><meta name=twitter:image content="https://www.tidyverse.org/blog/2025/03/tidymodels-sparsity/thumbnail-wd.jpg"><link rel=apple-touch-icon sizes=180x180 href=/images/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/images/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/images/favicons/favicon-16x16.png><link rel=manifest href=/images/favicons/site.webmanifest><link rel=mask-icon href=/images/favicons/safari-pinned-tab.svg><link rel="shortcut icon" href=/images/favicons/favicon.ico><meta name=msapplication-TileColor content="#da532c"><meta name=msapplication-config href=/images/favicons/browserconfig.xml><script type=text/javascript src=/js/jquery-3.5.1.min.js></script><script type=text/javascript src=/js/site.js></script><link rel=icon href=/images/favicon.ico><script type=text/javascript src=/js/clipboard.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin=anonymous></script><script defer data-domain=tidyverse.org,all.tidyverse.org src=https://plausible.io/js/plausible.js></script></head><body><div id=appTidyverseSite class="shrinkHeader alwaysShrinkHeader"><div id=main><div id=rStudioHeader><nav class=band><div class="innards bandContent"><div><a class=productName href=/%20/>Tidyverse</a></div><div id=menu><div id=menuToggler></div><div id=menuItems><a class=menuItem href=/packages/>Packages</a>
<a class="menuItem current" href=/blog/>Blog</a>
<a class=menuItem href=/learn/>Learn</a>
<a class=menuItem href=/help/>Help</a>
<a class=menuItem href=/contribute/>Contribute</a></div></div></div></nav></div><main><div class="band padForHeader pushFooter"><div class=bandContent><div class="full splitColumns withMobileMargins"><div class=column75><h1 class=article-title>Improved sparsity support in tidymodels</h1><div class=article-header aria-hidden=true><div class=photo><img src=/blog/2025/03/tidymodels-sparsity/thumbnail-wd.jpg></div><div class=photoCredit>Photo by <a href=https://unsplash.com/photos/green-tree-in-the-middle-of-grass-field-KD8nzFznQQ0>Oliver Olah</a></div></div><span class=article-date><i class="fas fa-calendar-day fa-fw"></i>&nbsp;&nbsp;2025/03/19</span><p style=margin-bottom:.5em;margin-top:.85em><i class="fas fa-tags"></i>&nbsp;
<a href=/tags/recipes/>recipes</a>,
<a href=/tags/tidymodels/>tidymodels</a>,
<a href=/tags/parsnip/>parsnip</a>,
<a href=/tags/workflows/>workflows</a></p><p style=margin-top:.5em><i class="fas fa-user-circle fa-fw"></i>&nbsp;
Emil Hvitfeldt</p><div class=article-content><p>Photo by <a href="https://unsplash.com/@oxygenvisuals?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Oliver Olah</a> on <a href="https://unsplash.com/photos/green-tree-in-the-middle-of-grass-field-KD8nzFznQQ0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a></p><p>We&rsquo;re stoked to announce tidymodels now fully supports sparse data from end to end. We have been working on this for
<a href=https://github.com/tidymodels/recipes/pull/515 target=_blank rel=noopener>over 5 years</a>. This is an extension of the work we have done
<a href=https://www.tidyverse.org/blog/2020/11/tidymodels-sparse-support/ target=_blank rel=noopener>previously</a> with blueprints, which would carry the data sparsely some of the way.</p><p>You will need
<a href=https://recipes.tidymodels.org/news/index.html#recipes-120 target=_blank rel=noopener>recipes 1.2.0</a>,
<a href=https://parsnip.tidymodels.org/news/index.html#parsnip-130 target=_blank rel=noopener>parsnip 1.3.0</a>,
<a href=https://workflows.tidymodels.org/news/index.html#workflows-120 target=_blank rel=noopener>workflows 1.2.0</a> or later for this to work.</p><h2 id=what-are-sparse-data>What are sparse data?
<a href=#what-are-sparse-data><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>The term <strong>sparse data</strong> refers to a data set containing many zeroes. Sparse data appears in all kinds of fields and can be produced in a number of preprocessing methods. The reason why we care about sparse data is because of how computers store numbers. A 32-bit integer value takes 4 bytes to store. An array of 32-bit integers takes 40 bytes, and so on. This happens because each value is written down.</p><p>A sparse representation instead stores the locations and values of the non-zero entries. Suppose we have the following vector with 20 entries:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>1</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>3</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>7</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>)</span>
</code></pre></div><p>It could be represented sparsely using the 3 values <code>positions = c(1, 3, 7)</code>, <code>values = c(3, 5, 8)</code>, and <code>length = 20</code>. Now, we have seven values to represent a vector of 20 elements. Since some modeling tasks contain even sparser data, this type of representation starts to show real benefits in terms of execution time and memory consumption.</p><p>The tidymodels set of packages has undergone several internal changes to allow it to represent data sparsely internally when it would be beneficial. These changes allow you to fit models that contain sparse data faster and more memory efficiently than before. Moreover, it allows you to fit models previously not possible due to them not fitting in memory.</p><h2 id=sparse-matrix-support>Sparse matrix support
<a href=#sparse-matrix-support><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>The first benefit of these changes is that <code>recipe()</code>, <code>prep()</code>, <code>bake()</code>, <code>fit()</code>, and
<a href=https://rdrr.io/r/stats/predict.html target=_blank rel=noopener><code>predict()</code></a> now accept sparse matrices created using the Matrix package.</p><p>The <code>permeability_qsar</code> data set from the modeldata package contains quite a lot of zeroes in the predictors, so we will use it as a demonstration. Starting by coercing it into a sparse matrix.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span><span class=kr><a href=https://rdrr.io/r/base/library.html>library</a></span><span class=o>(</span><span class=nv><a href=https://tidymodels.tidymodels.org>tidymodels</a></span><span class=o>)</span></span>
<span><span class=kr><a href=https://rdrr.io/r/base/library.html>library</a></span><span class=o>(</span><span class=nv><a href=https://Matrix.R-forge.R-project.org>Matrix</a></span><span class=o>)</span></span>
<span><span class=nv>permeability_sparse</span> <span class=o>&lt;-</span> <span class=nf><a href=https://rdrr.io/r/methods/as.html>as</a></span><span class=o>(</span><span class=nf><a href=https://rdrr.io/r/base/matrix.html>as.matrix</a></span><span class=o>(</span><span class=nv>permeability_qsar</span><span class=o>)</span>, <span class=s>"sparseMatrix"</span><span class=o>)</span></span></code></pre></div><p>We can now use this sparse matrix in our code the same way as a dense matrix or data frame:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span><span class=nv>rec_spec</span> <span class=o>&lt;-</span> <span class=nf>recipe</span><span class=o>(</span><span class=nv>permeability</span> <span class=o>~</span> <span class=nv>.</span>, data <span class=o>=</span> <span class=nv>permeability_sparse</span><span class=o>)</span> <span class=o>|&gt;</span></span>
<span>  <span class=nf>step_zv</span><span class=o>(</span><span class=nf>all_predictors</span><span class=o>(</span><span class=o>)</span><span class=o>)</span></span>
<span></span>
<span><span class=nv>mod_spec</span> <span class=o>&lt;-</span> <span class=nf>boost_tree</span><span class=o>(</span><span class=s>"regression"</span>, <span class=s>"xgboost"</span><span class=o>)</span></span>
<span></span>
<span><span class=nv>wf_spec</span> <span class=o>&lt;-</span> <span class=nf>workflow</span><span class=o>(</span><span class=nv>rec_spec</span>, <span class=nv>mod_spec</span><span class=o>)</span></span></code></pre></div><p>Model training has the usual syntax:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span><span class=nv>wf_fit</span> <span class=o>&lt;-</span> <span class=nf>fit</span><span class=o>(</span><span class=nv>wf_spec</span>, <span class=nv>permeability_sparse</span><span class=o>)</span></span></code></pre></div><p>as does prediction:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span><span class=nf><a href=https://rdrr.io/r/stats/predict.html>predict</a></span><span class=o>(</span><span class=nv>wf_fit</span>, <span class=nv>permeability_sparse</span><span class=o>)</span></span>
<span><span class=c>#&gt; <span style=color:#555># A tibble: 165 × 1</span></span></span>
<span><span class=c>#&gt;     .pred</span></span>
<span><span class=c>#&gt;     <span style=color:#555;font-style:italic>&lt;dbl&gt;</span></span></span>
<span><span class=c>#&gt; <span style=color:#555> 1</span> 10.5  </span></span>
<span><span class=c>#&gt; <span style=color:#555> 2</span>  1.50 </span></span>
<span><span class=c>#&gt; <span style=color:#555> 3</span> 13.1  </span></span>
<span><span class=c>#&gt; <span style=color:#555> 4</span>  1.10 </span></span>
<span><span class=c>#&gt; <span style=color:#555> 5</span>  1.25 </span></span>
<span><span class=c>#&gt; <span style=color:#555> 6</span>  0.738</span></span>
<span><span class=c>#&gt; <span style=color:#555> 7</span> 29.3  </span></span>
<span><span class=c>#&gt; <span style=color:#555> 8</span>  2.44 </span></span>
<span><span class=c>#&gt; <span style=color:#555> 9</span> 36.3  </span></span>
<span><span class=c>#&gt; <span style=color:#555>10</span>  4.31 </span></span>
<span><span class=c>#&gt; <span style=color:#555># ℹ 155 more rows</span></span></span>
<span></span></code></pre></div><p>Note that only some models/engines work well with sparse data. These are all listed here <a href=https://www.tidymodels.org/find/sparse/>https://www.tidymodels.org/find/sparse/</a>. If the model doesn&rsquo;t support sparse data, it will be coerced into the default non-sparse representation and used as usual.</p><p>With a few exceptions, it should work like any other data set. However, this approach has two main limitations. The first is that we are limited to regression tasks since the outcome has to be numeric to be part of the sparse matrix.</p><p>The second limitation is that it only works with non-formula methods for parsnip and workflows. This means that you can use a recipe with <code>add_recipe()</code> or select variables directly with <code>add_variables()</code> when using a workflow. And you need to use <code>fit_xy()</code> instead of <code>fit()</code> when using a parsnip object by itself.</p><p>If this is of interest we also have a <a href=https://www.tidymodels.org/>https://www.tidymodels.org/</a> post about
<a href=https://www.tidymodels.org/learn/work/sparse-matrix/ target=_blank rel=noopener>using sparse matrices in tidymodels</a>.</p><h2 id=sparse-data-from-recipes-steps>Sparse data from recipes steps
<a href=#sparse-data-from-recipes-steps><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>Where this sparsity support really starts to shine is when the recipe we use will generate sparse data. They come in two flavors, sparsity creation steps and sparsity preserving steps. Both listed here: <a href=https://www.tidymodels.org/find/sparse/>https://www.tidymodels.org/find/sparse/</a>.</p><p>Some steps like <code>step_dummy()</code>, <code>step_indicate_na()</code>, and
<a href=https://textrecipes.tidymodels.org/reference/step_tf.html target=_blank rel=noopener><code>textrecipes::step_tf()</code></a> will almost always produce a lot of zeroes. We take advantage of that by generating it sparsely when it is beneficial. If these steps end up producing sparse vectors, we want to make sure the sparsity is preserved. A couple of handfuls of steps, such as <code>step_impute_mean()</code> and <code>step_scale(),</code> have been updated to be able to work efficiently with sparse vectors. Both types of steps are detailed in the above-linked list of compatible methods.</p><p>What this means in practice is that if you use a model/engine that supports sparse data and have a recipe that produces enough sparse data, then the steps will switch to produce sparse data by using a new sparse data format to store the data (when appropriate) as the recipe is being processed. Then if the model can accept sparse objects, we convert the data from our new sparse format to a standard sparse matrix object. Increasing performance when possible while preserving performance otherwise.</p><p>Below is a simple recipe using the <code>ames</code> data set. <code>step_dummy()</code> is applied to all the categorical predictors, leading to a significant amount of zeroes.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span><span class=nv>rec_spec</span> <span class=o>&lt;-</span> <span class=nf>recipe</span><span class=o>(</span><span class=nv>Sale_Price</span> <span class=o>~</span> <span class=nv>.</span>, data <span class=o>=</span> <span class=nv>ames</span><span class=o>)</span> <span class=o>|&gt;</span></span>
<span>  <span class=nf>step_zv</span><span class=o>(</span><span class=nf>all_predictors</span><span class=o>(</span><span class=o>)</span><span class=o>)</span> <span class=o>|&gt;</span></span>
<span>  <span class=nf>step_normalize</span><span class=o>(</span><span class=nf>all_numeric_predictors</span><span class=o>(</span><span class=o>)</span><span class=o>)</span> <span class=o>|&gt;</span></span>
<span>  <span class=nf>step_dummy</span><span class=o>(</span><span class=nf>all_nominal_predictors</span><span class=o>(</span><span class=o>)</span><span class=o>)</span></span>
<span></span>
<span><span class=nv>mod_spec</span> <span class=o>&lt;-</span> <span class=nf>boost_tree</span><span class=o>(</span><span class=s>"regression"</span>, <span class=s>"xgboost"</span><span class=o>)</span></span>
<span></span>
<span><span class=nv>wf_spec</span> <span class=o>&lt;-</span> <span class=nf>workflow</span><span class=o>(</span><span class=nv>rec_spec</span>, <span class=nv>mod_spec</span><span class=o>)</span></span></code></pre></div><p>When we go to fit it now, it takes around 125ms and allocates 37.2MB. Compared to before these changes it would take around 335ms and allocate 67.5MB.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span><span class=nv>wf_fit</span> <span class=o>&lt;-</span> <span class=nf>fit</span><span class=o>(</span><span class=nv>wf_spec</span>, <span class=nv>ames</span><span class=o>)</span></span></code></pre></div><p>We see similar speedups when we predictor with around 20ms and 25.2MB now, compared to around 60ms and 55.6MB before.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span><span class=nf><a href=https://rdrr.io/r/stats/predict.html>predict</a></span><span class=o>(</span><span class=nv>wf_fit</span>, <span class=nv>ames</span><span class=o>)</span></span>
<span><span class=c>#&gt; <span style=color:#555># A tibble: 2,930 × 1</span></span></span>
<span><span class=c>#&gt;      .pred</span></span>
<span><span class=c>#&gt;      <span style=color:#555;font-style:italic>&lt;dbl&gt;</span></span></span>
<span><span class=c>#&gt; <span style=color:#555> 1</span> <span style=text-decoration:underline>208</span>649.</span></span>
<span><span class=c>#&gt; <span style=color:#555> 2</span> <span style=text-decoration:underline>115</span>339.</span></span>
<span><span class=c>#&gt; <span style=color:#555> 3</span> <span style=text-decoration:underline>148</span>634.</span></span>
<span><span class=c>#&gt; <span style=color:#555> 4</span> <span style=text-decoration:underline>239</span>770.</span></span>
<span><span class=c>#&gt; <span style=color:#555> 5</span> <span style=text-decoration:underline>190</span>082.</span></span>
<span><span class=c>#&gt; <span style=color:#555> 6</span> <span style=text-decoration:underline>184</span>604.</span></span>
<span><span class=c>#&gt; <span style=color:#555> 7</span> <span style=text-decoration:underline>208</span>572.</span></span>
<span><span class=c>#&gt; <span style=color:#555> 8</span> <span style=text-decoration:underline>177</span>403 </span></span>
<span><span class=c>#&gt; <span style=color:#555> 9</span> <span style=text-decoration:underline>261</span>000.</span></span>
<span><span class=c>#&gt; <span style=color:#555>10</span> <span style=text-decoration:underline>198</span>604.</span></span>
<span><span class=c>#&gt; <span style=color:#555># ℹ 2,920 more rows</span></span></span>
<span></span></code></pre></div><p>These improvements are tightly related to memory allocation, which depends on the sparsity of the data set produced by the recipe. This is why it is hard to say how much benefit you will see. We have seen orders of magnitudes of improvements, both in terms of time and memory allocation. We have also been able to fit models where previously the data was too big to fit in memory.</p><p>Please see the post on tidymodels.org, which goes into more detail about when you are likely to benefit from this and how to change your recipes and workflows to take full advantage of this new feature.</p><p>There is also a <a href=https://www.tidymodels.org/>https://www.tidymodels.org/</a> post going into a bit more detail about how to
<a href=https://www.tidymodels.org/learn/work/sparse-recipe/ target=_blank rel=noopener>use recipes to produce sparse data</a>.</p></div></div><div class=column25><div class="section hideOnMobile"><div class=sectionTitle>Contents</div><nav id=TableOfContents><ul><li><a href=#what-are-sparse-data>What are sparse data?</a></li><li><a href=#sparse-matrix-support>Sparse matrix support</a></li><li><a href=#sparse-data-from-recipes-steps>Sparse data from recipes steps</a></li></ul></nav></div><div class=section></div></div></div></div></div><div id=rStudioFooter class=band><div class=bandContent><div id=copyright>The tidyverse is proudly supported by <a class=rstudioLogo href=https://posit.co/ aria-label="Posit Homepage"></a></div><div id=logos><a href=https://www.tidyverse.org/google_privacy_policy>Privacy policy</a>
<a href=https://github.com/tidyverse class="footerLogo gitHub" aria-label="Tidyverse GitHub organization"></a><a href=https://twitter.com/hashtag/rstats class="footerLogo twitter" aria-label="rstats hashtag on twitter.com"></a></div></div></div></div></div><script type=application/javascript>var dnt=(navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack);var doNotTrack=(dnt=="1"||dnt=="yes");if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');if(window.sessionStorage){var GA_SESSION_STORAGE_KEY='ga:clientId';ga('create','UA-115082821-1',{'storage':'none','clientId':sessionStorage.getItem(GA_SESSION_STORAGE_KEY)});ga(function(tracker){sessionStorage.setItem(GA_SESSION_STORAGE_KEY,tracker.get('clientId'));});}
ga('set','anonymizeIp',true);ga('send','pageview');}</script></body></html></div></div></body></html>