<!doctype html><html><head><!doctype html><html lang=en-us><link rel=stylesheet href=/css/fonts.css><link rel=stylesheet href=/css/main-site.css><link rel=stylesheet href=/css/fa5-all.css><style type=text/css>body{background-color:#fff;color:#1a1917}a{color:#38577f}a:hover{color:#42709b}a:focus{outline-color:#42709b}.column25-left .sectionTitle a:hover:not(.current),.column16-left .sectionTitle a:hover:not(.current){color:#1a1917}.icon-attribution,.icon-attribution a{color:#1a1917;opacity:75%}#homeContent .band.first{background-color:#fff}#homeContent .band.second{background-color:#fdeba4}#homeContent .band.third{background-color:#fff}#rStudioHeader{background-color:#1a162d;color:#fff}#rStudioHeader .productName{color:#fff}#rStudioHeader .productName:hover,#rStudioHeader .productName:focus{color:#fdeba4}#rStudioHeader #menu .menuItem.a{background-color:#75aadb;color:#fff}#rStudioHeader #menu .menuItem:hover{background-color:#484557;color:#fff}#rStudioHeader #menu .menuItem.current{background-color:#fff;color:#1a162d;text-decoration:none}#rStudioFooter.band{background-color:#767381}#rStudioFooter .bandContent #copyright{color:#e3eef8}table tbody tr:nth-child(even){background-color:#f7faff}table tbody tr:nth-child(odd){background-color:#fff}.latest{border-top:.5em solid <no value>}.event{-moz-box-shadow:0 0 0 0 rgba(0,0,0,.1);-webkit-box-shadow:0 0 0 0 rgba(0,0,0,.1);box-shadow:0 0 0 0 rgba(0,0,0,.1)}.section .event{background-color:#eab0c41a}.section .event{border-top:7pt solid #a19ea936}.section .event a{color:#1a162d}.section .event{color:#404040}</style><link rel=stylesheet href=/css/tidyverse.css><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo 0.71.1"><title>Parallel processing in purrr 1.1.0</title><meta property="og:title" content="Parallel processing in purrr 1.1.0"><meta property="og:description" content="The functional programming toolkit for R gains new capabilities for parallel processing and distributed computing using mirai."><meta property="og:type" content="article"><meta property="og:url" content="https://www.tidyverse.org/blog/2025/07/purrr-1-1-0-parallel/"><meta property="twitter:card" content="summary_large_image"><meta property="og:title" content="Parallel processing in purrr 1.1.0 - Tidyverse"><meta property="description" content="The functional programming toolkit for R gains new capabilities for parallel processing and distributed computing using mirai."><meta property="og:description" content="The functional programming toolkit for R gains new capabilities for parallel processing and distributed computing using mirai."><meta property="og:image" content="https://www.tidyverse.org/blog/2025/07/purrr-1-1-0-parallel/thumbnail-sq.jpg"><meta name=twitter:image content="https://www.tidyverse.org/blog/2025/07/purrr-1-1-0-parallel/thumbnail-wd.jpg"><link rel=apple-touch-icon sizes=180x180 href=/images/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/images/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/images/favicons/favicon-16x16.png><link rel=manifest href=/images/favicons/site.webmanifest><link rel=mask-icon href=/images/favicons/safari-pinned-tab.svg><link rel="shortcut icon" href=/images/favicons/favicon.ico><meta name=msapplication-TileColor content="#da532c"><meta name=msapplication-config href=/images/favicons/browserconfig.xml><script type=text/javascript src=/js/jquery-3.5.1.min.js></script><script type=text/javascript src=/js/site.js></script><link rel=icon href=/images/favicon.ico><script type=text/javascript src=/js/clipboard.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin=anonymous></script><script defer data-domain=tidyverse.org,all.tidyverse.org src=https://plausible.io/js/plausible.js></script></head><body><div id=appTidyverseSite class="shrinkHeader alwaysShrinkHeader"><div id=main><div id=rStudioHeader><nav class=band><div class="innards bandContent"><div><a class=productName href=/>Tidyverse</a></div><div id=menu><div id=menuToggler></div><div id=menuItems><a class=menuItem href=/packages/>Packages</a>
<a class="menuItem current" href=/blog/>Blog</a>
<a class=menuItem href=/learn/>Learn</a>
<a class=menuItem href=/help/>Help</a>
<a class=menuItem href=/contribute/>Contribute</a></div></div></div></nav></div><main><div class="band padForHeader pushFooter"><div class=bandContent><div class="full splitColumns withMobileMargins"><div class=column75><h1 class=article-title>Parallel processing in purrr 1.1.0</h1><div class=article-header aria-hidden=true><div class=photo><img src=/blog/2025/07/purrr-1-1-0-parallel/thumbnail-wd.jpg></div><div class=photoCredit>Photo by <a href=https://unsplash.com/photos/chart-bar-chart-14XDMqDmCq0>Martin Woortman</a></div></div><span class=article-date><i class="fas fa-calendar-day fa-fw"></i>&nbsp;&nbsp;2025/07/10</span><p style=margin-bottom:.5em;margin-top:.85em><i class="fas fa-tags"></i>&nbsp;
<a href=/tags/purrr/>purrr</a>,
<a href=/tags/parallelism/>parallelism</a></p><p style=margin-top:.5em><i class="fas fa-user-circle fa-fw"></i>&nbsp;
Charlie Gao, Hadley Wickham, Davis Vaughan and Lionel Henry</p><div class=article-content><p>We&rsquo;re thrilled to announce the release of
<a href=https://purrr.tidyverse.org target=_blank rel=noopener>purrr</a> 1.1.0, bringing a game-changing feature to this cornerstone of the tidyverse: <strong>parallel processing</strong>.</p><p>For the first time in purrr&rsquo;s history, you can now scale your <code>map()</code> operations across multiple cores and even distributed systems, all while maintaining the elegant, functional programming style you know and love.</p><p>This milestone represents more than just a performance boost&mdash;it&rsquo;s a fundamental shift that makes purrr suitable for production-scale data processing tasks without sacrificing the clarity and composability that make it such a joy to use.</p><p>Get started by installing purrr 1.1.0 today:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>install.packages</span><span class=p>(</span><span class=s>&#34;purrr&#34;</span><span class=p>)</span>
</code></pre></div><p>The parallel processing functionality requires the mirai and carrier packages. You will be prompted to install them when you first call <code>in_parallel()</code>.</p><p>Ready to supercharge your functional programming workflows? Parallel purrr is here, and it&rsquo;s remarkably simple to use.</p><h2 id=the-power-of-in_parallel>The power of <code>in_parallel()</code>
<a href=#the-power-of-in_parallel><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>The magic happens through a shiny new function: <code>in_parallel()</code>. This purrr adverb wraps your functions to signal that they should run in parallel, powered by the venerable
<a href=https://mirai.r-lib.org/ target=_blank rel=noopener>mirai</a> package.</p><p>Here&rsquo;s how simple it is to transform your sequential operations:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>library</span><span class=p>(</span><span class=n>purrr</span><span class=p>)</span>
<span class=nf>library</span><span class=p>(</span><span class=n>mirai</span><span class=p>)</span>

<span class=c1># Set up parallel processing (6 background processes)</span>
<span class=nf>daemons</span><span class=p>(</span><span class=m>6</span><span class=p>)</span>

<span class=c1># Sequential version</span>
<span class=n>mtcars</span> <span class=o>|&gt;</span> <span class=nf>map_dbl</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=nf>mean</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
<span class=c1>#&gt;    mpg    cyl   disp     hp   drat     wt   qsec     vs     am   gear   carb </span>
<span class=c1>#&gt;  20.09   6.19 230.72 146.69   3.60   3.22  17.85   0.44   0.41   3.69   2.81</span>

<span class=c1># Parallel version - just wrap your function with in_parallel()</span>
<span class=n>mtcars</span> <span class=o>|&gt;</span> <span class=nf>map_dbl</span><span class=p>(</span><span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=nf>mean</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
<span class=c1>#&gt;    mpg    cyl   disp     hp   drat     wt   qsec     vs     am   gear   carb </span>
<span class=c1>#&gt;  20.09   6.19 230.72 146.69   3.60   3.22  17.85   0.44   0.41   3.69   2.81</span>

<span class=c1># Don&#39;t forget to clean up when done</span>
<span class=nf>daemons</span><span class=p>(</span><span class=m>0</span><span class=p>)</span>
</code></pre></div><p>The results are identical, but the second version distributes the work across multiple CPU cores. For computationally intensive tasks, the performance gains can be dramatic.</p><p>The beauty of using an adverb is that <code>in_parallel()</code> works not just with <code>map()</code>, but across the entire purrr ecosystem:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>daemons</span><span class=p>(</span><span class=m>6</span><span class=p>,</span> <span class=n>output</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>)</span>

<span class=c1># Works with all map variants</span>
<span class=m>1</span><span class=o>:</span><span class=m>4</span> <span class=o>|&gt;</span> <span class=nf>map_int</span><span class=p>(</span><span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=n>x^2</span><span class=p>))</span>
<span class=m>1</span><span class=o>:</span><span class=m>4</span> <span class=o>|&gt;</span> <span class=nf>map_chr</span><span class=p>(</span><span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=nf>paste</span><span class=p>(</span><span class=s>&#34;Number&#34;</span><span class=p>,</span> <span class=n>x</span><span class=p>)))</span>

<span class=c1># Works with map2 and pmap</span>
<span class=nf>map2_dbl</span><span class=p>(</span><span class=m>1</span><span class=o>:</span><span class=m>3</span><span class=p>,</span> <span class=m>4</span><span class=o>:</span><span class=m>6</span><span class=p>,</span> <span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span> <span class=n>x</span> <span class=o>+</span> <span class=n>y</span><span class=p>))</span>

<span class=nf>list</span><span class=p>(</span><span class=n>a</span> <span class=o>=</span> <span class=m>1</span><span class=o>:</span><span class=m>3</span><span class=p>,</span> <span class=n>b</span> <span class=o>=</span> <span class=m>4</span><span class=o>:</span><span class=m>6</span><span class=p>,</span> <span class=n>c</span> <span class=o>=</span> <span class=m>7</span><span class=o>:</span><span class=m>9</span><span class=p>)</span> <span class=o>|&gt;</span>
  <span class=nf>pmap_dbl</span><span class=p>(</span><span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=n>c</span><span class=p>)</span> <span class=nf>mean</span><span class=p>(</span><span class=nf>c</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=n>c</span><span class=p>))))</span>

<span class=c1># Even works with walk for side effects</span>
<span class=m>1</span><span class=o>:</span><span class=m>3</span> <span class=o>|&gt;</span> <span class=nf>walk</span><span class=p>(</span><span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=nf>cat</span><span class=p>(</span><span class=s>&#34;Processing&#34;</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=s>&#34;\n&#34;</span><span class=p>)))</span>

<span class=nf>daemons</span><span class=p>(</span><span class=m>0</span><span class=p>)</span>
</code></pre></div><p>If you use <code>in_parallel()</code> but don&rsquo;t set <code>daemons()</code>, then the map will just proceed sequentially, so you don&rsquo;t need to worry about having two separate code paths for parallel vs non-parallel execution.</p><h2 id=real-world-example-parallel-model-fitting>Real-world example: parallel model fitting
<a href=#real-world-example-parallel-model-fitting><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>Let&rsquo;s look at a more realistic scenario where parallel processing truly shines&mdash;fitting multiple models:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>library</span><span class=p>(</span><span class=n>purrr</span><span class=p>)</span>
<span class=nf>library</span><span class=p>(</span><span class=n>mirai</span><span class=p>)</span>

<span class=c1># Set up 4 parallel processes</span>
<span class=nf>daemons</span><span class=p>(</span><span class=m>4</span><span class=p>)</span>

<span class=c1># Define a slow model fitting function</span>
<span class=n>slow_lm</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>formula</span><span class=p>,</span> <span class=n>data</span><span class=p>)</span> <span class=p>{</span>
  <span class=nf>Sys.sleep</span><span class=p>(</span><span class=m>0.1</span><span class=p>)</span>  <span class=c1># Simulate computational complexity</span>
  <span class=nf>lm</span><span class=p>(</span><span class=n>formula</span><span class=p>,</span> <span class=n>data</span><span class=p>)</span>
<span class=p>}</span>

<span class=c1># Fit models to different subsets of data in parallel</span>
<span class=n>models</span> <span class=o>&lt;-</span> <span class=n>mtcars</span> <span class=o>|&gt;</span>
  <span class=nf>split</span><span class=p>(</span><span class=n>mtcars</span><span class=o>$</span><span class=n>cyl</span><span class=p>)</span> <span class=o>|&gt;</span>
  <span class=nf>map</span><span class=p>(</span><span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>df</span><span class=p>)</span> <span class=nf>slow_lm</span><span class=p>(</span><span class=n>mpg</span> <span class=o>~</span> <span class=n>wt</span> <span class=o>+</span> <span class=n>hp</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=n>df</span><span class=p>),</span> <span class=n>slow_lm</span> <span class=o>=</span> <span class=n>slow_lm</span><span class=p>))</span>

<span class=c1># Extract R-squared values</span>
<span class=n>models</span> <span class=o>|&gt;</span> 
  <span class=nf>map</span><span class=p>(</span><span class=n>summary</span><span class=p>)</span> <span class=o>|&gt;</span> 
  <span class=nf>map_dbl</span><span class=p>(</span><span class=s>&#34;r.squared&#34;</span><span class=p>)</span>
<span class=c1>#&gt;         4         6         8 </span>
<span class=c1>#&gt; 0.6807065 0.5889239 0.4970692</span>

<span class=nf>daemons</span><span class=p>(</span><span class=m>0</span><span class=p>)</span>
</code></pre></div><p>Notice how we pass the <code>slow_lm</code> function as an argument to <code>in_parallel()</code>&mdash;this ensures our custom function is available in the parallel processes.</p><h2 id=production-ready-with-mirai>Production-ready with mirai
<a href=#production-ready-with-mirai><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>The choice of
<a href=https://mirai.r-lib.org target=_blank rel=noopener>mirai</a> as the parallel backend wasn&rsquo;t arbitrary.
<a href=https://mirai.r-lib.org target=_blank rel=noopener>mirai</a> is a production-grade async evaluation framework that brings several key advantages:</p><ul><li><strong>Minimal overhead</strong>: Built on modern networking and concurrency principles</li><li><strong>Reliable scheduling</strong>: Leveraging fast inter-process communications locally</li><li><strong>Scalable architecture</strong>: From multi-process to distributed computing on HPC clusters</li><li><strong>Security</strong>: Offers zero-configuration TLS over TCP for additional assurance</li></ul><p>This means your parallel purrr code isn&rsquo;t just fast&mdash;it&rsquo;s production-ready.</p><p>Compared to the
<a href=https://furrr.futureverse.org target=_blank rel=noopener>furrr</a> package:</p><ul><li>Much lower overhead means you can get a performance boost even for relatively fast functions</li><li>More linear scaling means you get the same benefits whether you&rsquo;re running on 2 or 200 cores</li></ul><p>We&rsquo;ve learned a lot from our work on furrr, and from
<a href=https://github.com/henrikbengtsson target=_blank rel=noopener>Henrik Bengtsson</a>&lsquo;s excellent work on the
<a href=https://github.com/futureverse target=_blank rel=noopener>futureverse</a> ecosystem. purrr doesn&rsquo;t use future as the underlying engine for parallelism because we&rsquo;ve made some design decisions that differ at a fundamental level, but Henrik&rsquo;s entire ecosystem deserves credit for pushing the boundaries of parallelism in R farther than many thought possible.</p><h2 id=creating-self-contained-functions>Creating self-contained functions
<a href=#creating-self-contained-functions><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>One of the key concepts when using <code>in_parallel()</code> is creating self-contained functions. Since your function gets serialized and sent to parallel processes, it needs to be completely standalone:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=c1># ❌ This won&#39;t work - external dependencies not declared</span>
<span class=n>my_data</span> <span class=o>&lt;-</span> <span class=nf>c</span><span class=p>(</span><span class=m>1</span><span class=p>,</span> <span class=m>2</span><span class=p>,</span> <span class=m>3</span><span class=p>)</span>
<span class=nf>map</span><span class=p>(</span><span class=m>1</span><span class=o>:</span><span class=m>3</span><span class=p>,</span> <span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=nf>mean</span><span class=p>(</span><span class=n>my_data</span><span class=p>)))</span>

<span class=c1># ✅ This works - dependencies explicitly provided</span>
<span class=n>my_data</span> <span class=o>&lt;-</span> <span class=nf>c</span><span class=p>(</span><span class=m>1</span><span class=p>,</span> <span class=m>2</span><span class=p>,</span> <span class=m>3</span><span class=p>)</span>
<span class=nf>map</span><span class=p>(</span><span class=m>1</span><span class=o>:</span><span class=m>3</span><span class=p>,</span> <span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=nf>mean</span><span class=p>(</span><span class=n>my_data</span><span class=p>),</span> <span class=n>my_data</span> <span class=o>=</span> <span class=n>my_data</span><span class=p>))</span>

<span class=c1># ✅ Package functions need explicit namespacing</span>
<span class=nf>map</span><span class=p>(</span><span class=m>1</span><span class=o>:</span><span class=m>3</span><span class=p>,</span> <span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=n>vctrs</span><span class=o>::</span><span class=nf>vec_init</span><span class=p>(</span><span class=nf>integer</span><span class=p>(),</span> <span class=n>x</span><span class=p>)))</span>

<span class=c1># ✅ Or load packages within the function</span>
<span class=nf>map</span><span class=p>(</span><span class=m>1</span><span class=o>:</span><span class=m>3</span><span class=p>,</span> <span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=p>{</span>
  <span class=nf>library</span><span class=p>(</span><span class=n>vctrs</span><span class=p>)</span>
  <span class=nf>vec_init</span><span class=p>(</span><span class=nf>integer</span><span class=p>(),</span> <span class=n>x</span><span class=p>)</span>
<span class=p>}))</span>
</code></pre></div><p>This explicit dependency management might seem verbose, but it ensures your parallel code is reliable and predictable&mdash;crucial for production environments.</p><p>It also removes the danger of accidentally shipping large objects to parallel processes&mdash;often a source of performance degradation.</p><h2 id=when-to-use-parallel-processing>When to use parallel processing
<a href=#when-to-use-parallel-processing><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>Not every <code>map()</code> operation benefits from parallelization. The overhead of setting up parallel tasks and communicating between processes can outweigh the benefits for simple operations. As a rule of thumb, consider parallel processing when:</p><ul><li>Each iteration takes at least 100 microseconds to 1 millisecond</li><li>You&rsquo;re performing CPU-intensive computations</li><li>You&rsquo;re working with I/O-bound operations that can benefit from concurrency</li><li>The data being passed between processes isn&rsquo;t excessively large</li></ul><p>For quick operations like simple arithmetic, sequential processing will often be faster.</p><p>If you&rsquo;re a package developer, use <code>in_parallel()</code> where you see fit, but please be mindful not to call <code>daemons()</code> within your package code. How to set mirai daemons should be always be for the end user to decide.</p><h2 id=distributed-computing-made-simple>Distributed computing made simple
<a href=#distributed-computing-made-simple><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>Want to scale beyond your local machine? mirai&rsquo;s networking capabilities make distributed computing surprisingly straightforward:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>library</span><span class=p>(</span><span class=n>mirai</span><span class=p>)</span>

<span class=c1># Set up remote daemons on a Slurm HPC cluster</span>
<span class=nf>daemons</span><span class=p>(</span>
  <span class=n>n</span> <span class=o>=</span> <span class=m>100</span><span class=p>,</span>
  <span class=n>url</span> <span class=o>=</span> <span class=nf>host_url</span><span class=p>(),</span>
  <span class=n>remote</span> <span class=o>=</span> <span class=nf>cluster_config</span><span class=p>(</span><span class=n>command</span> <span class=o>=</span> <span class=s>&#34;sbatch&#34;</span><span class=p>)</span>
<span class=p>)</span>

<span class=c1># Your purrr code remains exactly the same!</span>
<span class=n>results</span> <span class=o>&lt;-</span> <span class=n>big_dataset</span> <span class=o>|&gt;</span>
  <span class=nf>split</span><span class=p>(</span><span class=n>big_dataset</span><span class=o>$</span><span class=n>group</span><span class=p>)</span> <span class=o>|&gt;</span>
  <span class=nf>map</span><span class=p>(</span><span class=nf>in_parallel</span><span class=p>(</span><span class=nf>\</span><span class=p>(</span><span class=n>df</span><span class=p>)</span> <span class=nf>complex_analysis</span><span class=p>(</span><span class=n>df</span><span class=p>),</span> <span class=n>complex_analysis</span> <span class=o>=</span> <span class=n>complex_analysis</span><span class=p>))</span>

<span class=nf>daemons</span><span class=p>(</span><span class=m>0</span><span class=p>)</span>
</code></pre></div><p>The same <code>in_parallel()</code> syntax that works locally scales seamlessly to distributed systems.</p><p>Please refer to the mirai documentation on
<a href=https://mirai.r-lib.org/articles/mirai.html#remote-daemons target=_blank rel=noopener>remote daemons</a> and
<a href=https://mirai.r-lib.org/articles/mirai.html#launching-remote-daemons target=_blank rel=noopener>launching remote daemons</a> for more details. This
<a href=https://shikokuchuo.net/posts/27-mirai-240/ target=_blank rel=noopener>mirai blog post</a> will also be useful if you&rsquo;re working with High-Performance Computing (HPC) clusters.</p><h2 id=looking-forward>Looking forward
<a href=#looking-forward><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>The addition of parallel processing to purrr 1.1.0 represents a significant evolution in the package&rsquo;s capabilities. It maintains purrr&rsquo;s core philosophy of functional programming while opening doors to high-performance computing scenarios that were previously challenging to achieve with such clean, readable code.</p><p>This feature is currently marked as experimental as we gather feedback from the community, but the underlying mirai infrastructure is production-proven and battle-tested. We encourage you to try it out and let us know about your experiences.</p><p>Whether you&rsquo;re processing large datasets, fitting complex models, or running simulations, purrr 1.1.0&rsquo;s parallel processing capabilities can help you scale your R workflows without sacrificing code clarity or reliability.</p><h2 id=acknowledgements>Acknowledgements
<a href=#acknowledgements><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>A big thanks to all those who posted issues and contributed PRs since our last release!
<a href=https://github.com/ar-puuk target=_blank rel=noopener>@ar-puuk</a>,
<a href=https://github.com/DanChaltiel target=_blank rel=noopener>@DanChaltiel</a>,
<a href=https://github.com/davidrsch target=_blank rel=noopener>@davidrsch</a>,
<a href=https://github.com/ErdaradunGaztea target=_blank rel=noopener>@ErdaradunGaztea</a>,
<a href=https://github.com/h-a-graham target=_blank rel=noopener>@h-a-graham</a>,
<a href=https://github.com/hadley target=_blank rel=noopener>@hadley</a>,
<a href=https://github.com/HenningLorenzen-ext-bayer target=_blank rel=noopener>@HenningLorenzen-ext-bayer</a>,
<a href=https://github.com/krivit target=_blank rel=noopener>@krivit</a>,
<a href=https://github.com/MarceloRTonon target=_blank rel=noopener>@MarceloRTonon</a>,
<a href=https://github.com/MarkPaulin target=_blank rel=noopener>@MarkPaulin</a>,
<a href=https://github.com/salim-b target=_blank rel=noopener>@salim-b</a>,
<a href=https://github.com/ScientiaFelis target=_blank rel=noopener>@ScientiaFelis</a>,
<a href=https://github.com/shikokuchuo target=_blank rel=noopener>@shikokuchuo</a>, and
<a href=https://github.com/sierrajohnson target=_blank rel=noopener>@sierrajohnson</a>.</p></div></div><div class=column25><div class="section hideOnMobile"><div class=sectionTitle>Contents</div><nav id=TableOfContents><ul><li><a href=#the-power-of-in_parallel>The power of <code>in_parallel()</code></a></li><li><a href=#real-world-example-parallel-model-fitting>Real-world example: parallel model fitting</a></li><li><a href=#production-ready-with-mirai>Production-ready with mirai</a></li><li><a href=#creating-self-contained-functions>Creating self-contained functions</a></li><li><a href=#when-to-use-parallel-processing>When to use parallel processing</a></li><li><a href=#distributed-computing-made-simple>Distributed computing made simple</a></li><li><a href=#looking-forward>Looking forward</a></li><li><a href=#acknowledgements>Acknowledgements</a></li></ul></nav></div><div class=section></div></div></div></div></div><div id=rStudioFooter class=band><div class=bandContent><div id=copyright>The tidyverse is proudly supported by <a class=rstudioLogo href=https://posit.co/ aria-label="Posit Homepage"></a></div><div id=logos><a href=https://www.tidyverse.org/google_privacy_policy>Privacy policy</a>
<a href=https://github.com/tidyverse class="footerLogo gitHub" aria-label="Tidyverse GitHub organization"></a><a href=https://twitter.com/hashtag/rstats class="footerLogo twitter" aria-label="rstats hashtag on twitter.com"></a></div></div></div></div></div><script src=/js/math-code.js></script><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script><script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type=application/javascript>var dnt=(navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack);var doNotTrack=(dnt=="1"||dnt=="yes");if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');if(window.sessionStorage){var GA_SESSION_STORAGE_KEY='ga:clientId';ga('create','UA-115082821-1',{'storage':'none','clientId':sessionStorage.getItem(GA_SESSION_STORAGE_KEY)});ga(function(tracker){sessionStorage.setItem(GA_SESSION_STORAGE_KEY,tracker.get('clientId'));});}
ga('set','anonymizeIp',true);ga('send','pageview');}</script></body></html></div></div></body></html>