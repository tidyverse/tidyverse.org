<!doctype html><html><head><!doctype html><html lang=en-us><link rel=stylesheet href=/css/fonts.css><link rel=stylesheet href=/css/main-site.css><link rel=stylesheet href=/css/fa5-all.css><style type=text/css>body{background-color:#fff;color:#1a1917}a{color:#38577f}a:hover{color:#42709b}a:focus{outline-color:#42709b}.column25-left .sectionTitle a:hover:not(.current),.column16-left .sectionTitle a:hover:not(.current){color:#1a1917}.icon-attribution,.icon-attribution a{color:#1a1917;opacity:75%}#homeContent .band.first{background-color:#fff}#homeContent .band.second{background-color:#fdeba4}#homeContent .band.third{background-color:#fff}#rStudioHeader{background-color:#1a162d;color:#fff}#rStudioHeader .productName{color:#fff}#rStudioHeader .productName:hover,#rStudioHeader .productName:focus{color:#fdeba4}#rStudioHeader #menu .menuItem.a{background-color:#75aadb;color:#fff}#rStudioHeader #menu .menuItem:hover{background-color:#484557;color:#fff}#rStudioHeader #menu .menuItem.current{background-color:#fff;color:#1a162d;text-decoration:none}#rStudioFooter.band{background-color:#767381}#rStudioFooter .bandContent #copyright{color:#e3eef8}table tbody tr:nth-child(even){background-color:#f7faff}table tbody tr:nth-child(odd){background-color:#fff}.latest{border-top:.5em solid <no value>}.event{-moz-box-shadow:0 0 0 0 rgba(0,0,0,.1);-webkit-box-shadow:0 0 0 0 rgba(0,0,0,.1);box-shadow:0 0 0 0 rgba(0,0,0,.1)}.section .event{background-color:#eab0c41a}.section .event{border-top:7pt solid #a19ea936}.section .event a{color:#1a162d}.section .event{color:#404040}</style><link rel=stylesheet href=/css/tidyverse.css><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo 0.71.1"><title>hardhat 0.1.0</title><meta property="og:title" content="hardhat 0.1.0"><meta property="og:description" content="hardhat 0.1.0 is now available on CRAN. It provides tools for developing new modeling packages, with a focus around preprocessing, predicting, and validating input."><meta property="og:type" content="article"><meta property="og:url" content="https://www.tidyverse.org/blog/2019/12/hardhat-0-1-0/"><meta property="twitter:card" content="summary_large_image"><meta property="og:title" content="hardhat 0.1.0 - Tidyverse"><meta property="description" content="hardhat 0.1.0 is now available on CRAN. It provides tools for developing new modeling packages, with a focus around preprocessing, predicting, and validating input."><meta property="og:description" content="hardhat 0.1.0 is now available on CRAN. It provides tools for developing new modeling packages, with a focus around preprocessing, predicting, and validating input."><meta property="og:image" content="https://www.tidyverse.org/blog/2019/12/hardhat-0-1-0/thumb-sq.jpg"><meta name=twitter:image content="https://www.tidyverse.org/blog/2019/12/hardhat-0-1-0/thumb-wd.jpg"><link rel=apple-touch-icon sizes=180x180 href=/images/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/images/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/images/favicons/favicon-16x16.png><link rel=manifest href=/images/favicons/site.webmanifest><link rel=mask-icon href=/images/favicons/safari-pinned-tab.svg><link rel="shortcut icon" href=/images/favicons/favicon.ico><meta name=msapplication-TileColor content="#da532c"><meta name=msapplication-config href=/images/favicons/browserconfig.xml><script type=text/javascript src=/js/jquery-3.5.1.min.js></script><script type=text/javascript src=/js/site.js></script><link rel=icon href=/images/favicon.ico><script type=text/javascript src=/js/clipboard.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin=anonymous></script><script defer data-domain=tidyverse.org,all.tidyverse.org src=https://plausible.io/js/plausible.js></script></head><body><div id=appTidyverseSite class="shrinkHeader alwaysShrinkHeader"><div id=main><div id=rStudioHeader><nav class=band><div class="innards bandContent"><div><a class=productName href=/>Tidyverse</a></div><div id=menu><div id=menuToggler></div><div id=menuItems><a class=menuItem href=/packages/>Packages</a>
<a class="menuItem current" href=/blog/>Blog</a>
<a class=menuItem href=/learn/>Learn</a>
<a class=menuItem href=/help/>Help</a>
<a class=menuItem href=/contribute/>Contribute</a></div></div></div></nav></div><main><div class="band padForHeader pushFooter"><div class=bandContent><div class="full splitColumns withMobileMargins"><div class=column75><h1 class=article-title>hardhat 0.1.0</h1><div class=article-header aria-hidden=true><div class=photo><img src=/blog/2019/12/hardhat-0-1-0/thumb-wd.jpg></div><div class=photoCredit>Photo by <a href=https://unsplash.com/photos/YSxcf6C_SEg>Silvia Brazzoduro</a></div></div><span class=article-date><i class="fas fa-calendar-day fa-fw"></i>&nbsp;&nbsp;2019/12/16</span><p style=margin-bottom:.5em;margin-top:.85em><i class="fas fa-tags"></i>&nbsp;
<a href=/tags/tidymodels/>tidymodels</a>,
<a href=/tags/hardhat/>hardhat</a></p><p style=margin-top:.5em><i class="fas fa-user-circle fa-fw"></i>&nbsp;
Davis Vaughan</p><div class=article-content><p>We&rsquo;re excited to announce that the first version of
<a href=https://tidymodels.github.io/hardhat/ target=_blank rel=noopener>hardhat</a> is now on CRAN. hardhat is a developer-focused package with the goal of making it easier to create new modeling packages, while simultaneously promoting good R modeling package standards. To accomplish this, hardhat provides tooling around preprocessing, predicting, and validating user input, along with a way to set up the structure of a new modeling package with a single function call.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>library</span><span class=p>(</span><span class=n>modeldata</span><span class=p>)</span>
<span class=nf>library</span><span class=p>(</span><span class=n>tibble</span><span class=p>)</span>
<span class=nf>library</span><span class=p>(</span><span class=n>hardhat</span><span class=p>)</span>
<span class=nf>library</span><span class=p>(</span><span class=n>recipes</span><span class=p>)</span>

<span class=nf>data</span><span class=p>(</span><span class=s>&#34;biomass&#34;</span><span class=p>)</span>
<span class=n>biomass</span> <span class=o>&lt;-</span> <span class=nf>as_tibble</span><span class=p>(</span><span class=n>biomass</span><span class=p>)</span>
</code></pre></div><h2 id=setup>Setup
<a href=#setup><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>One exciting feature included with hardhat is <code>create_modeling_package()</code>. Built on top of <code>usethis::create_package()</code>, this allows you to quickly set up a new modeling package with pre-generated infrastructure in place for an S3 generic to go with your user-facing modeling function. It also includes a <code>predict()</code> method and other best practices outlined further in
<a href=https://tidymodels.github.io/model-implementation-principles/ target=_blank rel=noopener>Conventions for R Modeling Packages</a>. If you&rsquo;ve never created a modeling package before, this is a great place to start so you can focus more on the implementation rather than the details around package setup.</p><h2 id=preprocessing>Preprocessing
<a href=#preprocessing><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>When building a model, there are often preprocessing steps that you perform on the training set before fitting. Take this <code>biomass</code> dataset for example. The goal is to predict the <code>HHV</code> for each sample, an acronym for the Higher Heating Value, defined as the amount of heat released by an object during combustion. To do this, you might use the numeric columns containing the amounts of different atomic elements that make up each sample.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>training</span> <span class=o>&lt;-</span> <span class=n>biomass[biomass</span><span class=o>$</span><span class=n>dataset</span> <span class=o>==</span> <span class=s>&#34;Training&#34;</span><span class=p>,</span><span class=n>]</span>
<span class=n>testing</span> <span class=o>&lt;-</span> <span class=n>biomass[biomass</span><span class=o>$</span><span class=n>dataset</span> <span class=o>==</span> <span class=s>&#34;Testing&#34;</span><span class=p>,</span><span class=n>]</span>

<span class=n>training</span>
<span class=c1>#&gt; # A tibble: 456 x 8</span>
<span class=c1>#&gt;    sample                 dataset  carbon hydrogen oxygen nitrogen sulfur   HHV</span>
<span class=c1>#&gt;    &lt;chr&gt;                  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;</span>
<span class=c1>#&gt;  1 Akhrot Shell           Training   49.8     5.64   42.9     0.41   0     20.0</span>
<span class=c1>#&gt;  2 Alabama Oak Wood Waste Training   49.5     5.7    41.3     0.2    0     19.2</span>
<span class=c1>#&gt;  3 Alder                  Training   47.8     5.8    46.2     0.11   0.02  18.3</span>
<span class=c1>#&gt;  4 Alfalfa                Training   45.1     4.97   35.6     3.3    0.16  18.2</span>
<span class=c1>#&gt;  5 Alfalfa Seed Straw     Training   46.8     5.4    40.7     1      0.02  18.4</span>
<span class=c1>#&gt;  6 Alfalfa Stalks         Training   45.4     5.75   40.2     2.04   0.1   18.5</span>
<span class=c1>#&gt;  7 Alfalfa Stems          Training   47.2     5.99   38.2     2.68   0.2   18.7</span>
<span class=c1>#&gt;  8 Alfalfa Straw          Training   45.7     5.7    39.7     1.7    0.2   18.3</span>
<span class=c1>#&gt;  9 Almond                 Training   48.8     5.5    40.9     0.8    0     18.6</span>
<span class=c1>#&gt; 10 Almond Hull            Training   47.1     5.9    40       1.2    0.1   18.9</span>
<span class=c1>#&gt; # … with 446 more rows</span>
</code></pre></div><p>Depending on the model you choose, you might need to center and scale your data before passing it along to the fitting function. There are two main ways you might do this: a formula, or a recipe. As a modeling package developer, ideally you&rsquo;d support both in your user-facing modeling function, like so:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>my_model</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=kc>...</span><span class=p>)</span> <span class=p>{</span>
  <span class=nf>UseMethod</span><span class=p>(</span><span class=s>&#34;my_model&#34;</span><span class=p>)</span>
<span class=p>}</span>

<span class=n>my_model.formula</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>formula</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=kc>...</span><span class=p>)</span> <span class=p>{</span>
  
<span class=p>}</span>

<span class=n>my_model.recipe</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=kc>...</span><span class=p>)</span> <span class=p>{</span>
  
<span class=p>}</span>
</code></pre></div><p>Unfortunately, each have their own nuances and tricks to be aware of, which you probably don&rsquo;t want to spend too much time thinking about. Ideally, you&rsquo;d be able to focus on your package&rsquo;s implementation, and easily be able to support a number of different user input methods. This is where hardhat can help. <code>hardhat::mold()</code> is a preprocessing function that knows how to preprocess formulas, prep recipes, and deal with the more basic XY input (two data frames, one holding predictors and one holding outcomes). The best part is that the output from <code>mold()</code> is standardized across all 3 preprocessing methods, so you always know what data structures you&rsquo;ll be getting back.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>rec</span> <span class=o>&lt;-</span> <span class=nf>recipe</span><span class=p>(</span><span class=n>HHV</span> <span class=o>~</span> <span class=n>carbon</span><span class=p>,</span> <span class=n>training</span><span class=p>)</span> <span class=o>%&gt;%</span>
  <span class=nf>step_normalize</span><span class=p>(</span><span class=n>carbon</span><span class=p>)</span>

<span class=n>processed_formula</span> <span class=o>&lt;-</span> <span class=nf>mold</span><span class=p>(</span><span class=n>HHV</span> <span class=o>~</span> <span class=nf>scale</span><span class=p>(</span><span class=n>carbon</span><span class=p>),</span> <span class=n>training</span><span class=p>)</span>
<span class=n>processed_recipe</span> <span class=o>&lt;-</span> <span class=nf>mold</span><span class=p>(</span><span class=n>rec</span><span class=p>,</span> <span class=n>training</span><span class=p>)</span>

<span class=nf>names</span><span class=p>(</span><span class=n>processed_formula</span><span class=p>)</span>
<span class=c1>#&gt; [1] &#34;predictors&#34; &#34;outcomes&#34;   &#34;blueprint&#34;  &#34;extras&#34;</span>
<span class=nf>names</span><span class=p>(</span><span class=n>processed_recipe</span><span class=p>)</span>
<span class=c1>#&gt; [1] &#34;predictors&#34; &#34;outcomes&#34;   &#34;blueprint&#34;  &#34;extras&#34;</span>
</code></pre></div><ul><li><p><code>predictors</code> is a data frame of the preprocessed predictors.</p></li><li><p><code>outcomes</code> is a data frame of the preprocessed outcomes.</p></li><li><p><code>blueprint</code> is the best part of hardhat. It records the preprocessing activities, so that it can replay them on top of new data that needs to be preprocessed at prediction time.</p></li><li><p><code>extras</code> is a data frame of any &ldquo;extra&rdquo; columns in your data set that aren&rsquo;t considered predictors or outcomes. These might be offsets in a formula, or extra roles from a recipe.</p></li></ul><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>processed_recipe</span><span class=o>$</span><span class=n>predictors</span>
<span class=c1>#&gt; # A tibble: 456 x 1</span>
<span class=c1>#&gt;     carbon</span>
<span class=c1>#&gt;      &lt;dbl&gt;</span>
<span class=c1>#&gt;  1  0.140 </span>
<span class=c1>#&gt;  2  0.110 </span>
<span class=c1>#&gt;  3 -0.0513</span>
<span class=c1>#&gt;  4 -0.313 </span>
<span class=c1>#&gt;  5 -0.153 </span>
<span class=c1>#&gt;  6 -0.284 </span>
<span class=c1>#&gt;  7 -0.114 </span>
<span class=c1>#&gt;  8 -0.255 </span>
<span class=c1>#&gt;  9  0.0428</span>
<span class=c1>#&gt; 10 -0.120 </span>
<span class=c1>#&gt; # … with 446 more rows</span>

<span class=n>processed_recipe</span><span class=o>$</span><span class=n>outcomes</span>
<span class=c1>#&gt; # A tibble: 456 x 1</span>
<span class=c1>#&gt;      HHV</span>
<span class=c1>#&gt;    &lt;dbl&gt;</span>
<span class=c1>#&gt;  1  20.0</span>
<span class=c1>#&gt;  2  19.2</span>
<span class=c1>#&gt;  3  18.3</span>
<span class=c1>#&gt;  4  18.2</span>
<span class=c1>#&gt;  5  18.4</span>
<span class=c1>#&gt;  6  18.5</span>
<span class=c1>#&gt;  7  18.7</span>
<span class=c1>#&gt;  8  18.3</span>
<span class=c1>#&gt;  9  18.6</span>
<span class=c1>#&gt; 10  18.9</span>
<span class=c1>#&gt; # … with 446 more rows</span>
</code></pre></div><p>Generally you won&rsquo;t call <code>mold()</code> interactively, but will, instead, call it from your top-level modeling function as the first step to standardize and validate a user&rsquo;s input.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>my_model</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=kc>...</span><span class=p>)</span> <span class=p>{</span>
  <span class=nf>UseMethod</span><span class=p>(</span><span class=s>&#34;my_model&#34;</span><span class=p>)</span>
<span class=p>}</span>

<span class=n>my_model.formula</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>formula</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=kc>...</span><span class=p>)</span> <span class=p>{</span>
  <span class=n>processed</span> <span class=o>&lt;-</span> <span class=n>hardhat</span><span class=o>::</span><span class=nf>mold</span><span class=p>(</span><span class=n>formula</span><span class=p>,</span> <span class=n>data</span><span class=p>)</span>
  <span class=c1># ... pass on to implementation</span>
<span class=p>}</span>

<span class=n>my_model.recipe</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=kc>...</span><span class=p>)</span> <span class=p>{</span>
  <span class=n>processed</span> <span class=o>&lt;-</span> <span class=n>hardhat</span><span class=o>::</span><span class=nf>mold</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>data</span><span class=p>)</span>
  <span class=c1># ... pass on to implementation</span>
<span class=p>}</span>
</code></pre></div><h2 id=predicting>Predicting
<a href=#predicting><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>Once you&rsquo;ve used the preprocessed data to fit your model, you&rsquo;ll probably want to make predictions on a test set. To do this, you&rsquo;ll need to reapply any preprocessing that you did on the training set to the test set as well. hardhat makes this easy with <code>hardhat::forge()</code>. <code>forge()</code> takes a data frame of new predictors, as well as a <code>blueprint</code> that was created in the call to <code>mold()</code>, and reapplies the correct preprocessing for you. Again, no matter what the original preprocessing method was, the output is consistent and predictable.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>forged_formula</span> <span class=o>&lt;-</span> <span class=nf>forge</span><span class=p>(</span><span class=n>testing</span><span class=p>,</span> <span class=n>processed_formula</span><span class=o>$</span><span class=n>blueprint</span><span class=p>)</span>
<span class=n>forged_recipe</span> <span class=o>&lt;-</span> <span class=nf>forge</span><span class=p>(</span><span class=n>testing</span><span class=p>,</span> <span class=n>processed_recipe</span><span class=o>$</span><span class=n>blueprint</span><span class=p>)</span>

<span class=nf>names</span><span class=p>(</span><span class=n>forged_formula</span><span class=p>)</span>
<span class=c1>#&gt; [1] &#34;predictors&#34; &#34;outcomes&#34;   &#34;extras&#34;</span>
<span class=nf>names</span><span class=p>(</span><span class=n>forged_recipe</span><span class=p>)</span>
<span class=c1>#&gt; [1] &#34;predictors&#34; &#34;outcomes&#34;   &#34;extras&#34;</span>

<span class=n>forged_recipe</span><span class=o>$</span><span class=n>predictors</span>
<span class=c1>#&gt; # A tibble: 80 x 1</span>
<span class=c1>#&gt;     carbon</span>
<span class=c1>#&gt;      &lt;dbl&gt;</span>
<span class=c1>#&gt;  1 -0.193 </span>
<span class=c1>#&gt;  2 -0.490 </span>
<span class=c1>#&gt;  3 -0.543 </span>
<span class=c1>#&gt;  4 -0.188 </span>
<span class=c1>#&gt;  5  0.0390</span>
<span class=c1>#&gt;  6 -0.390 </span>
<span class=c1>#&gt;  7 -0.904 </span>
<span class=c1>#&gt;  8 -0.601 </span>
<span class=c1>#&gt;  9 -1.84  </span>
<span class=c1>#&gt; 10 -1.97  </span>
<span class=c1>#&gt; # … with 70 more rows</span>
</code></pre></div><p>Like <code>mold()</code>, <code>forge()</code> is not intended for interactive use. Instead, you&rsquo;ll call it from your <code>predict()</code> method.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>predict.my_model</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>object</span><span class=p>,</span> <span class=n>new_data</span><span class=p>,</span> <span class=kc>...</span><span class=p>)</span> <span class=p>{</span>
  <span class=n>processed</span> <span class=o>&lt;-</span> <span class=n>hardhat</span><span class=o>::</span><span class=nf>forge</span><span class=p>(</span><span class=n>new_data</span><span class=p>,</span> <span class=n>object</span><span class=o>$</span><span class=n>blueprint</span><span class=p>)</span>
  <span class=c1># ... pass on to predict() implementation</span>
<span class=p>}</span>
</code></pre></div><p><code>object</code> here is a model fit of class <code>"my_model"</code> that should be the result of a user calling your high level <code>my_model()</code> function. To enable <code>forge()</code> to work as shown here, you&rsquo;ll need to attach and return the <code>blueprint</code> that is created from <code>mold()</code> to this model <code>object</code>.</p><p><code>forge()</code> has powerful data type validation built in. It checks for a number of things including:</p><ul><li><p>Missing predictors</p></li><li><p>Predictors with the correct name, but wrong data type</p></li><li><p>Factor predictors with &ldquo;novel levels&rdquo;</p></li><li><p>Factor predictors with missing levels, which can be recovered automatically</p></li></ul><h2 id=learning-more>Learning more
<a href=#learning-more><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>There are 3 key vignettes for hardhat.</p><ul><li><p><a href=https://tidymodels.github.io/hardhat/articles/package.html target=_blank rel=noopener>Creating Modeling Packages With hardhat</a></p></li><li><p><a href=https://tidymodels.github.io/hardhat/articles/mold.html target=_blank rel=noopener>Molding data for modeling</a></p></li><li><p><a href=https://tidymodels.github.io/hardhat/articles/forge.html target=_blank rel=noopener>Forging data for predictions</a></p></li></ul><p>There is also a video of Max Kuhn speaking about hardhat at the
<a href=https://canal.uned.es/video/5dd25b9f5578f275e407dd88 target=_blank rel=noopener>XI Jornadas de Usuarios de R conference</a>.</p></div></div><div class=column25><div class="section hideOnMobile"><div class=sectionTitle>Contents</div><nav id=TableOfContents><ul><li><a href=#setup>Setup</a></li><li><a href=#preprocessing>Preprocessing</a></li><li><a href=#predicting>Predicting</a></li><li><a href=#learning-more>Learning more</a></li></ul></nav></div><div class=section></div></div></div></div></div><div id=rStudioFooter class=band><div class=bandContent><div id=copyright>The tidyverse is proudly supported by <a class=rstudioLogo href=https://posit.co/ aria-label="Posit Homepage"></a></div><div id=logos><a href=https://www.tidyverse.org/google_privacy_policy>Privacy policy</a>
<a href=https://github.com/tidyverse class="footerLogo gitHub" aria-label="Tidyverse GitHub organization"></a><a href=https://twitter.com/hashtag/rstats class="footerLogo twitter" aria-label="rstats hashtag on twitter.com"></a></div></div></div></div></div><script src=/js/math-code.js></script><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script><script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script type=application/javascript>var dnt=(navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack);var doNotTrack=(dnt=="1"||dnt=="yes");if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');if(window.sessionStorage){var GA_SESSION_STORAGE_KEY='ga:clientId';ga('create','UA-115082821-1',{'storage':'none','clientId':sessionStorage.getItem(GA_SESSION_STORAGE_KEY)});ga(function(tracker){sessionStorage.setItem(GA_SESSION_STORAGE_KEY,tracker.get('clientId'));});}
ga('set','anonymizeIp',true);ga('send','pageview');}</script></body></html></div></div></body></html>