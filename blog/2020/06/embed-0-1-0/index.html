<!doctype html><html><head><!doctype html><html lang=en-us><link rel=stylesheet href=/css/fonts.css><link rel=stylesheet href=/css/main-site.css><link rel=stylesheet href=/css/fa5-all.css><style type=text/css>body{background-color:#fff;color:#1a1917}a{color:#38577f}a:hover{color:#42709b}a:focus{outline-color:#42709b}.column25-left .sectionTitle a:hover:not(.current),.column16-left .sectionTitle a:hover:not(.current){color:#1a1917}.icon-attribution,.icon-attribution a{color:#1a1917;opacity:75%}#homeContent .band.first{background-color:#fff}#homeContent .band.second{background-color:#fdeba4}#homeContent .band.third{background-color:#fff}#rStudioHeader{background-color:#1a162d;color:#fff}#rStudioHeader .productName{color:#fff}#rStudioHeader .productName:hover,#rStudioHeader .productName:focus{color:#fdeba4}#rStudioHeader #menu .menuItem.a{background-color:#75aadb;color:#fff}#rStudioHeader #menu .menuItem:hover{background-color:#484557;color:#fff}#rStudioHeader #menu .menuItem.current{background-color:#fff;color:#1a162d;text-decoration:none}#rStudioFooter.band{background-color:#767381}#rStudioFooter .bandContent #copyright{color:#e3eef8}table tbody tr:nth-child(even){background-color:#f7faff}table tbody tr:nth-child(odd){background-color:#fff}.latest{border-top:.5em solid <no value>}.event{-moz-box-shadow:0 0 0 0 rgba(0,0,0,.1);-webkit-box-shadow:0 0 0 0 rgba(0,0,0,.1);box-shadow:0 0 0 0 rgba(0,0,0,.1)}.section .event{background-color:#eab0c41a}.section .event{border-top:7pt solid #a19ea936}.section .event a{color:#1a162d}.section .event{color:#404040}</style><link rel=stylesheet href=/css/tidyverse.css><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo 0.71.1"><title>embed 0.1.0</title><meta property="og:title" content="embed 0.1.0"><meta property="og:description" content="An update to embed adds two new steps."><meta property="og:type" content="article"><meta property="og:url" content="https://www.tidyverse.org/blog/2020/06/embed-0-1-0/"><meta property="twitter:card" content="summary_large_image"><meta property="og:title" content="embed 0.1.0 - Tidyverse"><meta property="description" content="An update to embed adds two new steps."><meta property="og:description" content="An update to embed adds two new steps."><meta property="og:image" content="https://www.tidyverse.org/blog/2020/06/embed-0-1-0/embed-0-1-0-sq.jpg"><meta name=twitter:image content="https://www.tidyverse.org/blog/2020/06/embed-0-1-0/embed-0-1-0-wd.jpg"><link rel=apple-touch-icon sizes=180x180 href=/images/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/images/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/images/favicons/favicon-16x16.png><link rel=manifest href=/images/favicons/site.webmanifest><link rel=mask-icon href=/images/favicons/safari-pinned-tab.svg><link rel="shortcut icon" href=/images/favicons/favicon.ico><meta name=msapplication-TileColor content="#da532c"><meta name=msapplication-config href=/images/favicons/browserconfig.xml><script type=text/javascript src=/js/jquery-3.5.1.min.js></script><script type=text/javascript src=/js/site.js></script><link rel=icon href=/images/favicon.ico><script type=text/javascript src=/js/clipboard.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin=anonymous></script><script defer data-domain=tidyverse.org,all.tidyverse.org src=https://plausible.io/js/plausible.js></script></head><body><div id=appTidyverseSite class="shrinkHeader alwaysShrinkHeader"><div id=main><div id=rStudioHeader><nav class=band><div class="innards bandContent"><div><a class=productName href=/%20/>Tidyverse</a></div><div id=menu><div id=menuToggler></div><div id=menuItems><a class=menuItem href=/packages/>Packages</a>
<a class="menuItem current" href=/blog/>Blog</a>
<a class=menuItem href=/learn/>Learn</a>
<a class=menuItem href=/help/>Help</a>
<a class=menuItem href=/contribute/>Contribute</a></div></div></div></nav></div><main><div class="band padForHeader pushFooter"><div class=bandContent><div class="full splitColumns withMobileMargins"><div class=column75><h1 class=article-title>embed 0.1.0</h1><div class=article-header aria-hidden=true><div class=photo><img src=/blog/2020/06/embed-0-1-0/embed-0-1-0-wd.jpg></div><div class=photoCredit>Photo by <a href=https://unsplash.com/photos/rNhL85ocOGg>Clark Van Der Beken</a></div></div><span class=article-date><i class="fas fa-calendar-day fa-fw"></i>&nbsp;&nbsp;2020/06/09</span><p style=margin-bottom:.5em;margin-top:.85em><i class="fas fa-tags"></i>&nbsp;
<a href=/tags/tidymodels/>tidymodels</a>,
<a href=/tags/embed/>embed</a>,
<a href=/tags/embed-0-1-0/>embed-0-1-0</a></p><p style=margin-top:.5em><i class="fas fa-user-circle fa-fw"></i>&nbsp;
Max Kuhn</p><div class=article-content><p>There is a new release of the
<a href=https://embed.tidymodels.org target=_blank rel=noopener>embed package</a> on
<a href="https://cran.r-project.org/package=embed" target=_blank rel=noopener>CRAN</a>. embed contains a number of recipe steps that can be used to represent predictors using a smaller set of artificial features. Some of these methods are <em>supervised</em> (i.e., it uses the outcome data) and others are <em>unsupervised</em> (the outcome is not considered). The recipes package already contains similar methods (e.g. principal component analysis, partial least squares, etc.). embed has more sophisticated method and these tend to have more significant package dependencies such as stan and tensorflow.</p><p>The current roster of methods in the embed package are:</p><ul><li><p><em>Entity embeddings</em> where categorical predictors are decomposed into a set of smaller numeric features (supervised,
<a href=https://embed.tidymodels.org/reference/step_embed.html target=_blank rel=noopener><code>step_embed()</code></a>).</p></li><li><p><em>Effect encodings</em> model categorical predictors against the outcome and the resulting coefficients are used as the numeric features (supervised,
<a href=https://embed.tidymodels.org/reference/index.html target=_blank rel=noopener><code>step_lencode_*()</code></a>).</p></li><li><p><em>Weight of evidence transformation</em> that use measures of association for categorical predictors and categorical outcomes to generate new features (supervised,
<a href=https://embed.tidymodels.org/reference/step_woe.html target=_blank rel=noopener><code>step_woe()</code></a>).</p></li><li><p><em>Uniform manifold approximation and projections</em> (UMAP) estimate local, low-dimensional representations of numeric predictors (supervised or unsupervised,
<a href=https://embed.tidymodels.org/reference/step_umap.html target=_blank rel=noopener><code>step_umap()</code></a>).</p></li><li><p><em>Discretization methods</em> of numeric predictors using tree-based methods (supervised,
<a href=https://embed.tidymodels.org/reference/index.html target=_blank rel=noopener><code>step_discretize_*()</code></a>).</p></li><li><p><em>Feature hashing</em> creates dummy variables using hashing methods (unsupervised,
<a href=https://embed.tidymodels.org/reference/step_feature_hash.html target=_blank rel=noopener><code>step_feature_hash()</code></a>).</p></li></ul><p>The latter two sets of steps are only in this new version. Let&rsquo;s look at these two methods in detail.</p><h2 id=discretization>Discretization
<a href=#discretization><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>I am
<a href=https://bookdown.org/max/FES/numeric-one-to-many.html#binning target=_blank rel=noopener>not a huge fan</a> of taking numeric data and re-encoding them as categorical predictors. There is mostly likely a loss of information by doing so and other methods, such as splines, are probably a better approach overall. However, I&rsquo;m willing to admit that there might be some data sets where binning works best.</p><p>The recipes package already includes <code>step_discretize()</code>. This is an unsupervised method that creates the bins using percentiles of the data (so that the new categories have about the same frequency). The new methods in embed use the outcome data (numeric or categorical) to determine the values of the bins as well as how many bins are required.</p><p>Konrad Semsch contributed
<a href=https://embed.tidymodels.org/reference/step_discretize_xgb.html target=_blank rel=noopener><code>step_discretize_xgb()</code></a>) which uses an xgboost model. An initial boosting model is created with a single numeric predictor and the unique splits across boosting iterations are used to discretize the predictor. Here&rsquo;s an example predictor from the Ames housing data:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>library</span><span class=p>(</span><span class=n>tidymodels</span><span class=p>)</span>
<span class=nf>library</span><span class=p>(</span><span class=n>embed</span><span class=p>)</span>
<span class=nf>library</span><span class=p>(</span><span class=n>AmesHousing</span><span class=p>)</span>

<span class=n>ames</span> <span class=o>&lt;-</span> 
  <span class=nf>make_ames</span><span class=p>()</span> <span class=o>%&gt;%</span> 
  <span class=c1># Remove quality-related predictors</span>
  <span class=n>dplyr</span><span class=o>::</span><span class=nf>select</span><span class=p>(</span><span class=o>-</span><span class=nf>matches</span><span class=p>(</span><span class=s>&#34;Qu&#34;</span><span class=p>))</span>

<span class=nf>set.seed</span><span class=p>(</span><span class=m>4595</span><span class=p>)</span>
<span class=n>data_split</span> <span class=o>&lt;-</span> <span class=nf>initial_split</span><span class=p>(</span><span class=n>ames</span><span class=p>,</span> <span class=n>strata</span> <span class=o>=</span> <span class=s>&#34;Sale_Price&#34;</span><span class=p>)</span>
<span class=n>ames_train</span> <span class=o>&lt;-</span> <span class=nf>training</span><span class=p>(</span><span class=n>data_split</span><span class=p>)</span>
<span class=n>ames_test</span>  <span class=o>&lt;-</span> <span class=nf>testing</span><span class=p>(</span><span class=n>data_split</span><span class=p>)</span>

<span class=nf>theme_set</span><span class=p>(</span><span class=nf>theme_bw</span><span class=p>())</span>

<span class=nf>ggplot</span><span class=p>(</span><span class=n>ames_train</span><span class=p>,</span> <span class=nf>aes</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=n>Longitude</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>Sale_Price</span><span class=p>))</span> <span class=o>+</span> 
  <span class=nf>geom_point</span><span class=p>(</span><span class=n>alpha</span> <span class=o>=</span> <span class=m>0.3</span><span class=p>)</span> <span class=o>+</span>
  <span class=nf>scale_y_log10</span><span class=p>()</span>
</code></pre></div><p><img src=figure/ames-longitude-1.svg alt="plot of chunk ames-longitude"></p><p>Because the Iowa State University is in the center of Ames, there are discontinuous relationships between the sale price of houses and longitude. There&rsquo;s a relationship here but it is nonlinear and complex. To discretize these data:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>set.seed</span><span class=p>(</span><span class=m>525</span><span class=p>)</span>
<span class=n>ames_rec</span> <span class=o>&lt;-</span> 
  <span class=nf>recipe</span><span class=p>(</span><span class=n>Sale_Price</span> <span class=o>~</span> <span class=n>.,</span> <span class=n>data</span> <span class=o>=</span> <span class=n>ames_train</span><span class=p>)</span> <span class=o>%&gt;%</span> 
  <span class=nf>step_log</span><span class=p>(</span><span class=n>Sale_Price</span><span class=p>,</span> <span class=n>base</span> <span class=o>=</span> <span class=m>10</span><span class=p>)</span> <span class=o>%&gt;%</span> 
  <span class=nf>step_discretize_xgb</span><span class=p>(</span><span class=n>Longitude</span><span class=p>,</span> <span class=n>outcome</span> <span class=o>=</span> <span class=s>&#34;Sale_Price&#34;</span><span class=p>,</span> <span class=n>id</span> <span class=o>=</span> <span class=s>&#34;xgb&#34;</span><span class=p>)</span> <span class=o>%&gt;%</span> 
  <span class=nf>prep</span><span class=p>()</span>
</code></pre></div><p>The <code>tidy()</code> method can be used to show the estimated breaks:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>breaks</span> <span class=o>&lt;-</span> 
  <span class=nf>tidy</span><span class=p>(</span><span class=n>ames_rec</span><span class=p>,</span> <span class=n>id</span> <span class=o>=</span> <span class=s>&#34;xgb&#34;</span><span class=p>)</span> <span class=o>%&gt;%</span> 
  <span class=nf>pull</span><span class=p>(</span><span class=n>values</span><span class=p>)</span>

<span class=n>breaks</span>
</code></pre></div><pre><code>## [1] -93.68667 -93.67038 -93.65519 -93.64602 -93.63570 -93.62575 -93.61737
</code></pre><p>The consequence of using <code>step_discretize_xgb()</code> is that the numeric predictor <code>Longitude</code> is converted to a factor with 8 levels:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>bake</span><span class=p>(</span><span class=n>ames_rec</span><span class=p>,</span> <span class=n>ames_test</span><span class=p>,</span> <span class=n>Longitude</span><span class=p>)</span>
</code></pre></div><pre><code>## # A tibble: 731 x 1
##    Longitude      
##    &lt;fct&gt;          
##  1 [-93.63,-93.62)
##  2 [-93.63,-93.62)
##  3 [-93.65,-93.64)
##  4 [-93.64,-93.63)
##  5 [-93.64,-93.63)
##  6 [-93.64,-93.63)
##  7 [-93.64,-93.63)
##  8 [-93.66,-93.65)
##  9 [-93.66,-93.65)
## 10 [-93.66,-93.65)
## # … with 721 more rows
</code></pre><p>For the test set, here are the breaks:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=nf>ggplot</span><span class=p>(</span><span class=n>ames_train</span><span class=p>,</span> <span class=nf>aes</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=n>Longitude</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>Sale_Price</span><span class=p>))</span> <span class=o>+</span> 
  <span class=nf>geom_vline</span><span class=p>(</span><span class=n>xintercept</span> <span class=o>=</span> <span class=n>breaks</span><span class=p>,</span> <span class=n>col</span> <span class=o>=</span> <span class=s>&#34;blue&#34;</span><span class=p>,</span> <span class=n>alpha</span> <span class=o>=</span> <span class=m>0.7</span><span class=p>)</span> <span class=o>+</span> 
  <span class=nf>geom_point</span><span class=p>(</span><span class=n>alpha</span> <span class=o>=</span> <span class=m>0.3</span><span class=p>)</span> <span class=o>+</span>
  <span class=nf>scale_y_log10</span><span class=p>()</span>
</code></pre></div><p><img src=figure/ames-longitude-breaks-1.svg alt="plot of chunk ames-longitude-breaks"></p><p><code>step_discretize_xgb()</code> and <code>step_discretize_cart()</code> contain arguments for the common tuning parameters (e.g. the number of breaks, tree depth, etc.) that can be optimized using the tune package. Also, it is possible that the tree model cannot find any informative splits of a predictor. In this case, a warning is issued and the predictor is not discretized.</p><h2 id=feature-hashing>Feature hashing
<a href=#feature-hashing><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>When converting a
<a href=https://bookdown.org/max/FES/creating-dummy-variables-for-unordered-categories.html target=_blank rel=noopener>categorical predictor to a numeric encoding</a>, the traditional approach is to make a collection of binary indicator variables. If the original data have <code>C</code> levels, the standard approach is to create <code>C - 1</code> new columns using the levels observed within the training set. A slightly different method is <em>one-hot encoding</em> which creates the full set of <code>C</code> indicators. The important points for these methods are:</p><ul><li><p>The indicators can only be created for the levels in the training set. There is a 1:1 mapping between the levels and the indicator columns.</p></li><li><p>A &ldquo;new&rdquo; category could also be issued in case future samples contain other levels.</p></li><li><p>When <code>C</code> is very large, this approach is problematic since many indicators are created and many of these will be infrequently observed in the data.</p></li></ul><p>One alternative method for making indicator variables is
<a href=https://bookdown.org/max/FES/encoding-predictors-with-many-categories.html target=_blank rel=noopener><em>feature hashing</em></a>. This method uses the actual value of the levels to decide which indicator column that the sample should be mapped to. Also, the number of indicators can be less than <code>C</code>. The math used in the background originate in cryptography and are
<a href=https://en.wikipedia.org/wiki/Hash_function target=_blank rel=noopener>pretty interesting</a>.</p><p>Let&rsquo;s look again at the Ames data. The neighborhood predictor has 28 possible values. This is by no means large but it can be used to illustrate how this method works. Instead of creating 27 indicator columns, let&rsquo;s use 10 instead.</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>hash_rec</span> <span class=o>&lt;-</span> 
  <span class=nf>recipe</span><span class=p>(</span><span class=n>Sale_Price</span> <span class=o>~</span> <span class=n>Neighborhood</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=n>ames_train</span><span class=p>)</span> <span class=o>%&gt;%</span> 
  <span class=c1># For illustration only, `preserve` is used to keep the original column. </span>
  <span class=nf>step_feature_hash</span><span class=p>(</span><span class=n>Neighborhood</span><span class=p>,</span> <span class=n>num_hash</span> <span class=o>=</span> <span class=m>10</span><span class=p>,</span> <span class=n>preserve</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>)</span> <span class=o>%&gt;%</span> 
  <span class=nf>prep</span><span class=p>()</span>
</code></pre></div><p>There is no actual estimation used so far. When generating the values, the hashing function is used to create the indicators:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>all_nhood</span> <span class=o>&lt;-</span> 
  <span class=n>ames</span> <span class=o>%&gt;%</span> 
  <span class=nf>select</span><span class=p>(</span><span class=n>Neighborhood</span><span class=p>)</span> <span class=o>%&gt;%</span> 
  <span class=nf>distinct</span><span class=p>()</span>
<span class=n>hashed</span> <span class=o>&lt;-</span> <span class=nf>bake</span><span class=p>(</span><span class=n>hash_rec</span><span class=p>,</span> <span class=n>all_nhood</span><span class=p>,</span> <span class=nf>starts_with</span><span class=p>(</span><span class=s>&#34;Neighborhood&#34;</span><span class=p>))</span>
<span class=n>hashed</span>
</code></pre></div><pre><code>## # A tibble: 28 x 11
##    Neighborhood Neighborhood_ha… Neighborhood_ha… Neighborhood_ha…
##    &lt;fct&gt;                   &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;
##  1 North_Ames                  0                0                0
##  2 Gilbert                     0                0                0
##  3 Stone_Brook                 0                0                0
##  4 Northwest_A…                1                0                0
##  5 Somerset                    0                0                1
##  6 Briardale                   0                0                0
##  7 Northpark_V…                0                0                0
##  8 Northridge_…                0                0                0
##  9 Bloomington…                0                0                0
## 10 Northridge                  0                0                0
## # … with 18 more rows, and 7 more variables: Neighborhood_hash_04 &lt;dbl&gt;,
## #   Neighborhood_hash_05 &lt;dbl&gt;, Neighborhood_hash_06 &lt;dbl&gt;,
## #   Neighborhood_hash_07 &lt;dbl&gt;, Neighborhood_hash_08 &lt;dbl&gt;,
## #   Neighborhood_hash_09 &lt;dbl&gt;, Neighborhood_hash_10 &lt;dbl&gt;
</code></pre><p>How were neighborhoods mapped to indicators in these data? Each neighborhood only maps to a single row. However, unlike the traditional methods, multiple neighborhoods are likely to be mapped to the same indicator column:</p><div class=highlight><pre class=chroma><code class=language-r data-lang=r><span class=n>hashed</span> <span class=o>%&gt;%</span>
  <span class=n>tidyr</span><span class=o>::</span><span class=nf>pivot_longer</span><span class=p>(</span><span class=n>cols</span> <span class=o>=</span> <span class=nf>c</span><span class=p>(</span><span class=nf>contains</span><span class=p>(</span><span class=s>&#34;hash&#34;</span><span class=p>)),</span>
                      <span class=n>names_to</span> <span class=o>=</span> <span class=s>&#34;column&#34;</span><span class=p>,</span>
                      <span class=n>values_to</span> <span class=o>=</span> <span class=s>&#34;values&#34;</span><span class=p>)</span> <span class=o>%&gt;%</span>
  <span class=nf>group_by</span><span class=p>(</span><span class=n>column</span><span class=p>)</span> <span class=o>%&gt;%</span>
  <span class=nf>summarize</span><span class=p>(</span><span class=n>num_neighborhood</span> <span class=o>=</span> <span class=nf>sum</span><span class=p>(</span><span class=n>values</span><span class=p>))</span>
</code></pre></div><pre><code>## # A tibble: 10 x 2
##    column               num_neighborhood
##    &lt;chr&gt;                           &lt;dbl&gt;
##  1 Neighborhood_hash_01                4
##  2 Neighborhood_hash_02                2
##  3 Neighborhood_hash_03                3
##  4 Neighborhood_hash_04                2
##  5 Neighborhood_hash_05                2
##  6 Neighborhood_hash_06                4
##  7 Neighborhood_hash_07                3
##  8 Neighborhood_hash_08                4
##  9 Neighborhood_hash_09                4
## 10 Neighborhood_hash_10                0
</code></pre><p>For this configuration, multiple neighborhoods are mapped to the same feature. In statistics, this is called <em>aliasing</em> or <em>confounding</em>. While sometime required, confounding methods should generally alias different values to the same feature using some sort of optimality criterion. Feature hashing does not appear to be optimal in any way that is relevant to modeling. Also note in the output above that some hash features will have no indicators. It might be a good practice to follow this step with <code>step_zv()</code> to remove them.</p><p>On the bright side, new neighborhoods can be easily mapped. For example:</p><ul><li><code>Novigrad</code> would be mapped to column 1.</li><li><code>Brokilon Forest</code> would be mapped to column 4.</li><li><code>Brokilon forest</code> would be mapped to column 9.</li></ul><p>As the last two examples show, the actual value of the factor level is used. Also note that, if a different number of features are created, the mapping will also change.</p><p>This step requires the
<a href=https://keras.rstudio.com/ target=_blank rel=noopener>keras</a> R package along with a working
<a href=https://tensorflow.rstudio.com/installation/ target=_blank rel=noopener>tensorflow</a> installation.</p><h2 id=hex-logo>Hex logo
<a href=#hex-logo><svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="currentcolor"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a></h2><p>The embed package doesn&rsquo;t have a hex logo. If you would like to propose one, please
<a href=https://twitter.com/topepos target=_blank rel=noopener>tweet at us</a> or
<a href=mailto:max@rstudio.com>email</a>!</p></div></div><div class=column25><div class="section hideOnMobile"><div class=sectionTitle>Contents</div><nav id=TableOfContents><ul><li><a href=#discretization>Discretization</a></li><li><a href=#feature-hashing>Feature hashing</a></li><li><a href=#hex-logo>Hex logo</a></li></ul></nav></div><div class=section></div></div></div></div></div><div id=rStudioFooter class=band><div class=bandContent><div id=copyright>The tidyverse is proudly supported by <a class=rstudioLogo href=https://posit.co/ aria-label="Posit Homepage"></a></div><div id=logos><a href=https://www.tidyverse.org/google_privacy_policy>Privacy policy</a>
<a href=https://github.com/tidyverse class="footerLogo gitHub" aria-label="Tidyverse GitHub organization"></a><a href=https://twitter.com/hashtag/rstats class="footerLogo twitter" aria-label="rstats hashtag on twitter.com"></a></div></div></div></div></div><script type=application/javascript>var dnt=(navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack);var doNotTrack=(dnt=="1"||dnt=="yes");if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');if(window.sessionStorage){var GA_SESSION_STORAGE_KEY='ga:clientId';ga('create','UA-115082821-1',{'storage':'none','clientId':sessionStorage.getItem(GA_SESSION_STORAGE_KEY)});ga(function(tracker){sessionStorage.setItem(GA_SESSION_STORAGE_KEY,tracker.get('clientId'));});}
ga('set','anonymizeIp',true);ga('send','pageview');}</script></body></html></div></div></body></html>