<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>tune | Tidyverse</title><link>https://www.tidyverse.org/tags/tune/</link><atom:link href="https://www.tidyverse.org/tags/tune/index.xml" rel="self" type="application/rss+xml"/><description>tune</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 18 Apr 2024 00:00:00 +0000</lastBuildDate><item><title>tune 1.2.0</title><link>https://www.tidyverse.org/blog/2024/04/tune-1-2-0/</link><pubDate>Thu, 18 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2024/04/tune-1-2-0/</guid><description>&lt;div class="highlight">
&lt;/div>
&lt;p>We&amp;rsquo;re indubitably amped to announce the release of
&lt;a href="https://tune.tidymodels.org/" target="_blank" rel="noopener">tune&lt;/a> 1.2.0, a package for hyperparameter tuning in the
&lt;a href="https://www.tidymodels.org/" target="_blank" rel="noopener">tidymodels framework&lt;/a>.&lt;/p>
&lt;p>You can install it from CRAN, along with the rest of the core packages in tidymodels, using the tidymodels meta-package:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/utils/install.packages.html'>install.packages&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"tidymodels"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>The 1.2.0 release of tune has introduced support for two major features that we&amp;rsquo;ve written about on the tidyverse blog already:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://www.tidyverse.org/blog/2024/04/tidymodels-survival-analysis/" target="_blank" rel="noopener">Survival analysis for time-to-event data with tidymodels&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.tidyverse.org/blog/2024/03/tidymodels-fairness/" target="_blank" rel="noopener">Fair machine learning with tidymodels&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>While those features got their own blog posts, there are several more features in this release that we thought were worth calling out. This post will highlight improvements to our support for parallel processing, the introduction of support for percentile confidence intervals for performance metrics, and a few other bits and bobs. You can see a full list of changes in the
&lt;a href="https://github.com/tidymodels/tune/releases/tag/v1.2.0" target="_blank" rel="noopener">release notes&lt;/a>.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='kr'>&lt;a href='https://rdrr.io/r/base/library.html'>library&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>&lt;a href='https://tidymodels.tidymodels.org'>tidymodels&lt;/a>&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Throughout this post, I&amp;rsquo;ll refer to the example of tuning an XGBoost model to predict the fuel efficiency of various car models. I hear this is already a well-explored modeling problem, but alas:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/Random.html'>set.seed&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='m'>2024&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>xgb_res&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;/span>
&lt;span> &lt;span class='nf'>tune_grid&lt;/span>&lt;span class='o'>(&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>boost_tree&lt;/span>&lt;span class='o'>(&lt;/span>mode &lt;span class='o'>=&lt;/span> &lt;span class='s'>"regression"&lt;/span>, mtry &lt;span class='o'>=&lt;/span> &lt;span class='nf'>tune&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>, learn_rate &lt;span class='o'>=&lt;/span> &lt;span class='nf'>tune&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>.&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nf'>bootstraps&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> control &lt;span class='o'>=&lt;/span> &lt;span class='nf'>control_grid&lt;/span>&lt;span class='o'>(&lt;/span>save_pred &lt;span class='o'>=&lt;/span> &lt;span class='kc'>TRUE&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span> &lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Note that we&amp;rsquo;ve used the
&lt;a href="https://tune.tidymodels.org/reference/control_grid.html" target="_blank" rel="noopener">control option&lt;/a> &lt;code>save_pred = TRUE&lt;/code> to indicate that we want to save the predictions from our resampled models in the tuning results. Both &lt;code>int_pctl()&lt;/code> and &lt;code>compute_metrics()&lt;/code> below will need those predictions. The metrics for our resampled model look like so:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>collect_metrics&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>xgb_res&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 20 × 8&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; mtry learn_rate .metric .estimator mean n std_err .config &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;int&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;int&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> 2 0.002&lt;span style='text-decoration: underline;'>04&lt;/span> rmse standard 19.7 25 0.262 Preprocessor1_Model01&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>2&lt;/span> 2 0.002&lt;span style='text-decoration: underline;'>04&lt;/span> rsq standard 0.659 25 0.031&lt;span style='text-decoration: underline;'>4&lt;/span> Preprocessor1_Model01&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>3&lt;/span> 6 0.008&lt;span style='text-decoration: underline;'>59&lt;/span> rmse standard 18.0 25 0.260 Preprocessor1_Model02&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>4&lt;/span> 6 0.008&lt;span style='text-decoration: underline;'>59&lt;/span> rsq standard 0.607 25 0.027&lt;span style='text-decoration: underline;'>0&lt;/span> Preprocessor1_Model02&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>5&lt;/span> 3 0.027&lt;span style='text-decoration: underline;'>6&lt;/span> rmse standard 14.0 25 0.267 Preprocessor1_Model03&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>6&lt;/span> 3 0.027&lt;span style='text-decoration: underline;'>6&lt;/span> rsq standard 0.710 25 0.023&lt;span style='text-decoration: underline;'>7&lt;/span> Preprocessor1_Model03&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># ℹ 14 more rows&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;h2 id="modernized-support-for-parallel-processing">Modernized support for parallel processing
&lt;a href="#modernized-support-for-parallel-processing">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>The tidymodels framework has long supported evaluating models in parallel using the
&lt;a href="https://cran.r-project.org/web/packages/foreach/vignettes/foreach.html" target="_blank" rel="noopener">foreach&lt;/a> package. This release of tune has introduced support for parallelism using the
&lt;a href="https://www.futureverse.org/" target="_blank" rel="noopener">futureverse&lt;/a> framework, and we will begin deprecating our support for foreach in a coming release.&lt;/p>
&lt;p>To tune a model in parallel with foreach, a user would load a &lt;em>parallel backend&lt;/em> package (usually with a name like
&lt;a href="https://rdrr.io/r/base/library.html" target="_blank" rel="noopener">&lt;code>library(doBackend)&lt;/code>&lt;/a>) and then &lt;em>register&lt;/em> it with foreach (with a function call like &lt;code>registerDoBackend()&lt;/code>). The tune package would then detect that registered backend and take it from there. For example, the code to distribute the above tuning process across 10 cores with foreach would look like:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='kr'>&lt;a href='https://rdrr.io/r/base/library.html'>library&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>doMC&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/pkg/doMC/man/registerDoMC.html'>registerDoMC&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>cores &lt;span class='o'>=&lt;/span> &lt;span class='m'>10&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/Random.html'>set.seed&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='m'>2024&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>xgb_res&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;/span>
&lt;span> &lt;span class='nf'>tune_grid&lt;/span>&lt;span class='o'>(&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>boost_tree&lt;/span>&lt;span class='o'>(&lt;/span>mode &lt;span class='o'>=&lt;/span> &lt;span class='s'>"regression"&lt;/span>, mtry &lt;span class='o'>=&lt;/span> &lt;span class='nf'>tune&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>, learn_rate &lt;span class='o'>=&lt;/span> &lt;span class='nf'>tune&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>.&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nf'>bootstraps&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> control &lt;span class='o'>=&lt;/span> &lt;span class='nf'>control_grid&lt;/span>&lt;span class='o'>(&lt;/span>save_pred &lt;span class='o'>=&lt;/span> &lt;span class='kc'>TRUE&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span> &lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>The code to do so with future is similarly simple. Users first load the
&lt;a href="https://future.futureverse.org/index.html" target="_blank" rel="noopener">future&lt;/a> package, and then specify a
&lt;a href="https://future.futureverse.org/reference/plan.html" target="_blank" rel="noopener">&lt;code>plan()&lt;/code>&lt;/a> which dictates how computations will be distributed. For example, the code to distribute the above tuning process across 10 cores with future looks like:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='kr'>&lt;a href='https://rdrr.io/r/base/library.html'>library&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>&lt;a href='https://future.futureverse.org'>future&lt;/a>&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='nf'>&lt;a href='https://future.futureverse.org/reference/plan.html'>plan&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>multisession&lt;/span>, workers &lt;span class='o'>=&lt;/span> &lt;span class='m'>10&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/Random.html'>set.seed&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='m'>2024&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>xgb_res&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;/span>
&lt;span> &lt;span class='nf'>tune_grid&lt;/span>&lt;span class='o'>(&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>boost_tree&lt;/span>&lt;span class='o'>(&lt;/span>mode &lt;span class='o'>=&lt;/span> &lt;span class='s'>"regression"&lt;/span>, mtry &lt;span class='o'>=&lt;/span> &lt;span class='nf'>tune&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>, learn_rate &lt;span class='o'>=&lt;/span> &lt;span class='nf'>tune&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>.&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nf'>bootstraps&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> control &lt;span class='o'>=&lt;/span> &lt;span class='nf'>control_grid&lt;/span>&lt;span class='o'>(&lt;/span>save_pred &lt;span class='o'>=&lt;/span> &lt;span class='kc'>TRUE&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span> &lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>For users, the transition to parallelism with future has several benefits:&lt;/p>
&lt;ul>
&lt;li>The futureverse presently supports a greater number of parallelism technologies and has been more likely to receive implementations for new ones.&lt;/li>
&lt;li>Once foreach is fully deprecated, users will be able to use the
&lt;a href="https://www.tidyverse.org/blog/2023/04/tuning-delights/#interactive-issue-logging" target="_blank" rel="noopener">interactive logger&lt;/a> when tuning in parallel.&lt;/li>
&lt;/ul>
&lt;p>From our perspective, transitioning our parallelism support to future makes our packages much more maintainable, reducing complexity in random number generation, error handling, and progress reporting.&lt;/p>
&lt;p>In an upcoming release of the package, you&amp;rsquo;ll see a deprecation warning when a foreach parallel backend is registered but no future plan has been specified, so start transitioning your code sooner than later!&lt;/p>
&lt;h2 id="percentile-confidence-intervals">Percentile confidence intervals
&lt;a href="#percentile-confidence-intervals">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Following up on changes in the
&lt;a href="https://github.com/tidymodels/rsample/releases/tag/v1.2.0" target="_blank" rel="noopener">most recent rsample release&lt;/a>, tune has introduced a
&lt;a href="https://tune.tidymodels.org/reference/int_pctl.tune_results.html" target="_blank" rel="noopener">method for &lt;code>int_pctl()&lt;/code>&lt;/a> that calculates percentile confidence intervals for performance metrics. To calculate a 90% confidence interval for the values of each performance metric returned in &lt;code>collect_metrics()&lt;/code>, we&amp;rsquo;d write:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/Random.html'>set.seed&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='m'>2024&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nf'>int_pctl&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>xgb_res&lt;/span>, alpha &lt;span class='o'>=&lt;/span> &lt;span class='m'>.1&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 20 × 8&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; .metric .estimator .lower .estimate .upper .config mtry learn_rate&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;int&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> rmse bootstrap 18.1 19.9 22.0 Preprocessor1_Mod… 2 0.002&lt;span style='text-decoration: underline;'>04&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>2&lt;/span> rsq bootstrap 0.570 0.679 0.778 Preprocessor1_Mod… 2 0.002&lt;span style='text-decoration: underline;'>04&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>3&lt;/span> rmse bootstrap 16.6 18.3 19.9 Preprocessor1_Mod… 6 0.008&lt;span style='text-decoration: underline;'>59&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>4&lt;/span> rsq bootstrap 0.548 0.665 0.765 Preprocessor1_Mod… 6 0.008&lt;span style='text-decoration: underline;'>59&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>5&lt;/span> rmse bootstrap 12.5 14.1 15.9 Preprocessor1_Mod… 3 0.027&lt;span style='text-decoration: underline;'>6&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>6&lt;/span> rsq bootstrap 0.622 0.720 0.818 Preprocessor1_Mod… 3 0.027&lt;span style='text-decoration: underline;'>6&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># ℹ 14 more rows&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Note that the output has the same number of rows as the &lt;code>collect_metrics()&lt;/code> output: one for each unique pair of metric and workflow.&lt;/p>
&lt;p>This is very helpful for validation sets. Other resampling methods generate replicated performance statistics. We can compute simple interval estimates using the mean and standard error for those. Validation sets produce only one estimate, and these bootstrap methods are probably the best option for obtaining interval estimates.&lt;/p>
&lt;h2 id="breaking-change-relocation-of-ellipses">Breaking change: relocation of ellipses
&lt;a href="#breaking-change-relocation-of-ellipses">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>We&amp;rsquo;ve made a &lt;strong>breaking change&lt;/strong> in argument order for several functions in the package (and downstream packages like finetune and workflowsets). Ellipses (&amp;hellip;) are now used consistently in the package to require optional arguments to be named. For functions that previously had unused ellipses at the end of the function signature, they have been moved to follow the last argument without a default value, and several other functions that previously did not have ellipses in their signatures gained them. This applies to methods for &lt;code>augment()&lt;/code>, &lt;code>collect_predictions()&lt;/code>, &lt;code>collect_metrics()&lt;/code>, &lt;code>select_best()&lt;/code>, &lt;code>show_best()&lt;/code>, and &lt;code>conf_mat_resampled()&lt;/code>.&lt;/p>
&lt;h2 id="compute-new-metrics-without-re-fitting">Compute new metrics without re-fitting
&lt;a href="#compute-new-metrics-without-re-fitting">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>We&amp;rsquo;ve also added a new function,
&lt;a href="https://tune.tidymodels.org/reference/compute_metrics.html" target="_blank" rel="noopener">&lt;code>compute_metrics()&lt;/code>&lt;/a>, that allows for calculating metrics that were not used when evaluating against resamples. For example, consider our &lt;code>xgb_res&lt;/code> object. Since we didn&amp;rsquo;t supply any metrics to evaluate, and this model is a regression model, tidymodels selected RMSE and R&lt;sup>2&lt;/sup> as defaults:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>collect_metrics&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>xgb_res&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 20 × 8&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; mtry learn_rate .metric .estimator mean n std_err .config &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;int&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;int&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> 2 0.002&lt;span style='text-decoration: underline;'>04&lt;/span> rmse standard 19.7 25 0.262 Preprocessor1_Model01&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>2&lt;/span> 2 0.002&lt;span style='text-decoration: underline;'>04&lt;/span> rsq standard 0.659 25 0.031&lt;span style='text-decoration: underline;'>4&lt;/span> Preprocessor1_Model01&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>3&lt;/span> 6 0.008&lt;span style='text-decoration: underline;'>59&lt;/span> rmse standard 18.0 25 0.260 Preprocessor1_Model02&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>4&lt;/span> 6 0.008&lt;span style='text-decoration: underline;'>59&lt;/span> rsq standard 0.607 25 0.027&lt;span style='text-decoration: underline;'>0&lt;/span> Preprocessor1_Model02&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>5&lt;/span> 3 0.027&lt;span style='text-decoration: underline;'>6&lt;/span> rmse standard 14.0 25 0.267 Preprocessor1_Model03&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>6&lt;/span> 3 0.027&lt;span style='text-decoration: underline;'>6&lt;/span> rsq standard 0.710 25 0.023&lt;span style='text-decoration: underline;'>7&lt;/span> Preprocessor1_Model03&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># ℹ 14 more rows&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>In the past, if you wanted to evaluate that workflow against a performance metric that you hadn&amp;rsquo;t included in your &lt;code>tune_grid()&lt;/code> run, you&amp;rsquo;d need to re-run &lt;code>tune_grid()&lt;/code>, fitting models and predicting new values all over again. Now, using the &lt;code>compute_metrics()&lt;/code> function, you can use the &lt;code>tune_grid()&lt;/code> output you&amp;rsquo;ve already generated and compute any number of new metrics without having to fit any more models as long as you use the control option &lt;code>save_pred = TRUE&lt;/code> when tuning.&lt;/p>
&lt;p>So, say I want to additionally calculate Huber Loss and Mean Absolute Percent Error. I just pass those metrics along with the tuning result to &lt;code>compute_metrics()&lt;/code>, and the result looks just like &lt;code>collect_metrics()&lt;/code> output for the metrics originally calculated:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>compute_metrics&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>xgb_res&lt;/span>, &lt;span class='nf'>metric_set&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>huber_loss&lt;/span>, &lt;span class='nv'>mape&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 20 × 8&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; mtry learn_rate .metric .estimator mean n std_err .config &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;int&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;int&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> 2 0.002&lt;span style='text-decoration: underline;'>04&lt;/span> huber_loss standard 18.3 25 0.232 Preprocessor1_Mode…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>2&lt;/span> 2 0.002&lt;span style='text-decoration: underline;'>04&lt;/span> mape standard 94.4 25 0.068&lt;span style='text-decoration: underline;'>5&lt;/span> Preprocessor1_Mode…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>3&lt;/span> 6 0.008&lt;span style='text-decoration: underline;'>59&lt;/span> huber_loss standard 16.7 25 0.229 Preprocessor1_Mode…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>4&lt;/span> 6 0.008&lt;span style='text-decoration: underline;'>59&lt;/span> mape standard 85.7 25 0.178 Preprocessor1_Mode…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>5&lt;/span> 3 0.027&lt;span style='text-decoration: underline;'>6&lt;/span> huber_loss standard 12.6 25 0.230 Preprocessor1_Mode…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>6&lt;/span> 3 0.027&lt;span style='text-decoration: underline;'>6&lt;/span> mape standard 64.4 25 0.435 Preprocessor1_Mode…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># ℹ 14 more rows&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;h2 id="easily-pivot-resampled-metrics">Easily pivot resampled metrics
&lt;a href="#easily-pivot-resampled-metrics">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Finally, the &lt;code>collect_metrics()&lt;/code> method for tune results recently
&lt;a href="https://tune.tidymodels.org/reference/collect_predictions.html#arguments" target="_blank" rel="noopener">gained a new argument&lt;/a>, &lt;code>type&lt;/code>, indicating the shape of the returned metrics. The default, &lt;code>type = &amp;quot;long&amp;quot;&lt;/code>, is the same shape as before. The argument value &lt;code>type = &amp;quot;wide&amp;quot;&lt;/code> will allot each metric its own column, making it easier to compare metrics across different models.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>collect_metrics&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>xgb_res&lt;/span>, type &lt;span class='o'>=&lt;/span> &lt;span class='s'>"wide"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 10 × 5&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; mtry learn_rate .config rmse rsq&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;int&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> 2 0.002&lt;span style='text-decoration: underline;'>04&lt;/span> Preprocessor1_Model01 19.7 0.659&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>2&lt;/span> 6 0.008&lt;span style='text-decoration: underline;'>59&lt;/span> Preprocessor1_Model02 18.0 0.607&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>3&lt;/span> 3 0.027&lt;span style='text-decoration: underline;'>6&lt;/span> Preprocessor1_Model03 14.0 0.710&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>4&lt;/span> 2 0.037&lt;span style='text-decoration: underline;'>1&lt;/span> Preprocessor1_Model04 12.3 0.728&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>5&lt;/span> 5 0.005&lt;span style='text-decoration: underline;'>39&lt;/span> Preprocessor1_Model05 18.8 0.595&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>6&lt;/span> 9 0.011&lt;span style='text-decoration: underline;'>0&lt;/span> Preprocessor1_Model06 17.4 0.577&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># ℹ 4 more rows&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Under the hood, this is indeed just a &lt;code>pivot_wider()&lt;/code> call. We&amp;rsquo;ve found that it&amp;rsquo;s time-consuming and error-prone to programmatically determine identifying columns when pivoting resampled metrics, so we&amp;rsquo;ve localized and thoroughly tested the code that we use to do so with this feature.&lt;/p>
&lt;h2 id="more-love-for-the-brier-score">More love for the Brier score
&lt;a href="#more-love-for-the-brier-score">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Tuning and resampling functions use default metrics when the user does not specify a custom metric set. For regression models, these are RMSE and R&lt;sup>2&lt;/sup>. For classification, accuracy and the area under the ROC curve &lt;em>were&lt;/em> the default. We&amp;rsquo;ve also added the
&lt;a href="https://en.wikipedia.org/wiki/Brier_score" target="_blank" rel="noopener">Brier score&lt;/a> to the default classification metric list.&lt;/p>
&lt;h2 id="acknowledgements">Acknowledgements
&lt;a href="#acknowledgements">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>As always, we&amp;rsquo;re appreciative of the community contributors who helped make this release happen:
&lt;a href="https://github.com/AlbertoImg" target="_blank" rel="noopener">@AlbertoImg&lt;/a>,
&lt;a href="https://github.com/dramanica" target="_blank" rel="noopener">@dramanica&lt;/a>,
&lt;a href="https://github.com/epiheather" target="_blank" rel="noopener">@epiheather&lt;/a>,
&lt;a href="https://github.com/joranE" target="_blank" rel="noopener">@joranE&lt;/a>,
&lt;a href="https://github.com/jrosell" target="_blank" rel="noopener">@jrosell&lt;/a>,
&lt;a href="https://github.com/jxu" target="_blank" rel="noopener">@jxu&lt;/a>,
&lt;a href="https://github.com/kbodwin" target="_blank" rel="noopener">@kbodwin&lt;/a>,
&lt;a href="https://github.com/kenraywilliams" target="_blank" rel="noopener">@kenraywilliams&lt;/a>,
&lt;a href="https://github.com/KJT-Habitat" target="_blank" rel="noopener">@KJT-Habitat&lt;/a>,
&lt;a href="https://github.com/lionel-" target="_blank" rel="noopener">@lionel-&lt;/a>,
&lt;a href="https://github.com/marcozanotti" target="_blank" rel="noopener">@marcozanotti&lt;/a>,
&lt;a href="https://github.com/MasterLuke84" target="_blank" rel="noopener">@MasterLuke84&lt;/a>,
&lt;a href="https://github.com/mikemahoney218" target="_blank" rel="noopener">@mikemahoney218&lt;/a>,
&lt;a href="https://github.com/PathosEthosLogos" target="_blank" rel="noopener">@PathosEthosLogos&lt;/a>, and
&lt;a href="https://github.com/Peter4801" target="_blank" rel="noopener">@Peter4801&lt;/a>.&lt;/p>
&lt;div class="highlight">
&lt;/div></description></item><item><title>Survival analysis for time-to-event data with tidymodels</title><link>https://www.tidyverse.org/blog/2024/04/tidymodels-survival-analysis/</link><pubDate>Wed, 03 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2024/04/tidymodels-survival-analysis/</guid><description>&lt;!--
TODO:
* [x] Look over / edit the post's title in the yaml
* [x] Edit (or delete) the description; note this appears in the Twitter card
* [x] Pick category and tags (see existing with [`hugodown::tidy_show_meta()`](https://rdrr.io/pkg/hugodown/man/use_tidy_post.html))
* [x] Find photo &amp; update yaml metadata
* [x] Create `thumbnail-sq.jpg`; height and width should be equal
* [x] Create `thumbnail-wd.jpg`; width should be >5x height
* [x] [`hugodown::use_tidy_thumbnails()`](https://rdrr.io/pkg/hugodown/man/use_tidy_post.html)
* [x] Add intro sentence, e.g. the standard tagline for the package
* [x] [`usethis::use_tidy_thanks()`](https://usethis.r-lib.org/reference/use_tidy_thanks.html)
-->
&lt;p>We&amp;rsquo;re tickled pink to announce the support of survival analysis for time-to-event data across tidymodels. The
&lt;a href="https://www.tidymodels.org/" target="_blank" rel="noopener">tidymodels&lt;/a> framework is a collection of R packages for modeling and machine learning using tidyverse principles. This new support makes survival analysis a first-class citizen in tidymodels and gives censored regression modeling the same flexibility and ease as classification or regression.&lt;/p>
&lt;p>The functionality resides in multiple tidymodels packages. The easiest way to install them all is to install the tidymodels meta-package:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/utils/install.packages.html'>install.packages&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"tidymodels"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>This blog post will highlight why this is useful, explain which additions we&amp;rsquo;ve made to the framework, and point to several places to learn more.&lt;/p>
&lt;p>You can see a full list of changes in the release notes:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://parsnip.tidymodels.org/news/index.html#parsnip-120" target="_blank" rel="noopener">parsnip&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://censored.tidymodels.org/news/index.html#censored-030" target="_blank" rel="noopener">censored&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://yardstick.tidymodels.org/news/index.html#yardstick-130" target="_blank" rel="noopener">yardstick&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://workflows.tidymodels.org/news/index.html#workflows-114" target="_blank" rel="noopener">workflows&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://tune.tidymodels.org/news/index.html#tune-120" target="_blank" rel="noopener">tune&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://finetune.tidymodels.org/news/index.html#finetune-120" target="_blank" rel="noopener">finetune&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://workflowsets.tidymodels.org/news/index.html#workflowsets-110" target="_blank" rel="noopener">workflowsets&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="increasing-usefulness-two-perspectives">Increasing usefulness: Two perspectives
&lt;a href="#increasing-usefulness-two-perspectives">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>We&amp;rsquo;d like to situate the changes from two different perspectives: How this is useful for people already familiar with survival analysis as well as for people already familiar with tidymodels.&lt;/p>
&lt;p>If you are already familiar with both: Excellent, this is very much for you! Read on for more details on how these two things come together.&lt;/p>
&lt;h3 id="adding-tidymodels-to-your-tool-kit">Adding tidymodels to your tool kit
&lt;a href="#adding-tidymodels-to-your-tool-kit">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h3>&lt;p>If you are already familiar with survival analysis but maybe not tidymodels, these changes now unlock a whole framework for predictive modelling for you. It applies tidyverse principles to modeling, meaning it strives to be consistent, composable, and human-centered. The framework covers the modeling process from the initial test/train split of the data all the way to tuning various models. Along the way it offers a rich selection of preprocessing techniques, resampling schemes, and performance metrics along with safe-guards against accidental overfitting. We make the full case for tidymodels at
&lt;a href="https://www.tidymodels.org/" target="_blank" rel="noopener">tidymodels.org&lt;/a>.&lt;/p>
&lt;h3 id="adding-survival-analysis-to-your-tool-kit">Adding survival analysis to your tool kit
&lt;a href="#adding-survival-analysis-to-your-tool-kit">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h3>&lt;p>If you are already familiar with tidymodels but maybe not survival analysis, these changes let you leverage the familiar framework for an additional type of modeling problem. Survival analysis offers methods for modeling time-to-event data. While it has its roots in medical research, it has broad applications as that event of interest can be so much more than a medical outcome. Take customer churn as an example: We are interested in how long someone is a customer for and when they churn. For customers who churned, we have the complete time for which they were customers. For existing customers, we only know how long they&amp;rsquo;ve been customers for &lt;em>so far&lt;/em>. Such observations are called censored. So what are our modeling choices here?&lt;/p>
&lt;p>We could look at the time and model that as a regression problem. We could look at the event status and model that as a classification problem. Both options might get us somewhere close to an answer to our original modeling question but not quite there. Censored regression models let us model an outcome that includes both aspects, the time and the event status. And with that, it can deal with both censored and uncensored observations appropriately. With this type of model, we can predict the survival time, or in more applied terms, how long someone will stay as a customer. We can also predict the probability of survival at a given time point. This lets us answer questions like &amp;ldquo;How likely is it that this customer will churn after 3 months?&amp;quot;. See which prediction types are available for which models at
&lt;a href="https://censored.tidymodels.org/" target="_blank" rel="noopener">censored.tidymodels.org&lt;/a>.&lt;/p>
&lt;h2 id="ch-ch-changes-whats-new-for-censored-regression">Ch-ch-changes: What&amp;rsquo;s new for censored regression?
&lt;a href="#ch-ch-changes-whats-new-for-censored-regression">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>The main components needed for this full-fledged integration of survival analysis into tidymodels were&lt;/p>
&lt;ul>
&lt;li>Survival analysis models that can take censoring into account&lt;/li>
&lt;li>Survival analysis performance metrics that can take censoring into account&lt;/li>
&lt;li>Integrating changes required by these models and metrics into the framework&lt;/li>
&lt;/ul>
&lt;p>For the models, parsnip gained a new mode, &lt;code>&amp;quot;censored regression&amp;quot;&lt;/code>, for existing models as well as new model types such as &lt;code>proportional_hazards()&lt;/code>. Engines for these reside in censored, the parsnip extension package for survival models. The &lt;code>&amp;quot;censored regression&amp;quot;&lt;/code> mode has been around for a while and we&amp;rsquo;ve previously shared posts on
&lt;a href="https://www.tidyverse.org/blog/2021/11/survival-analysis-parsnip-adjacent/" target="_blank" rel="noopener">our initial thoughts&lt;/a> and the
&lt;a href="https://www.tidyverse.org/blog/2022/08/censored-0-1-0/" target="_blank" rel="noopener">release of censored&lt;/a>.&lt;/p>
&lt;p>Now we&amp;rsquo;ve added the metrics:
&lt;a href="https://yardstick.tidymodels.org/news/index.html#yardstick-130" target="_blank" rel="noopener">yardstick v1.3.0&lt;/a> includes new metrics for assessing censored regression models. Somewhat similar to how metrics for classification models can take class predictions or probability predictions as input, these survival metrics can take predicted survival times or predictions of survival probabilities as input.&lt;/p>
&lt;p>The new metrics are&lt;/p>
&lt;ul>
&lt;li>Concordance index on the survival time via &lt;code>concordance_survival()&lt;/code>&lt;/li>
&lt;li>Brier score on the survival probability and its integrated version via &lt;code>brier_survival()&lt;/code> and &lt;code>brier_survival_integrated()&lt;/code>&lt;/li>
&lt;li>ROC curve and the area under the ROC curve on the survival probabilities via &lt;code>roc_curve_survival()&lt;/code> and &lt;code>auc_roc_survival()&lt;/code> respectively&lt;/li>
&lt;/ul>
&lt;p>The probability of survival is always defined &lt;em>at a certain point in time&lt;/em>. We call that time point the &lt;em>evaluation time&lt;/em> because it is then also the time point at which we want to evaluate model performance. Metrics that work on the survival probabilities are also called &lt;em>dynamic metrics&lt;/em> and you can read more about them here:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://www.tidymodels.org/learn/statistics/survival-metrics/" target="_blank" rel="noopener">Dynamic Performance Metrics for Event Time Data&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.tidymodels.org/learn/statistics/survival-metrics-details/" target="_blank" rel="noopener">Accounting for Censoring in Performance Metrics for Event Time Data&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>The evaluation time is also the best example to illustrate the changes necessary to the framework. Most of them were under the hood but the evaluation time is user-facing. Let&amp;rsquo;s take a look at that.&lt;/p>
&lt;p>While the need for evaluation times is dependent on type of metric, it is not actually specified as an argument to the metric functions. Like yardstick&amp;rsquo;s other metrics, those take pre-made predictions as the input. So where do you specify it then?&lt;/p>
&lt;ul>
&lt;li>You need to specify it to directly predict survival probabilities, via
&lt;a href="https://rdrr.io/r/stats/predict.html" target="_blank" rel="noopener">&lt;code>predict()&lt;/code>&lt;/a> or &lt;code>augment()&lt;/code>. We introduced the corresponding &lt;code>eval_time&lt;/code> argument first for fitted models in
&lt;a href="https://www.tidyverse.org/blog/2023/04/censored-0-2-0/#introducing-eval_time" target="_blank" rel="noopener">parsnip and censored&lt;/a> and have added it now for workflows.&lt;/li>
&lt;li>You also need to specify it for the tuning functions &lt;code>tune_*()&lt;/code> from tune and finetune as they will predict survival probabilities as part of the tuning process.&lt;/li>
&lt;li>Lastly, the &lt;code>eval_time&lt;/code> argument now shows up when working with tuning/resampling results such as in &lt;code>show_best()&lt;/code> or &lt;code>autoplot()&lt;/code>. Those changes span the packages generating and working with resampling results: tune, finetune, and workflowsets.&lt;/li>
&lt;/ul>
&lt;p>As we said, plenty of changes under the hood but you shouldn&amp;rsquo;t need to notice them. Everything else should work &amp;ldquo;as usual,&amp;rdquo; allowing the same ease and flexibility in combining tidymodels functionality for censored regression as for classification and regression.&lt;/p>
&lt;h2 id="the-pieces-come-together-a-case-study">The pieces come together: A case study
&lt;a href="#the-pieces-come-together-a-case-study">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>To see it all in action, check out the case study
&lt;a href="https://www.tidymodels.org/learn/statistics/survival-case-study/" target="_blank" rel="noopener">How long until building complaints are dispositioned?&lt;/a> on the tidymodels website!&lt;/p>
&lt;p>The city of New York publishes data on complaints received by the Department of Buildings that include how long it takes for a complaint to be dealt with (&amp;ldquo;dispositioned&amp;rdquo;) as well as several characteristics of the complaint. The case study covers a full analysis. We start with splitting the data into test and training sets, explore different preprocessing strategies and model types via tuning, and predict with a final model. It should give you a good first impression of how to use tidymodels for predictive survival analysis.&lt;/p>
&lt;p>We hope you&amp;rsquo;ll find this new capability of tidymodels useful!&lt;/p>
&lt;h2 id="acknowledgements">Acknowledgements
&lt;a href="#acknowledgements">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Many thanks to the people who contributed to our packages since their last release:&lt;/p>
&lt;p>&lt;strong>parsnip:&lt;/strong>
&lt;a href="https://github.com/AlbanOtt2" target="_blank" rel="noopener">@AlbanOtt2&lt;/a>,
&lt;a href="https://github.com/birbritto" target="_blank" rel="noopener">@birbritto&lt;/a>,
&lt;a href="https://github.com/christophscheuch" target="_blank" rel="noopener">@christophscheuch&lt;/a>,
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/Freestyleyang" target="_blank" rel="noopener">@Freestyleyang&lt;/a>,
&lt;a href="https://github.com/gmcmacran" target="_blank" rel="noopener">@gmcmacran&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/jmunyoon" target="_blank" rel="noopener">@jmunyoon&lt;/a>,
&lt;a href="https://github.com/joscani" target="_blank" rel="noopener">@joscani&lt;/a>,
&lt;a href="https://github.com/jxu" target="_blank" rel="noopener">@jxu&lt;/a>,
&lt;a href="https://github.com/marcelglueck" target="_blank" rel="noopener">@marcelglueck&lt;/a>,
&lt;a href="https://github.com/mattheaphy" target="_blank" rel="noopener">@mattheaphy&lt;/a>,
&lt;a href="https://github.com/mesdi" target="_blank" rel="noopener">@mesdi&lt;/a>,
&lt;a href="https://github.com/millermc38" target="_blank" rel="noopener">@millermc38&lt;/a>,
&lt;a href="https://github.com/nipnipj" target="_blank" rel="noopener">@nipnipj&lt;/a>,
&lt;a href="https://github.com/pgg1309" target="_blank" rel="noopener">@pgg1309&lt;/a>,
&lt;a href="https://github.com/rdavis120" target="_blank" rel="noopener">@rdavis120&lt;/a>,
&lt;a href="https://github.com/seb-mueller" target="_blank" rel="noopener">@seb-mueller&lt;/a>,
&lt;a href="https://github.com/SHo-JANG" target="_blank" rel="noopener">@SHo-JANG&lt;/a>,
&lt;a href="https://github.com/simonpcouch" target="_blank" rel="noopener">@simonpcouch&lt;/a>,
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>,
&lt;a href="https://github.com/vidarsumo" target="_blank" rel="noopener">@vidarsumo&lt;/a>, and
&lt;a href="https://github.com/wzbillings" target="_blank" rel="noopener">@wzbillings&lt;/a>.&lt;/p>
&lt;p>&lt;strong>censored:&lt;/strong>
&lt;a href="https://github.com/bcjaeger" target="_blank" rel="noopener">@bcjaeger&lt;/a>,
&lt;a href="https://github.com/brunocarlin" target="_blank" rel="noopener">@brunocarlin&lt;/a>,
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/noahtsao" target="_blank" rel="noopener">@noahtsao&lt;/a>, and
&lt;a href="https://github.com/tripartio" target="_blank" rel="noopener">@tripartio&lt;/a>.&lt;/p>
&lt;p>&lt;strong>yardstick:&lt;/strong>
&lt;a href="https://github.com/aecoleman" target="_blank" rel="noopener">@aecoleman&lt;/a>,
&lt;a href="https://github.com/asb2111" target="_blank" rel="noopener">@asb2111&lt;/a>,
&lt;a href="https://github.com/atsyplenkov" target="_blank" rel="noopener">@atsyplenkov&lt;/a>,
&lt;a href="https://github.com/bgreenwell" target="_blank" rel="noopener">@bgreenwell&lt;/a>,
&lt;a href="https://github.com/Dpananos" target="_blank" rel="noopener">@Dpananos&lt;/a>,
&lt;a href="https://github.com/EduMinsky" target="_blank" rel="noopener">@EduMinsky&lt;/a>,
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/heidekrueger" target="_blank" rel="noopener">@heidekrueger&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/iacrowe" target="_blank" rel="noopener">@iacrowe&lt;/a>,
&lt;a href="https://github.com/jarbet" target="_blank" rel="noopener">@jarbet&lt;/a>,
&lt;a href="https://github.com/jxu" target="_blank" rel="noopener">@jxu&lt;/a>,
&lt;a href="https://github.com/mattwarkentin" target="_blank" rel="noopener">@mattwarkentin&lt;/a>,
&lt;a href="https://github.com/maxwell-geospatial" target="_blank" rel="noopener">@maxwell-geospatial&lt;/a>,
&lt;a href="https://github.com/moloscripts" target="_blank" rel="noopener">@moloscripts&lt;/a>,
&lt;a href="https://github.com/rdavis120" target="_blank" rel="noopener">@rdavis120&lt;/a>,
&lt;a href="https://github.com/ruddnr" target="_blank" rel="noopener">@ruddnr&lt;/a>,
&lt;a href="https://github.com/SimonCoulombe" target="_blank" rel="noopener">@SimonCoulombe&lt;/a>,
&lt;a href="https://github.com/simonpcouch" target="_blank" rel="noopener">@simonpcouch&lt;/a>,
&lt;a href="https://github.com/tbrittoborges" target="_blank" rel="noopener">@tbrittoborges&lt;/a>,
&lt;a href="https://github.com/tonyelhabr" target="_blank" rel="noopener">@tonyelhabr&lt;/a>,
&lt;a href="https://github.com/tripartio" target="_blank" rel="noopener">@tripartio&lt;/a>,
&lt;a href="https://github.com/TSI-PTG" target="_blank" rel="noopener">@TSI-PTG&lt;/a>,
&lt;a href="https://github.com/vnijs" target="_blank" rel="noopener">@vnijs&lt;/a>,
&lt;a href="https://github.com/wbuchanan" target="_blank" rel="noopener">@wbuchanan&lt;/a>, and
&lt;a href="https://github.com/zkrog" target="_blank" rel="noopener">@zkrog&lt;/a>.&lt;/p>
&lt;p>&lt;strong>workflows:&lt;/strong>
&lt;a href="https://github.com/Milardkh" target="_blank" rel="noopener">@Milardkh&lt;/a>,
&lt;a href="https://github.com/simonpcouch" target="_blank" rel="noopener">@simonpcouch&lt;/a>, and
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>.&lt;/p>
&lt;p>&lt;strong>tune:&lt;/strong>
&lt;a href="https://github.com/AlbertoImg" target="_blank" rel="noopener">@AlbertoImg&lt;/a>,
&lt;a href="https://github.com/dramanica" target="_blank" rel="noopener">@dramanica&lt;/a>,
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/epiheather" target="_blank" rel="noopener">@epiheather&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/joranE" target="_blank" rel="noopener">@joranE&lt;/a>,
&lt;a href="https://github.com/jrosell" target="_blank" rel="noopener">@jrosell&lt;/a>,
&lt;a href="https://github.com/jxu" target="_blank" rel="noopener">@jxu&lt;/a>,
&lt;a href="https://github.com/kbodwin" target="_blank" rel="noopener">@kbodwin&lt;/a>,
&lt;a href="https://github.com/kenraywilliams" target="_blank" rel="noopener">@kenraywilliams&lt;/a>,
&lt;a href="https://github.com/KJT-Habitat" target="_blank" rel="noopener">@KJT-Habitat&lt;/a>,
&lt;a href="https://github.com/lionel-" target="_blank" rel="noopener">@lionel-&lt;/a>,
&lt;a href="https://github.com/marcozanotti" target="_blank" rel="noopener">@marcozanotti&lt;/a>,
&lt;a href="https://github.com/MasterLuke84" target="_blank" rel="noopener">@MasterLuke84&lt;/a>,
&lt;a href="https://github.com/mikemahoney218" target="_blank" rel="noopener">@mikemahoney218&lt;/a>,
&lt;a href="https://github.com/PathosEthosLogos" target="_blank" rel="noopener">@PathosEthosLogos&lt;/a>,
&lt;a href="https://github.com/Peter4801" target="_blank" rel="noopener">@Peter4801&lt;/a>,
&lt;a href="https://github.com/simonpcouch" target="_blank" rel="noopener">@simonpcouch&lt;/a>,
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>, and
&lt;a href="https://github.com/walkerjameschris" target="_blank" rel="noopener">@walkerjameschris&lt;/a>.&lt;/p>
&lt;p>&lt;strong>finetune:&lt;/strong>
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/jdberson" target="_blank" rel="noopener">@jdberson&lt;/a>,
&lt;a href="https://github.com/jrosell" target="_blank" rel="noopener">@jrosell&lt;/a>,
&lt;a href="https://github.com/mfansler" target="_blank" rel="noopener">@mfansler&lt;/a>,
&lt;a href="https://github.com/ruddnr" target="_blank" rel="noopener">@ruddnr&lt;/a>,
&lt;a href="https://github.com/simonpcouch" target="_blank" rel="noopener">@simonpcouch&lt;/a>, and
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>.&lt;/p>
&lt;p>&lt;strong>workflowsets:&lt;/strong>
&lt;a href="https://github.com/dchiu911" target="_blank" rel="noopener">@dchiu911&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/jkylearmstrong" target="_blank" rel="noopener">@jkylearmstrong&lt;/a>,
&lt;a href="https://github.com/PathosEthosLogos" target="_blank" rel="noopener">@PathosEthosLogos&lt;/a>, and
&lt;a href="https://github.com/simonpcouch" target="_blank" rel="noopener">@simonpcouch&lt;/a>.&lt;/p></description></item><item><title>Fair machine learning with tidymodels</title><link>https://www.tidyverse.org/blog/2024/03/tidymodels-fairness/</link><pubDate>Thu, 21 Mar 2024 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2024/03/tidymodels-fairness/</guid><description>&lt;p>We&amp;rsquo;re very, very excited to announce the introduction of tools for assessing model fairness in tidymodels. This effort involved coordination from various groups at Posit over the course of over a year and resulted in a toolkit that we believe is both principled and impactful.&lt;/p>
&lt;p>Fairness assessment features for tidymodels extend across a number of packages; to install each, use the tidymodels meta-package:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/utils/install.packages.html'>install.packages&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"tidymodels"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;h2 id="machine-learning-fairness">Machine learning fairness
&lt;a href="#machine-learning-fairness">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>In recent years, high-profile analyses have called attention to many contexts where the use of machine learning deepened inequities in our communities. In late 2022, a group of Posit employees across teams, roles, and technical backgrounds formed a reading group to engage with literature on machine learning fairness, a research field that aims to define what it means for a statistical model to act unfairly and take measures to address that unfairness. We then designed new software functionality and learning resources to help data scientists measure and critique the ways in which the machine learning models they&amp;rsquo;ve built might disparately impact people affected by that model.&lt;/p>
&lt;p>Perhaps the core question that fairness as a research field has tried to address is exactly what a machine learning model acting fairly entails. As a recent primer notes, &amp;ldquo;[t]he rapid growth of this new field has led to wildly inconsistent motivations, terminology, and notation, presenting a serious challenge for cataloging and comparing definitions&amp;rdquo; (Mitchell et al. 2021).&lt;/p>
&lt;p>Broadly, approaches to fairness provide tooling&amp;mdash;whether social or algorithmic&amp;mdash;to understand the social implications of utilizing a machine learning model. Different researchers categorize approaches to fairness differently, but work in this area can be loosely summarized as falling into one or more of the following categories: assessment, mitigation, and critique.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;em>Assessment&lt;/em>: Fairness assessment tooling allows practitioners to measure the degree to which a machine learning model acts unfairly given some definition of fairness. The chosen definition of fairness greatly impacts whether a model&amp;rsquo;s predictions are regarded as fair. While there have been many, many definitions of fairness proposed&amp;mdash;a popular tutorial on these approaches compares 21 canonical definitions&amp;mdash;most all of them involve simple inequalities based on a small set of conditional probabilities (Narayanan 2018; Mitchell et al. 2021).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Mitigation&lt;/em>: Given a fairness assessment, mitigation approaches reduce the degree to which a machine learning model acts unfairly given some definition of fairness. Making a model more fair according to one metric may make that model less fair according to another. Approaches to mitigation are subject to impossibility theorems, which show that &amp;ldquo;definitions are not mathematically or morally compatible in general&amp;rdquo; (Mitchell et al. 2021). That is, there is no way to satisfy many fairness constraints at once unless we live in a world with no inequality to start with. However, more recent studies have shown that near-fairness with respect to several definitions is quite possible (Bell et al. 2023).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Critique&lt;/em>: While approaches to assessment and mitigation seek to reduce complexity and situate notions of fairness in mathematical formalism, sociotechnical critique provides tooling to better understand how mathematical notions of fairness may fail to account for the real-world complexity of social phenomena. Work in this discipline often reveals that, in the process of measuring or addressing unfairness by some definition, methods for fairness assessment and mitigation may actually ignore, necessitate, or introduce unfairness by some other definition.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>The work of scoping Posit&amp;rsquo;s resources for fair machine learning, in large part, involved striking the right balance between tools in these categories and integrating them thoughtfully among our existing functionality. Rather than supporting as many fairness-oriented tools as possible, our goal is to best enable users of our tools to reason well about the fairness-relevant decisions they make throughout the modeling process.&lt;/p>
&lt;h2 id="additions-to-tidymodels">Additions to tidymodels
&lt;a href="#additions-to-tidymodels">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>The most recent set of tidymodels releases include changes that provide support for assessment and critique using the tidymodels framework.&lt;/p>
&lt;!-- TODO: change the tidymodels.org urls to the merged versions -->
&lt;p>The most recent yardstick release introduces
&lt;a href="https://yardstick.tidymodels.org/reference/new_groupwise_metric.html" target="_blank" rel="noopener">a tool to create fairness metrics&lt;/a> with the problem context in mind, as well as
&lt;a href="https://yardstick.tidymodels.org/reference/index.html#fairness-metrics" target="_blank" rel="noopener">some outputs of that tool&lt;/a> implementing common fairness metrics. For a higher-level introduction to the concept of a groupwise metric, we&amp;rsquo;ve also introduced a
&lt;a href="https://yardstick.tidymodels.org/articles/grouping.html" target="_blank" rel="noopener">new package vignette&lt;/a>. To see those fairness metrics in action, see
&lt;a href="https://www.tidymodels.org/learn/work/fairness-detectors/" target="_blank" rel="noopener">this new article on tidymodels.org&lt;/a>, a case study using data about GPT detectors.&lt;/p>
&lt;p>The most recent tune release integrates support for those fairness metrics from yardstick, allowing users to evaluate fairness criteria across resamples. To demonstrate those features in context, we&amp;rsquo;ve added
&lt;a href="https://www.tidymodels.org/learn/work/fairness-readmission/" target="_blank" rel="noopener">another new article on tidymodels.org&lt;/a>, modeling hospital readmission for patients with Type I diabetes.&lt;/p>
&lt;p>Notably, we haven&amp;rsquo;t introduced functionality to support mitigation. While a number of methods have proliferated over the years to finetune models to act more fairly with respect to some fairness criteria, each apply only in relatively niche applications with modest experimental results (Agarwal et al. 2018; Mittelstadt, Wachter, and Russell 2023). For now, we believe that, in practice, the efforts of practitioners&amp;mdash;and thus our efforts to support them&amp;mdash;are better spent engaging with the sociotechnical context of a given modeling problem (Holstein et al. 2019).&lt;/p>
&lt;p>We&amp;rsquo;re excited to support modeling practitioners in fairness-oriented analysis of models and look forward to seeing how these methods are put to work.&lt;/p>
&lt;h2 id="references">References
&lt;a href="#references">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
&lt;div id="ref-agarwal2018" class="csl-entry">
&lt;p>Agarwal, Alekh, Alina Beygelzimer, Miroslav Dudı́k, John Langford, and Hanna Wallach. 2018. &amp;ldquo;A Reductions Approach to Fair Classification.&amp;rdquo; In &lt;em>International Conference on Machine Learning&lt;/em>, 60&amp;ndash;69. PMLR.&lt;/p>
&lt;/div>
&lt;div id="ref-bell2023" class="csl-entry">
&lt;p>Bell, Andrew, Lucius Bynum, Nazarii Drushchak, Tetiana Zakharchenko, Lucas Rosenblatt, and Julia Stoyanovich. 2023. &amp;ldquo;The Possibility of Fairness: Revisiting the Impossibility Theorem in Practice.&amp;rdquo; In &lt;em>Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency&lt;/em>, 400&amp;ndash;422. FAccT &amp;lsquo;23. New York, NY, USA: Association for Computing Machinery. &lt;a href="https://doi.org/10.1145/3593013.3594007">https://doi.org/10.1145/3593013.3594007&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-holstein2019" class="csl-entry">
&lt;p>Holstein, Kenneth, Jennifer Wortman Vaughan, Hal Daumé III, Miro Dudik, and Hanna Wallach. 2019. &amp;ldquo;Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?&amp;rdquo; In &lt;em>Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems&lt;/em>, 1&amp;ndash;16.&lt;/p>
&lt;/div>
&lt;div id="ref-mitchell2021" class="csl-entry">
&lt;p>Mitchell, Shira, Eric Potash, Solon Barocas, Alexander D&amp;rsquo;Amour, and Kristian Lum. 2021. &amp;ldquo;Algorithmic Fairness: Choices, Assumptions, and Definitions.&amp;rdquo; &lt;em>Annual Review of Statistics and Its Application&lt;/em> 8 (1): 141&amp;ndash;63. &lt;a href="https://doi.org/10.1146/annurev-statistics-042720-125902">https://doi.org/10.1146/annurev-statistics-042720-125902&lt;/a>.&lt;/p>
&lt;/div>
&lt;div id="ref-mittelstadt2023" class="csl-entry">
&lt;p>Mittelstadt, Brent, Sandra Wachter, and Chris Russell. 2023. &amp;ldquo;The Unfairness of Fair Machine Learning: Levelling down and Strict Egalitarianism by Default.&amp;rdquo; &lt;em>arXiv Preprint arXiv:2302.02404&lt;/em>.&lt;/p>
&lt;/div>
&lt;div id="ref-narayanan2018" class="csl-entry">
&lt;p>Narayanan, Arvind. 2018. &amp;ldquo;Translation Tutorial: 21 Fairness Definitions and Their Politics.&amp;rdquo; In &lt;em>Proc. Conf. Fairness Accountability Transp., New York, Usa&lt;/em>, 1170:3.&lt;/p>
&lt;/div>
&lt;/div></description></item><item><title>Three ways errors are about to get better in tidymodels</title><link>https://www.tidyverse.org/blog/2023/11/tidymodels-errors-q4/</link><pubDate>Fri, 10 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2023/11/tidymodels-errors-q4/</guid><description>&lt;p>Twice a year, the tidymodels team comes together for &amp;ldquo;spring cleaning,&amp;rdquo; a week-long project devoted to package maintenance. Ahead of the week, we come up with a list of maintenance tasks that we&amp;rsquo;d like to see consistently implemented across our packages. Many of these tasks can be completed by running one usethis function, while others are much more involved, like issue triage.&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> In tidymodels, triaging issues in our core packages helps us to better understand common ways that users struggle to wrap their heads around an API choice we&amp;rsquo;ve made or find the information they need. So, among other things, refinements to the wording of our error messages is a common output of our spring cleanings. This blog post will call out three kinds of changes to our erroring that came out of this spring cleaning:&lt;/p>
&lt;ul>
&lt;li>Improving existing errors:
&lt;a href="#outcome">The outcome went missing&lt;/a>&lt;/li>
&lt;li>Do something where we once did nothing:
&lt;a href="#predict">Predicting with things that can&amp;rsquo;t predict&lt;/a>&lt;/li>
&lt;li>Make a place and point to it:
&lt;a href="#model">Model formulas&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>To demonstrate, we&amp;rsquo;ll walk through some examples using the tidymodels packages:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='kr'>&lt;a href='https://rdrr.io/r/base/library.html'>library&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>&lt;a href='https://tidymodels.tidymodels.org'>tidymodels&lt;/a>&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; ── &lt;span style='font-weight: bold;'>Attaching packages&lt;/span> ──────────────────────────── tidymodels 1.1.1 ──&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>broom &lt;/span> 1.0.5 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>recipes &lt;/span> 1.0.8.&lt;span style='color: #BB0000;'>9000&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>dials &lt;/span> 1.2.0 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>rsample &lt;/span> 1.2.0 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>dplyr &lt;/span> 1.1.3 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>tibble &lt;/span> 3.2.1 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>ggplot2 &lt;/span> 3.4.4 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>tidyr &lt;/span> 1.3.0 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>infer &lt;/span> 1.0.5 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>tune &lt;/span> 1.1.2.&lt;span style='color: #BB0000;'>9000&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>modeldata &lt;/span> 1.2.0 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>workflows &lt;/span> 1.1.3 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>parsnip &lt;/span> 1.1.1.&lt;span style='color: #BB0000;'>9001&lt;/span> &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>workflowsets&lt;/span> 1.0.1 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>purrr &lt;/span> 1.0.2 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>yardstick &lt;/span> 1.2.0&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;span class='c'>#&amp;gt; ── &lt;span style='font-weight: bold;'>Conflicts&lt;/span> ─────────────────────────────── tidymodels_conflicts() ──&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BB0000;'>✖&lt;/span> &lt;span style='color: #0000BB;'>purrr&lt;/span>::&lt;span style='color: #00BB00;'>discard()&lt;/span> masks &lt;span style='color: #0000BB;'>scales&lt;/span>::discard()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BB0000;'>✖&lt;/span> &lt;span style='color: #0000BB;'>dplyr&lt;/span>::&lt;span style='color: #00BB00;'>filter()&lt;/span> masks &lt;span style='color: #0000BB;'>stats&lt;/span>::filter()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BB0000;'>✖&lt;/span> &lt;span style='color: #0000BB;'>dplyr&lt;/span>::&lt;span style='color: #00BB00;'>lag()&lt;/span> masks &lt;span style='color: #0000BB;'>stats&lt;/span>::lag()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BB0000;'>✖&lt;/span> &lt;span style='color: #0000BB;'>recipes&lt;/span>::&lt;span style='color: #00BB00;'>step()&lt;/span> masks &lt;span style='color: #0000BB;'>stats&lt;/span>::step()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #0000BB;'>•&lt;/span> Use suppressPackageStartupMessages() to eliminate package startup messages&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Note that my installed versions include the current dev version of a few tidymodels packages. You can install those versions with:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>pak&lt;/span>&lt;span class='nf'>::&lt;/span>&lt;span class='nf'>&lt;a href='https://pak.r-lib.org/reference/pak.html'>pak&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/paste.html'>paste0&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"tidymodels/"&lt;/span>, &lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/c.html'>c&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"tune"&lt;/span>, &lt;span class='s'>"parsnip"&lt;/span>, &lt;span class='s'>"recipes"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;h2 id="the-outcome-went-missing-">The outcome went missing 👻
&lt;a href="#the-outcome-went-missing-">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>The tidymodels packages focus on &lt;em>supervised&lt;/em> machine learning problems, predicting the value of an outcome using predictors.&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> For example, in the code:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nv'>linear_spec&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>linear_reg&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>linear_fit&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>fit&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>linear_spec&lt;/span>, &lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>hp&lt;/span>, &lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>The &lt;code>mpg&lt;/code> variable is the outcome. There are many ways that an analyst may mistakenly fail to pass an outcome. In the most straightforward case, they might omit the outcome on the LHS of the formula:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">fit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">linear_spec&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">hp&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">mtcars&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1">#&amp;gt; Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : &lt;/span>
&lt;span class="c1">#&amp;gt; incompatible dimensions&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In this case, parsnip used to defer to the modeling engine to raise an error, which may or may not be informative.&lt;/p>
&lt;p>There are many less obvious ways an analyst may mistakenly supply no outcome variable. For example, try spotting the issue in the following code, defining a recipe to perform principal component analysis (PCA) on the numeric variables in the data before fitting the model:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">mtcars_rec&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">recipe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mpg&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">.,&lt;/span> &lt;span class="n">mtcars&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">step_pca&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">all_numeric&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="nf">workflow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mtcars_rec&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">linear_spec&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span> &lt;span class="nf">fit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mtcars&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1">#&amp;gt; Error: object &amp;#39;.&amp;#39; not found&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>A head-scratcher! To help diagnose what&amp;rsquo;s happening here, we could first try seeing what data is actually being passed to the model.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nv'>mtcars_rec_trained&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span>&lt;/span>
&lt;span> &lt;span class='nv'>mtcars_rec&lt;/span> &lt;span class='o'>%&amp;gt;%&lt;/span> &lt;/span>
&lt;span> &lt;span class='nf'>prep&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span> &lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>mtcars_rec_trained&lt;/span> &lt;span class='o'>%&amp;gt;%&lt;/span> &lt;span class='nf'>bake&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='kc'>NULL&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 32 × 5&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; PC1 PC2 PC3 PC4 PC5&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 1&lt;/span> -&lt;span style='color: #BB0000;'>195.&lt;/span> 12.8 -&lt;span style='color: #BB0000;'>11.4&lt;/span> 0.016&lt;span style='text-decoration: underline;'>4&lt;/span> 2.17 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 2&lt;/span> -&lt;span style='color: #BB0000;'>195.&lt;/span> 12.9 -&lt;span style='color: #BB0000;'>11.7&lt;/span> -&lt;span style='color: #BB0000;'>0.479&lt;/span> 2.11 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 3&lt;/span> -&lt;span style='color: #BB0000;'>142.&lt;/span> 25.9 -&lt;span style='color: #BB0000;'>16.0&lt;/span> -&lt;span style='color: #BB0000;'>1.34&lt;/span> -&lt;span style='color: #BB0000;'>1.18&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 4&lt;/span> -&lt;span style='color: #BB0000;'>279.&lt;/span> -&lt;span style='color: #BB0000;'>38.3&lt;/span> -&lt;span style='color: #BB0000;'>14.0&lt;/span> 0.157 -&lt;span style='color: #BB0000;'>0.817&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 5&lt;/span> -&lt;span style='color: #BB0000;'>399.&lt;/span> -&lt;span style='color: #BB0000;'>37.3&lt;/span> -&lt;span style='color: #BB0000;'>1.38&lt;/span> 2.56 -&lt;span style='color: #BB0000;'>0.444&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 6&lt;/span> -&lt;span style='color: #BB0000;'>248.&lt;/span> -&lt;span style='color: #BB0000;'>25.6&lt;/span> -&lt;span style='color: #BB0000;'>12.2&lt;/span> -&lt;span style='color: #BB0000;'>3.01&lt;/span> -&lt;span style='color: #BB0000;'>1.08&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 7&lt;/span> -&lt;span style='color: #BB0000;'>435.&lt;/span> 20.9 13.9 0.801 -&lt;span style='color: #BB0000;'>0.916&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 8&lt;/span> -&lt;span style='color: #BB0000;'>160.&lt;/span> -&lt;span style='color: #BB0000;'>20.0&lt;/span> -&lt;span style='color: #BB0000;'>23.3&lt;/span> -&lt;span style='color: #BB0000;'>1.06&lt;/span> 0.787&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 9&lt;/span> -&lt;span style='color: #BB0000;'>172.&lt;/span> 10.8 -&lt;span style='color: #BB0000;'>18.3&lt;/span> -&lt;span style='color: #BB0000;'>4.40&lt;/span> -&lt;span style='color: #BB0000;'>0.836&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>10&lt;/span> -&lt;span style='color: #BB0000;'>209.&lt;/span> 19.7 -&lt;span style='color: #BB0000;'>8.94&lt;/span> -&lt;span style='color: #BB0000;'>2.58&lt;/span> 1.33 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># ℹ 22 more rows&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Mmm. What happened to &lt;code>mpg&lt;/code>? We mistakenly told &lt;code>step_pca()&lt;/code> to perform PCA on &lt;em>all&lt;/em> of the numeric variables, not just the numeric &lt;em>predictors&lt;/em>! As a result, it incorporated &lt;code>mpg&lt;/code> into the principal components, removing each of the original numeric variables after the fact. Rewriting using the correct tidyselect specification &lt;code>all_numeric_predictors()&lt;/code>:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nv'>mtcars_rec_new&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;/span>
&lt;span> &lt;span class='nf'>recipe&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>.&lt;/span>, &lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span> &lt;span class='o'>%&amp;gt;%&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>step_pca&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nf'>all_numeric_predictors&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nf'>workflow&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars_rec_new&lt;/span>, &lt;span class='nv'>linear_spec&lt;/span>&lt;span class='o'>)&lt;/span> &lt;span class='o'>%&amp;gt;%&lt;/span> &lt;span class='nf'>fit&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; ══ Workflow [trained] ════════════════════════════════════════════════&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='font-style: italic;'>Preprocessor:&lt;/span> Recipe&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='font-style: italic;'>Model:&lt;/span> linear_reg()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; ── Preprocessor ──────────────────────────────────────────────────────&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; 1 Recipe Step&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; • step_pca()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; ── Model ─────────────────────────────────────────────────────────────&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Call:&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; stats::lm(formula = ..y ~ ., data = data)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Coefficients:&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; (Intercept) PC1 PC2 PC3 PC4 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; 43.39293 0.07609 -0.05266 0.57892 0.94890 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; PC5 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; -1.72569&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Works like a charm. That error we saw previously could be much more helpful, though. With the current developmental version of parsnip, this looks like:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>fit&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>linear_spec&lt;/span>, &lt;span class='o'>~&lt;/span> &lt;span class='nv'>hp&lt;/span>, &lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BBBB00; font-weight: bold;'>Error&lt;/span>&lt;span style='font-weight: bold;'>:&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BBBB00;'>!&lt;/span> `linear_reg()` was unable to find an outcome.&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BBBB;'>ℹ&lt;/span> Ensure that you have specified an outcome column and that it hasn't&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; been removed in pre-processing.&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Or, with workflows:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>workflow&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars_rec&lt;/span>, &lt;span class='nv'>linear_spec&lt;/span>&lt;span class='o'>)&lt;/span> &lt;span class='o'>%&amp;gt;%&lt;/span> &lt;span class='nf'>fit&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BBBB00; font-weight: bold;'>Error&lt;/span>&lt;span style='font-weight: bold;'>:&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BBBB00;'>!&lt;/span> `linear_reg()` was unable to find an outcome.&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BBBB;'>ℹ&lt;/span> Ensure that you have specified an outcome column and that it hasn't&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; been removed in pre-processing.&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Much better.&lt;/p>
&lt;h2 id="predicting-with-things-that-cant-predict">Predicting with things that can&amp;rsquo;t predict
&lt;a href="#predicting-with-things-that-cant-predict">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Earlier this year, Dr. Louise E. Sinks put out a
&lt;a href="https://lsinks.github.io/posts/2023-04-10-tidymodels/tidymodels_tutorial.html" target="_blank" rel="noopener">wonderful blog post&lt;/a> documenting what it felt like to approach the various object types defined in the tidymodels as a newcomer to the collection of packages. They wrote:&lt;/p>
&lt;blockquote>
&lt;p>I found it confusing that &lt;code>fit&lt;/code>, &lt;code>last_fit&lt;/code>, &lt;code>fit_resamples&lt;/code>, etc., did not all produce objects that contained the same information and could be acted on by the same functions.&lt;/p>
&lt;/blockquote>
&lt;p>This makes sense. While we try to forefront the intended mental model for fitting and predicting with tidymodels in our APIs and documentation, we also need to be proactive in anticipating common challenges in constructing that mental model.&lt;/p>
&lt;p>For example, we&amp;rsquo;ve found that it&amp;rsquo;s sometimes not clear to users which outputs they can call
&lt;a href="https://rdrr.io/r/stats/predict.html" target="_blank" rel="noopener">&lt;code>predict()&lt;/code>&lt;/a> on. One such situation, as Louise points out, is with &lt;code>fit_resamples()&lt;/code>:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='c'># fit a linear regression model to bootstrap resamples of mtcars&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>mtcars_res&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>fit_resamples&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nf'>linear_reg&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>, &lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>.&lt;/span>, &lt;span class='nf'>bootstraps&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>mtcars_res&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; # Resampling results&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; # Bootstrap sampling &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 25 × 4&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; splits id .metrics .notes &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 1&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/11]&amp;gt;&lt;/span> Bootstrap01 &lt;span style='color: #555555;'>&amp;lt;tibble [2 × 4]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 2&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/10]&amp;gt;&lt;/span> Bootstrap02 &lt;span style='color: #555555;'>&amp;lt;tibble [2 × 4]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 3&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/16]&amp;gt;&lt;/span> Bootstrap03 &lt;span style='color: #555555;'>&amp;lt;tibble [2 × 4]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 4&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/11]&amp;gt;&lt;/span> Bootstrap04 &lt;span style='color: #555555;'>&amp;lt;tibble [2 × 4]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 5&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/10]&amp;gt;&lt;/span> Bootstrap05 &lt;span style='color: #555555;'>&amp;lt;tibble [2 × 4]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 6&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/13]&amp;gt;&lt;/span> Bootstrap06 &lt;span style='color: #555555;'>&amp;lt;tibble [2 × 4]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 7&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/16]&amp;gt;&lt;/span> Bootstrap07 &lt;span style='color: #555555;'>&amp;lt;tibble [2 × 4]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 8&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/11]&amp;gt;&lt;/span> Bootstrap08 &lt;span style='color: #555555;'>&amp;lt;tibble [2 × 4]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 9&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/11]&amp;gt;&lt;/span> Bootstrap09 &lt;span style='color: #555555;'>&amp;lt;tibble [2 × 4]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>10&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/10]&amp;gt;&lt;/span> Bootstrap10 &lt;span style='color: #555555;'>&amp;lt;tibble [2 × 4]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># ℹ 15 more rows&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>With previous tidymodels versions, mistakenly trying to predict with this object resulted in the following output:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">predict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mtcars_res&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1">#&amp;gt; Error in UseMethod(&amp;#34;predict&amp;#34;) : &lt;/span>
&lt;span class="c1">#&amp;gt; no applicable method for &amp;#39;predict&amp;#39; applied to an object of class&lt;/span>
&lt;span class="c1">#&amp;gt; &amp;#34;c(&amp;#39;resample_results&amp;#39;, &amp;#39;tune_results&amp;#39;, &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39;, &amp;#39;data.frame&amp;#39;)&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Some R developers may recognize this error as what results when we didn&amp;rsquo;t define any
&lt;a href="https://rdrr.io/r/stats/predict.html" target="_blank" rel="noopener">&lt;code>predict()&lt;/code>&lt;/a> method for &lt;code>tune_results&lt;/code> objects. We didn&amp;rsquo;t do so because prediction isn&amp;rsquo;t well-defined for tuning results. &lt;em>But&lt;/em>, this error message does little to help a user understand why that&amp;rsquo;s the case.&lt;/p>
&lt;p>We&amp;rsquo;ve recently made some changes to error more informatively in this case. We do so by defining a &amp;ldquo;dummy&amp;rdquo;
&lt;a href="https://rdrr.io/r/stats/predict.html" target="_blank" rel="noopener">&lt;code>predict()&lt;/code>&lt;/a> method for tuning results, implemented only for the sake of erroring more informatively. The same code will now give the following output:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">predict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mtcars_res&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1">#&amp;gt; Error in `predict()`:&lt;/span>
&lt;span class="c1">#&amp;gt; ! `predict()` is not well-defined for tuning results.&lt;/span>
&lt;span class="c1">#&amp;gt; ℹ To predict with the optimal model configuration from tuning&lt;/span>
&lt;span class="c1">#&amp;gt; results, ensure that the tuning result was generated with the&lt;/span>
&lt;span class="c1">#&amp;gt; control option `save_workflow = TRUE`, run `fit_best()`, and&lt;/span>
&lt;span class="c1">#&amp;gt; then predict using `predict()` on its output.&lt;/span>
&lt;span class="c1">#&amp;gt; ℹ To collect predictions from tuning results, ensure that the&lt;/span>
&lt;span class="c1">#&amp;gt; tuning result was generated with the control option `save_pred&lt;/span>
&lt;span class="c1">#&amp;gt; = TRUE` and run `collect_predictions()`.&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>References to important concepts or functions, like
&lt;a href="https://tune.tidymodels.org/reference/control_grid.html" target="_blank" rel="noopener">control options&lt;/a>,
&lt;a href="https://tune.tidymodels.org/reference/fit_best.html?q=fit_best" target="_blank" rel="noopener">&lt;code>fit_best()&lt;/code>&lt;/a>, and
&lt;a href="https://tune.tidymodels.org/reference/collect_predictions.html?q=collect" target="_blank" rel="noopener">&lt;code>collect_predictions()&lt;/code>&lt;/a>, link to the help-files for those functions using
&lt;a href="https://cli.r-lib.org/reference/cli_abort.html" target="_blank" rel="noopener">cli&amp;rsquo;s erroring tools&lt;/a>.&lt;/p>
&lt;p>We hope new error messages like this will help to get folks back on track.&lt;/p>
&lt;h2 id="model-formulas">Model formulas
&lt;a href="#model-formulas">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>In R, formulas provide a compact, symbolic notation to specify model terms. Many modeling functions in R make use of &amp;ldquo;specials,&amp;rdquo; or nonstandard notations used in formulas. Specials are defined and handled as a special case by a given modeling package. parsnip defers to engine packages to handle specials, so you can work with them as usual. For example, the mgcv package provides support for generalized additive models in R, and defines a special called &lt;code>s()&lt;/code> to indicate smoothing terms. You can interface with it via tidymodels like so:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='c'># define a generalized additive model specification&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>gam_spec&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>gen_additive_mod&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"regression"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='c'># fit the specification using a formula with specials&lt;/span>&lt;/span>
&lt;span>&lt;span class='nf'>fit&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>gam_spec&lt;/span>, &lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>cyl&lt;/span> &lt;span class='o'>+&lt;/span> &lt;span class='nf'>s&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>disp&lt;/span>, k &lt;span class='o'>=&lt;/span> &lt;span class='m'>5&lt;/span>&lt;span class='o'>)&lt;/span>, &lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; parsnip model object&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Family: gaussian &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Link function: identity &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Formula:&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; mpg ~ cyl + s(disp, k = 5)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Estimated degrees of freedom:&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; 3.39 total = 5.39 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; GCV score: 6.380152&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>While parsnip can handle specials just fine, the package is often used in conjunction with the greater tidymodels package ecosystem, which defines its own pre-processing infrastructure and functionality via packages like hardhat and recipes. The specials defined in many modeling packages introduce conflicts with that infrastructure. To support specials while also maintaining consistent syntax elsewhere in the ecosystem, &lt;strong>tidymodels delineates between two types of formulas: preprocessing formulas and model formulas&lt;/strong>. Preprocessing formulas determine the input variables, while model formulas determine the model structure.&lt;/p>
&lt;p>This is a tricky abstraction, and one that users have tripped up on in the past. Users could generate all sorts of different errors by 1) mistakenly passing model formulas where preprocessing formulas were expected, or 2) forgetting to pass a model formula where it&amp;rsquo;s needed. For an example of 1), we could pass recipes the same formula we passed to parsnip:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">recipe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mpg&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">cyl&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nf">s&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">disp&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">k&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">5&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">mtcars&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1">#&amp;gt; Error in `inline_check()`:&lt;/span>
&lt;span class="c1">#&amp;gt; ! No in-line functions should be used here; use steps to &lt;/span>
&lt;span class="c1">#&amp;gt; define baking actions.&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But we &lt;em>just&lt;/em> used a special with another tidymodels function! Rude!&lt;/p>
&lt;p>Or, to demonstrate 2), we pass the preprocessing formula as we ought to but forget to provide the model formula:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">gam_wflow&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">workflow&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">add_formula&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mpg&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">.)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">add_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">gam_spec&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">gam_wflow&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span> &lt;span class="nf">fit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mtcars&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1">#&amp;gt; Error in `fit_xy()`:&lt;/span>
&lt;span class="c1">#&amp;gt; ! `fit()` must be used with GAM models (due to its use of formulas).&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Uh, but I &lt;em>did&lt;/em> just use &lt;code>fit()&lt;/code>!&lt;/p>
&lt;p>Since the distinction between model formulas and preprocessor formulas comes up in functions across tidymodels, we decide to create a
&lt;a href="https://parsnip.tidymodels.org/dev/reference/model_formula.html" target="_blank" rel="noopener">central page&lt;/a> that documents the concept itself, hopefully making the syntax associated with it come more easily to users. Then, we link to it &lt;em>all over the place&lt;/em>. For example, those errors now look like:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>recipe&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>cyl&lt;/span> &lt;span class='o'>+&lt;/span> &lt;span class='nf'>s&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>disp&lt;/span>, k &lt;span class='o'>=&lt;/span> &lt;span class='m'>5&lt;/span>&lt;span class='o'>)&lt;/span>, &lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BBBB00; font-weight: bold;'>Error&lt;/span>&lt;span style='font-weight: bold;'> in `inline_check()`:&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BB0000;'>✖&lt;/span> No in-line functions should be used here.&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BBBB;'>ℹ&lt;/span> The following function was found: `s`.&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BBBB;'>ℹ&lt;/span> Use steps to do transformations instead.&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BBBB;'>ℹ&lt;/span> If your modeling engine uses special terms in formulas, pass that&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; formula to workflows as a model formula&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; (`?parsnip::model_formula()`).&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Or:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nv'>gam_wflow&lt;/span> &lt;span class='o'>%&amp;gt;%&lt;/span> &lt;span class='nf'>fit&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BBBB00; font-weight: bold;'>Error&lt;/span>&lt;span style='font-weight: bold;'>:&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BBBB00;'>!&lt;/span> When working with generalized additive models, please supply&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; the model specification to `workflows::add_model()` along with a&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; `formula` argument.&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BBBB;'>ℹ&lt;/span> See `?parsnip::model_formula()` to learn more.&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>While I&amp;rsquo;ve only outlined three, there are all sorts of improvements to error messages on their way to the tidymodels packages in upcoming releases. If you happen to stumble across them, we hope they quickly set you back on the right path. 🗺&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Issue triage consists of categorizing, prioritizing, and consolidating issues in a repository&amp;rsquo;s issue tracker. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>See the
&lt;a href="https://tidyclust.tidymodels.org" target="_blank" rel="noopener">tidyclust&lt;/a> package for unsupervised learning with tidymodels! &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>New interface to validation splits</title><link>https://www.tidyverse.org/blog/2023/08/validation-split-as-3-way-split/</link><pubDate>Fri, 25 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2023/08/validation-split-as-3-way-split/</guid><description>&lt;!--
TODO:
* [x] Look over / edit the post's title in the yaml
* [x] Edit (or delete) the description; note this appears in the Twitter card
* [x] Pick category and tags (see existing with [`hugodown::tidy_show_meta()`](https://rdrr.io/pkg/hugodown/man/use_tidy_post.html))
* [x] Find photo &amp; update yaml metadata
* [x] Create `thumbnail-sq.jpg`; height and width should be equal
* [x] Create `thumbnail-wd.jpg`; width should be >5x height
* [x] [`hugodown::use_tidy_thumbnails()`](https://rdrr.io/pkg/hugodown/man/use_tidy_post.html)
* [x] Add intro sentence, e.g. the standard tagline for the package
* [x] [`usethis::use_tidy_thanks()`](https://usethis.r-lib.org/reference/use_tidy_thanks.html)
-->
&lt;p>We&amp;rsquo;re chuffed to announce the release of a new interface to validation splits in
&lt;a href="https://rsample.tidymodels.org/" target="_blank" rel="noopener">rsample&lt;/a> 1.2.0 and
&lt;a href="https://tune.tidymodels.org/" target="_blank" rel="noopener">tune&lt;/a> 1.1.2. The rsample package makes it easy to create resamples for assessing model performance. The tune package facilitates hyperparameter tuning for the tidymodels packages.&lt;/p>
&lt;p>You can install the new versions from CRAN with:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/utils/install.packages.html'>install.packages&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/c.html'>c&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"rsample"&lt;/span>, &lt;span class='s'>"tune"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>This blog post will walk you through how to make a validation split and use it for tuning.&lt;/p>
&lt;p>You can see a full list of changes in the release notes for
&lt;a href="https://github.com/tidymodels/rsample/releases/tag/v1.2.0" target="_blank" rel="noopener">rsample&lt;/a> and
&lt;a href="https://github.com/tidymodels/tune/releases/tag/v1.1.2" target="_blank" rel="noopener">tune&lt;/a>.&lt;/p>
&lt;p>Let&amp;rsquo;s start with loading the tidymodels package which will load, among others, both rsample and tune.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='kr'>&lt;a href='https://rdrr.io/r/base/library.html'>library&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>&lt;a href='https://tidymodels.tidymodels.org'>tidymodels&lt;/a>&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; ── &lt;span style='font-weight: bold;'>Attaching packages&lt;/span> ────────────────────────────────────── tidymodels 1.1.1 ──&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>broom &lt;/span> 1.0.5 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>recipes &lt;/span> 1.0.7&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>dials &lt;/span> 1.2.0 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>rsample &lt;/span> 1.2.0&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>dplyr &lt;/span> 1.1.2 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>tibble &lt;/span> 3.2.1&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>ggplot2 &lt;/span> 3.4.3 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>tidyr &lt;/span> 1.3.0&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>infer &lt;/span> 1.0.4 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>tune &lt;/span> 1.1.2&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>modeldata &lt;/span> 1.2.0 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>workflows &lt;/span> 1.1.3&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>parsnip &lt;/span> 1.1.1 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>workflowsets&lt;/span> 1.0.1&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>purrr &lt;/span> 1.0.2 &lt;span style='color: #00BB00;'>✔&lt;/span> &lt;span style='color: #0000BB;'>yardstick &lt;/span> 1.2.0&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;span class='c'>#&amp;gt; ── &lt;span style='font-weight: bold;'>Conflicts&lt;/span> ───────────────────────────────────────── tidymodels_conflicts() ──&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BB0000;'>✖&lt;/span> &lt;span style='color: #0000BB;'>purrr&lt;/span>::&lt;span style='color: #00BB00;'>discard()&lt;/span> masks &lt;span style='color: #0000BB;'>scales&lt;/span>::discard()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BB0000;'>✖&lt;/span> &lt;span style='color: #0000BB;'>dplyr&lt;/span>::&lt;span style='color: #00BB00;'>filter()&lt;/span> masks &lt;span style='color: #0000BB;'>stats&lt;/span>::filter()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BB0000;'>✖&lt;/span> &lt;span style='color: #0000BB;'>dplyr&lt;/span>::&lt;span style='color: #00BB00;'>lag()&lt;/span> masks &lt;span style='color: #0000BB;'>stats&lt;/span>::lag()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #BB0000;'>✖&lt;/span> &lt;span style='color: #0000BB;'>recipes&lt;/span>::&lt;span style='color: #00BB00;'>step()&lt;/span> masks &lt;span style='color: #0000BB;'>stats&lt;/span>::step()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #0000BB;'>•&lt;/span> Use suppressPackageStartupMessages() to eliminate package startup messages&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;h2 id="the-new-functions">The new functions
&lt;a href="#the-new-functions">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>You can now make a three-way split of your data instead of doing a sequence of two binary splits.&lt;/p>
&lt;ul>
&lt;li>&lt;code>initial_validation_split()&lt;/code> with variants &lt;code>initial_validation_time_split()&lt;/code> and &lt;code>group_initial_validation_split()&lt;/code> for the initial three-way split&lt;/li>
&lt;li>&lt;code>validation_set()&lt;/code> to create the &lt;code>rset&lt;/code> for tuning containing the analysis (= training) and assessment (= validation) set&lt;/li>
&lt;li>&lt;code>training()&lt;/code>, &lt;code>validation()&lt;/code>, and &lt;code>testing()&lt;/code> for access to the separate subsets&lt;/li>
&lt;li>&lt;code>last_fit()&lt;/code> (and &lt;code>fit_best()&lt;/code>) now also work on the initial three-way split&lt;/li>
&lt;/ul>
&lt;h2 id="the-new-functions-in-action">The new functions in action
&lt;a href="#the-new-functions-in-action">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>To illustrate how to use the new functions, we&amp;rsquo;ll replicate an analysis of
&lt;a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-05-09/readme.md" target="_blank" rel="noopener">childcare cost&lt;/a> from a
&lt;a href="https://github.com/rfordatascience/tidytuesday" target="_blank" rel="noopener">Tidy Tuesday&lt;/a> done by Julia Silge in one of her
&lt;a href="https://juliasilge.com/blog/childcare-costs/" target="_blank" rel="noopener">screencasts&lt;/a>.&lt;/p>
&lt;p>We are modeling the median weekly price for school-aged kids in childcare centers &lt;code>mcsa&lt;/code> and are thus removing the other variables containing different variants of median prices (e.g., for different age groups). We are also removing the FIPS code identifying the county as we are including various characteristics of the counties instead of their ID.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='kr'>&lt;a href='https://rdrr.io/r/base/library.html'>library&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>&lt;a href='https://readr.tidyverse.org'>readr&lt;/a>&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Attaching package: 'readr'&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;span class='c'>#&amp;gt; The following object is masked from 'package:yardstick':&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; spec&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;span class='c'>#&amp;gt; The following object is masked from 'package:scales':&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; col_factor&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>childcare_costs&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>&lt;a href='https://readr.tidyverse.org/reference/read_delim.html'>read_csv&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-05-09/childcare_costs.csv'&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='font-weight: bold;'>Rows: &lt;/span>&lt;span style='color: #0000BB;'>34567&lt;/span> &lt;span style='font-weight: bold;'>Columns: &lt;/span>&lt;span style='color: #0000BB;'>61&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BBBB;'>──&lt;/span> &lt;span style='font-weight: bold;'>Column specification&lt;/span> &lt;span style='color: #00BBBB;'>────────────────────────────────────────────────────────&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='font-weight: bold;'>Delimiter:&lt;/span> ","&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BB00;'>dbl&lt;/span> (61): county_fips_code, study_year, unr_16, funr_16, munr_16, unr_20to64...&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BBBB;'>ℹ&lt;/span> Use `spec()` to retrieve the full column specification for this data.&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #00BBBB;'>ℹ&lt;/span> Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>childcare_costs&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nv'>childcare_costs&lt;/span> &lt;span class='o'>|&amp;gt;&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>select&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>-&lt;/span>&lt;span class='nf'>matches&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"^mc_|^mfc"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span> &lt;span class='o'>|&amp;gt;&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>select&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>-&lt;/span>&lt;span class='nv'>county_fips_code&lt;/span>&lt;span class='o'>)&lt;/span> &lt;span class='o'>|&amp;gt;&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>drop_na&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span> &lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nf'>glimpse&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>childcare_costs&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Rows: 23,593&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Columns: 53&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ study_year &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 2008, 2009, 2010, 2011, 2012, 2013, 2014, 20…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ unr_16 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 5.42, 5.93, 6.21, 7.55, 8.60, 9.39, 8.50, 7.…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ funr_16 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 4.41, 5.72, 5.57, 8.13, 8.88, 10.31, 9.18, 8…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ munr_16 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 6.32, 6.11, 6.78, 7.03, 8.29, 8.56, 7.95, 6.…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ unr_20to64 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 4.6, 4.8, 5.1, 6.2, 6.7, 7.3, 6.8, 5.9, 4.4,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ funr_20to64 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 3.5, 4.6, 4.6, 6.3, 6.4, 7.6, 6.8, 6.1, 4.6,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ munr_20to64 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 5.6, 5.0, 5.6, 6.1, 7.0, 7.0, 6.8, 5.9, 4.3,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ flfpr_20to64 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 68.9, 70.8, 71.3, 70.2, 70.6, 70.7, 69.9, 68…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ flfpr_20to64_under6 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 66.9, 63.7, 67.0, 66.5, 67.1, 67.5, 65.2, 66…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ flfpr_20to64_6to17 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 79.59, 78.41, 78.15, 77.62, 76.31, 75.91, 75…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ flfpr_20to64_under6_6to17 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 60.81, 59.91, 59.71, 59.31, 58.30, 58.00, 57…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ mlfpr_20to64 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 84.0, 86.2, 85.8, 85.7, 85.7, 85.0, 84.2, 82…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ pr_f &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 8.5, 7.5, 7.5, 7.4, 7.4, 8.3, 9.1, 9.3, 9.4,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ pr_p &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 11.5, 10.3, 10.6, 10.9, 11.6, 12.1, 12.8, 12…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ mhi_2018 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 58462.55, 60211.71, 61775.80, 60366.88, 5915…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ me_2018 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 32710.60, 34688.16, 34740.84, 34564.32, 3432…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ fme_2018 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 25156.25, 26852.67, 27391.08, 26727.68, 2796…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ mme_2018 &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 41436.80, 43865.64, 46155.24, 45333.12, 4427…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ total_pop &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 49744, 49584, 53155, 53944, 54590, 54907, 55…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ one_race &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 98.1, 98.6, 98.5, 98.5, 98.5, 98.6, 98.7, 98…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ one_race_w &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 78.9, 79.1, 79.1, 78.9, 78.9, 78.3, 78.0, 77…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ one_race_b &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 17.7, 17.9, 17.9, 18.1, 18.1, 18.4, 18.6, 18…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ one_race_i &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 0.4, 0.4, 0.3, 0.2, 0.3, 0.3, 0.4, 0.4, 0.4,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ one_race_a &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 0.4, 0.6, 0.7, 0.7, 0.8, 1.0, 0.9, 1.0, 0.8,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ one_race_h &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ one_race_other &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 0.7, 0.7, 0.6, 0.5, 0.4, 0.7, 0.7, 0.9, 1.4,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ two_races &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 1.9, 1.4, 1.5, 1.5, 1.5, 1.4, 1.3, 1.6, 2.0,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ hispanic &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 1.8, 2.0, 2.3, 2.4, 2.4, 2.5, 2.5, 2.6, 2.6,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ households &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 18373, 18288, 19718, 19998, 19934, 20071, 20…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ h_under6_both_work &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 1543, 1475, 1569, 1695, 1714, 1532, 1557, 13…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ h_under6_f_work &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 970, 964, 1009, 1060, 938, 880, 1191, 1258, …&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ h_under6_m_work &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 22, 16, 16, 106, 120, 161, 159, 211, 109, 10…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ h_under6_single_m &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 995, 1099, 1110, 1030, 1095, 1160, 954, 883,…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ h_6to17_both_work &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 4900, 5028, 5472, 5065, 4608, 4238, 4056, 40…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ h_6to17_fwork &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 1308, 1519, 1541, 1965, 1963, 1978, 2073, 20…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ h_6to17_mwork &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 114, 92, 113, 246, 284, 354, 373, 551, 322, …&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ h_6to17_single_m &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 1966, 2305, 2377, 2299, 2644, 2522, 2269, 21…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ emp_m &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 27.40, 29.54, 29.33, 31.17, 32.13, 31.74, 32…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ memp_m &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 24.41, 26.07, 25.94, 26.97, 28.59, 27.44, 28…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ femp_m &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 30.68, 33.40, 33.06, 35.96, 36.09, 36.61, 37…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ emp_service &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 17.06, 15.81, 16.92, 16.18, 16.09, 16.72, 16…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ memp_service &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 15.53, 14.16, 15.09, 14.21, 14.71, 13.92, 13…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ femp_service &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 18.75, 17.64, 18.93, 18.42, 17.63, 19.89, 20…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ emp_sales &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 29.11, 28.75, 29.07, 27.56, 28.39, 27.22, 25…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ memp_sales &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 15.97, 17.51, 17.82, 17.74, 17.79, 17.38, 15…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ femp_sales &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 43.52, 41.25, 41.43, 38.76, 40.26, 38.36, 36…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ emp_n &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 13.21, 11.89, 11.57, 10.72, 9.02, 9.27, 9.38…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ memp_n &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 22.54, 20.30, 19.86, 18.28, 16.03, 16.79, 17…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ femp_n &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 2.99, 2.52, 2.45, 2.09, 1.19, 0.77, 0.58, 0.…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ emp_p &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 13.22, 14.02, 13.11, 14.38, 14.37, 15.04, 16…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ memp_p &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 21.55, 21.96, 21.28, 22.80, 22.88, 24.48, 24…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ femp_p &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 4.07, 5.19, 4.13, 4.77, 4.84, 4.36, 6.07, 7.…&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; $ mcsa &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> 80.92, 83.42, 85.92, 88.43, 90.93, 93.43, 95…&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Even after omitting rows with missing values are we left with 23593 observations. That is plenty to work with! We are likely to get a reliable estimate of the model performance from a validation set without having to fit and evaluate the model multiple times, as with, for example, v-fold cross-validation.&lt;/p>
&lt;p>We are creating a three-way split of the data into a training, a validation, and a test set with the new &lt;code>initial_validation_split()&lt;/code> function. We are stratifying based on our outcome &lt;code>mcsa&lt;/code>. The default of &lt;code>prop = c(0.6, 0.2)&lt;/code> means that 60% of the data gets allocated to the training set and 20% to the validation set - and the remaining 20% go into the test set.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/Random.html'>set.seed&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='m'>123&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>childcare_split&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nv'>childcare_costs&lt;/span> &lt;span class='o'>|&amp;gt;&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>initial_validation_split&lt;/span>&lt;span class='o'>(&lt;/span>strata &lt;span class='o'>=&lt;/span> &lt;span class='nv'>mcsa&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>childcare_split&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &amp;lt;Training/Validation/Testing/Total&amp;gt;&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &amp;lt;14155/4718/4720/23593&amp;gt;&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>You can access the subsets of the data with the familiar &lt;code>training()&lt;/code> and &lt;code>testing()&lt;/code> as well as the new &lt;code>validation()&lt;/code>:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>validation&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>childcare_split&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 4,718 × 53&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; study_year unr_16 funr_16 munr_16 unr_20to64 funr_20to64 munr_20to64&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 1&lt;/span> &lt;span style='text-decoration: underline;'>2&lt;/span>013 9.39 10.3 8.56 7.3 7.6 7 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 2&lt;/span> &lt;span style='text-decoration: underline;'>2&lt;/span>011 13.0 12.4 13.6 13.2 12.4 13.9&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 3&lt;/span> &lt;span style='text-decoration: underline;'>2&lt;/span>008 3.85 4.4 3.43 3.7 3.9 3.6&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 4&lt;/span> &lt;span style='text-decoration: underline;'>2&lt;/span>015 8.31 11.8 5.69 7.8 11.7 4.9&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 5&lt;/span> &lt;span style='text-decoration: underline;'>2&lt;/span>015 7.67 6.92 8.27 7.6 6.7 8.3&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 6&lt;/span> &lt;span style='text-decoration: underline;'>2&lt;/span>016 5.95 6.33 5.66 5.7 5.9 5.5&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 7&lt;/span> &lt;span style='text-decoration: underline;'>2&lt;/span>009 10.7 15.9 7.06 8.7 16.8 2.9&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 8&lt;/span> &lt;span style='text-decoration: underline;'>2&lt;/span>010 11.2 15.2 7.89 10.9 14.7 7.8&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 9&lt;/span> &lt;span style='text-decoration: underline;'>2&lt;/span>013 15.0 17.0 13.4 15.2 18.1 13 &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>10&lt;/span> &lt;span style='text-decoration: underline;'>2&lt;/span>014 17.4 16.3 18.2 17.2 17.7 16.9&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># ℹ 4,708 more rows&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># ℹ 46 more variables: flfpr_20to64 &amp;lt;dbl&amp;gt;, flfpr_20to64_under6 &amp;lt;dbl&amp;gt;,&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># flfpr_20to64_6to17 &amp;lt;dbl&amp;gt;, flfpr_20to64_under6_6to17 &amp;lt;dbl&amp;gt;,&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># mlfpr_20to64 &amp;lt;dbl&amp;gt;, pr_f &amp;lt;dbl&amp;gt;, pr_p &amp;lt;dbl&amp;gt;, mhi_2018 &amp;lt;dbl&amp;gt;, me_2018 &amp;lt;dbl&amp;gt;,&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># fme_2018 &amp;lt;dbl&amp;gt;, mme_2018 &amp;lt;dbl&amp;gt;, total_pop &amp;lt;dbl&amp;gt;, one_race &amp;lt;dbl&amp;gt;,&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># one_race_w &amp;lt;dbl&amp;gt;, one_race_b &amp;lt;dbl&amp;gt;, one_race_i &amp;lt;dbl&amp;gt;, one_race_a &amp;lt;dbl&amp;gt;,&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># one_race_h &amp;lt;dbl&amp;gt;, one_race_other &amp;lt;dbl&amp;gt;, two_races &amp;lt;dbl&amp;gt;, hispanic &amp;lt;dbl&amp;gt;, …&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>You may want to extract the training data to do some exploratory data analysis but here we are going to rely on xgboost to figure out patterns in the data so we can breeze straight to tuning a model.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nv'>xgb_spec&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>boost_tree&lt;/span>&lt;span class='o'>(&lt;/span>&lt;/span>
&lt;span> trees &lt;span class='o'>=&lt;/span> &lt;span class='m'>500&lt;/span>,&lt;/span>
&lt;span> min_n &lt;span class='o'>=&lt;/span> &lt;span class='nf'>tune&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> mtry &lt;span class='o'>=&lt;/span> &lt;span class='nf'>tune&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> stop_iter &lt;span class='o'>=&lt;/span> &lt;span class='nf'>tune&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> learn_rate &lt;span class='o'>=&lt;/span> &lt;span class='m'>0.01&lt;/span>&lt;/span>
&lt;span> &lt;span class='o'>)&lt;/span> &lt;span class='o'>|&amp;gt;&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>set_engine&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"xgboost"&lt;/span>, validation &lt;span class='o'>=&lt;/span> &lt;span class='m'>0.2&lt;/span>&lt;span class='o'>)&lt;/span> &lt;span class='o'>|&amp;gt;&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>set_mode&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"regression"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>xgb_wf&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>workflow&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mcsa&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>.&lt;/span>, &lt;span class='nv'>xgb_spec&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>xgb_wf&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; ══ Workflow ════════════════════════════════════════════════════════════════════&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='font-style: italic;'>Preprocessor:&lt;/span> Formula&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='font-style: italic;'>Model:&lt;/span> boost_tree()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; ── Preprocessor ────────────────────────────────────────────────────────────────&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; mcsa ~ .&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; ── Model ───────────────────────────────────────────────────────────────────────&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Boosted Tree Model Specification (regression)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Main Arguments:&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; mtry = tune()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; trees = 500&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; min_n = tune()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; learn_rate = 0.01&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; stop_iter = tune()&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Engine-Specific Arguments:&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; validation = 0.2&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; Computational engine: xgboost&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>We give this workflow object with the model specification to &lt;code>tune_grid()&lt;/code> to try multiple combinations of the hyperparameters we tagged for tuning (&lt;code>min_n&lt;/code>, &lt;code>mtry&lt;/code>, and &lt;code>stop_iter&lt;/code>).&lt;/p>
&lt;p>During tuning, the model should not have access to the test data, only to the data used to fit the model (the analysis set) and the data used to assess the model (the assessment set). Each pair of analysis and assessment set forms a resample. For 10-fold cross-validation, we&amp;rsquo;d have 10 resamples. With a validation split, we have just one resample with the training set functioning as the analysis set and the validation set as the assessment set. The tidymodels tuning functions all expect a &lt;em>set&lt;/em> of resamples (which can be of size one) and the corresponding objects are of class &lt;code>rset&lt;/code>.&lt;/p>
&lt;p>To remove the test data from the initial three-way split and create such an &lt;code>rset&lt;/code> object for tuning, use &lt;code>validation_set()&lt;/code>.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/Random.html'>set.seed&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='m'>234&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>childcare_set&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>validation_set&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>childcare_split&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>childcare_set&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 1 × 2&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; splits id &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [14155/4718]&amp;gt;&lt;/span> validation&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>We are going to try 15 different parameter combinations and pick the one with the smallest RMSE.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/Random.html'>set.seed&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='m'>234&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>xgb_res&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>tune_grid&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>xgb_wf&lt;/span>, &lt;span class='nv'>childcare_set&lt;/span>, grid &lt;span class='o'>=&lt;/span> &lt;span class='m'>15&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #0000BB;'>i&lt;/span> &lt;span style='color: #000000;'>Creating pre-processing data to finalize unknown parameter: mtry&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;span class='c'>#&amp;gt; Warning in `[.tbl_df`(x, is.finite(x &amp;lt;- as.numeric(x))): NAs introduced by coercion&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;span class='nv'>best_parameters&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>select_best&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>xgb_res&lt;/span>, &lt;span class='s'>"rmse"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>childcare_wflow&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>finalize_workflow&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>xgb_wf&lt;/span>, &lt;span class='nv'>best_parameters&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>&lt;code>last_fit()&lt;/code> then lets you fit your model on the training data and calculate performance on the test data. If you provide it with a three-way split, you can choose if you want your model to be fitted on the training data only or on the combination of training and validation set. You can specify this with the &lt;code>add_validation_set&lt;/code> argument.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nv'>childcare_fit&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>last_fit&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>childcare_wflow&lt;/span>, &lt;span class='nv'>childcare_split&lt;/span>, add_validation_set &lt;span class='o'>=&lt;/span> &lt;span class='kc'>TRUE&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='nf'>collect_metrics&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>childcare_fit&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 2 × 4&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; .metric .estimator .estimate .config &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> rmse standard 21.4 Preprocessor1_Model1&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>2&lt;/span> rsq standard 0.610 Preprocessor1_Model1&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>This takes you through the important changes for validation sets in the tidymodels framework!&lt;/p>
&lt;h2 id="acknowledgements">Acknowledgements
&lt;a href="#acknowledgements">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Many thanks to the people who contributed since the last releases!&lt;/p>
&lt;p>For rsample:
&lt;a href="https://github.com/afrogri37" target="_blank" rel="noopener">@afrogri37&lt;/a>,
&lt;a href="https://github.com/AngelFelizR" target="_blank" rel="noopener">@AngelFelizR&lt;/a>,
&lt;a href="https://github.com/bschneidr" target="_blank" rel="noopener">@bschneidr&lt;/a>,
&lt;a href="https://github.com/erictleung" target="_blank" rel="noopener">@erictleung&lt;/a>,
&lt;a href="https://github.com/exsell-jc" target="_blank" rel="noopener">@exsell-jc&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/jrosell" target="_blank" rel="noopener">@jrosell&lt;/a>,
&lt;a href="https://github.com/MasterLuke84" target="_blank" rel="noopener">@MasterLuke84&lt;/a>,
&lt;a href="https://github.com/MichaelChirico" target="_blank" rel="noopener">@MichaelChirico&lt;/a>,
&lt;a href="https://github.com/mikemahoney218" target="_blank" rel="noopener">@mikemahoney218&lt;/a>,
&lt;a href="https://github.com/rdavis120" target="_blank" rel="noopener">@rdavis120&lt;/a>,
&lt;a href="https://github.com/sametsoekel" target="_blank" rel="noopener">@sametsoekel&lt;/a>,
&lt;a href="https://github.com/Shafi2016" target="_blank" rel="noopener">@Shafi2016&lt;/a>,
&lt;a href="https://github.com/simonpcouch" target="_blank" rel="noopener">@simonpcouch&lt;/a>,
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>, and
&lt;a href="https://github.com/trevorcampbell" target="_blank" rel="noopener">@trevorcampbell&lt;/a>.&lt;/p>
&lt;p>For tune:
&lt;a href="https://github.com/blechturm" target="_blank" rel="noopener">@blechturm&lt;/a>,
&lt;a href="https://github.com/cphaarmeyer" target="_blank" rel="noopener">@cphaarmeyer&lt;/a>,
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/forecastingEDs" target="_blank" rel="noopener">@forecastingEDs&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/kjbeath" target="_blank" rel="noopener">@kjbeath&lt;/a>,
&lt;a href="https://github.com/mikemahoney218" target="_blank" rel="noopener">@mikemahoney218&lt;/a>,
&lt;a href="https://github.com/rdavis120" target="_blank" rel="noopener">@rdavis120&lt;/a>,
&lt;a href="https://github.com/simonpcouch" target="_blank" rel="noopener">@simonpcouch&lt;/a>, and
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>.&lt;/p></description></item><item><title>Tuning hyperparameters with tidymodels is a delight</title><link>https://www.tidyverse.org/blog/2023/04/tuning-delights/</link><pubDate>Thu, 20 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2023/04/tuning-delights/</guid><description>&lt;p>The tidymodels team recently released new versions of the tune, finetune, and workflowsets packages, and we&amp;rsquo;re super stoked about it! Each of these three packages facilitates tuning hyperparameters in tidymodels, and their new releases work to make the experience of hyperparameter tuning more joyful.&lt;/p>
&lt;p>You can install these releases from CRAN with:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/utils/install.packages.html'>install.packages&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/base/c.html'>c&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"tune"&lt;/span>, &lt;span class='s'>"workflowsets"&lt;/span>, &lt;span class='s'>"finetune"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>This blog post will highlight some of new changes in these packages that we&amp;rsquo;re most excited about.&lt;/p>
&lt;p>You can see the full lists of changes in the release notes for each package:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://github.com/tidymodels/tune/releases/tag/v1.1.0" target="_blank" rel="noopener">tune v1.1.0&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://github.com/tidymodels/workflowsets/releases/tag/v1.0.1" target="_blank" rel="noopener">workflowsets v1.0.1&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://github.com/tidymodels/finetune/releases/tag/v1.1.0" target="_blank" rel="noopener">finetune v1.1.0&lt;/a>&lt;/li>
&lt;/ul>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='kr'>&lt;a href='https://rdrr.io/r/base/library.html'>library&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>&lt;a href='https://tidymodels.tidymodels.org'>tidymodels&lt;/a>&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='kr'>&lt;a href='https://rdrr.io/r/base/library.html'>library&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>&lt;a href='https://github.com/tidymodels/finetune'>finetune&lt;/a>&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;h2 id="a-shorthand-for-fitting-the-optimal-model">A shorthand for fitting the optimal model
&lt;a href="#a-shorthand-for-fitting-the-optimal-model">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>In tidymodels, the result of tuning a set of hyperparameters is a data structure describing the candidate models, their predictions, and the performance metrics associated with those predictions. For example, tuning the number of &lt;code>neighbors&lt;/code> in a &lt;code>nearest_neighbors()&lt;/code> model over a regular grid:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='c'># tune the `neighbors` hyperparameter&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>knn_model_spec&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>nearest_neighbor&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"regression"&lt;/span>, neighbors &lt;span class='o'>=&lt;/span> &lt;span class='nf'>&lt;a href='https://hardhat.tidymodels.org/reference/tune.html'>tune&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='o'>)&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>tuning_res&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;/span>
&lt;span> &lt;span class='nf'>&lt;a href='https://tune.tidymodels.org/reference/tune_grid.html'>tune_grid&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;/span>
&lt;span> &lt;span class='nv'>knn_model_spec&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>.&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nf'>bootstraps&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>, &lt;span class='m'>5&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> control &lt;span class='o'>=&lt;/span> &lt;span class='nf'>&lt;a href='https://tune.tidymodels.org/reference/control_grid.html'>control_grid&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>save_workflow &lt;span class='o'>=&lt;/span> &lt;span class='kc'>TRUE&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span> &lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='c'># check out the resulting object&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>tuning_res&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; # Tuning results&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; # Bootstrap sampling &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 5 × 4&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; splits id .metrics .notes &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/11]&amp;gt;&lt;/span> Bootstrap1 &lt;span style='color: #555555;'>&amp;lt;tibble [20 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>2&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/12]&amp;gt;&lt;/span> Bootstrap2 &lt;span style='color: #555555;'>&amp;lt;tibble [20 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>3&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/11]&amp;gt;&lt;/span> Bootstrap3 &lt;span style='color: #555555;'>&amp;lt;tibble [20 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>4&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/10]&amp;gt;&lt;/span> Bootstrap4 &lt;span style='color: #555555;'>&amp;lt;tibble [20 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>5&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/12]&amp;gt;&lt;/span> Bootstrap5 &lt;span style='color: #555555;'>&amp;lt;tibble [20 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;/span>
&lt;span>&lt;span class='c'># examine proposed hyperparameters and associated metrics&lt;/span>&lt;/span>
&lt;span>&lt;span class='nf'>&lt;a href='https://tune.tidymodels.org/reference/collect_predictions.html'>collect_metrics&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>tuning_res&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 20 × 7&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; neighbors .metric .estimator mean n std_err .config &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;int&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;int&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 1&lt;/span> 2 rmse standard 3.19 5 0.208 Preprocessor1_Model01&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 2&lt;/span> 2 rsq standard 0.664 5 0.086&lt;span style='text-decoration: underline;'>1&lt;/span> Preprocessor1_Model01&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 3&lt;/span> 3 rmse standard 3.13 5 0.266 Preprocessor1_Model02&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 4&lt;/span> 3 rsq standard 0.678 5 0.086&lt;span style='text-decoration: underline;'>8&lt;/span> Preprocessor1_Model02&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 5&lt;/span> 4 rmse standard 3.11 5 0.292 Preprocessor1_Model03&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 6&lt;/span> 4 rsq standard 0.684 5 0.085&lt;span style='text-decoration: underline;'>1&lt;/span> Preprocessor1_Model03&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 7&lt;/span> 5 rmse standard 3.10 5 0.287 Preprocessor1_Model04&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 8&lt;/span> 5 rsq standard 0.686 5 0.083&lt;span style='text-decoration: underline;'>9&lt;/span> Preprocessor1_Model04&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'> 9&lt;/span> 8 rmse standard 3.08 5 0.263 Preprocessor1_Model05&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>10&lt;/span> 8 rsq standard 0.689 5 0.084&lt;span style='text-decoration: underline;'>3&lt;/span> Preprocessor1_Model05&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>11&lt;/span> 9 rmse standard 3.07 5 0.256 Preprocessor1_Model06&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>12&lt;/span> 9 rsq standard 0.691 5 0.084&lt;span style='text-decoration: underline;'>5&lt;/span> Preprocessor1_Model06&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>13&lt;/span> 10 rmse standard 3.06 5 0.247 Preprocessor1_Model07&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>14&lt;/span> 10 rsq standard 0.693 5 0.083&lt;span style='text-decoration: underline;'>7&lt;/span> Preprocessor1_Model07&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>15&lt;/span> 11 rmse standard 3.05 5 0.241 Preprocessor1_Model08&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>16&lt;/span> 11 rsq standard 0.696 5 0.083&lt;span style='text-decoration: underline;'>3&lt;/span> Preprocessor1_Model08&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>17&lt;/span> 13 rmse standard 3.03 5 0.236 Preprocessor1_Model09&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>18&lt;/span> 13 rsq standard 0.701 5 0.082&lt;span style='text-decoration: underline;'>0&lt;/span> Preprocessor1_Model09&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>19&lt;/span> 14 rmse standard 3.02 5 0.235 Preprocessor1_Model10&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>20&lt;/span> 14 rsq standard 0.704 5 0.080&lt;span style='text-decoration: underline;'>8&lt;/span> Preprocessor1_Model10&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Given these tuning results, the next steps are to choose the &amp;ldquo;best&amp;rdquo; hyperparameters, assign those hyperparameters to the model, and fit the finalized model on the training set. Previously in tidymodels, this has felt like:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='c'># choose a method to define "best" and extract the resulting parameters&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>best_param&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>&lt;a href='https://tune.tidymodels.org/reference/show_best.html'>select_best&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>tuning_res&lt;/span>, &lt;span class='s'>"rmse"&lt;/span>&lt;span class='o'>)&lt;/span> &lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='c'># assign those parameters to model&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>knn_model_final&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>&lt;a href='https://tune.tidymodels.org/reference/finalize_model.html'>finalize_model&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>knn_model_spec&lt;/span>, &lt;span class='nv'>best_param&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='c'># fit the finalized model to the training set&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>knn_fit&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>fit&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>knn_model_final&lt;/span>, &lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>.&lt;/span>, &lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Voilà! &lt;code>knn_fit&lt;/code> is a properly resampled model that is ready to
&lt;a href="https://rdrr.io/r/stats/predict.html" target="_blank" rel="noopener">&lt;code>predict()&lt;/code>&lt;/a> on new data:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/stats/predict.html'>predict&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>knn_fit&lt;/span>, &lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>[&lt;/span>&lt;span class='m'>1&lt;/span>, &lt;span class='o'>]&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 1 × 1&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; .pred&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> 22.0&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>The newest release of tune introduced a shorthand interface for going from tuning results to final fit called
&lt;a href="https://tune.tidymodels.org/reference/fit_best.html" target="_blank" rel="noopener">&lt;code>fit_best()&lt;/code>&lt;/a>. The function wraps each of those three functions with sensible defaults to abbreviate the process described above.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nv'>knn_fit_2&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nf'>&lt;a href='https://tune.tidymodels.org/reference/fit_best.html'>fit_best&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>tuning_res&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nf'>&lt;a href='https://rdrr.io/r/stats/predict.html'>predict&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>knn_fit_2&lt;/span>, &lt;span class='nv'>mtcars&lt;/span>&lt;span class='o'>[&lt;/span>&lt;span class='m'>1&lt;/span>, &lt;span class='o'>]&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 1 × 1&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; .pred&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;dbl&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> 22.0&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>This function is closely related to the
&lt;a href="https://tune.tidymodels.org/reference/last_fit.html" target="_blank" rel="noopener">&lt;code>last_fit()&lt;/code>&lt;/a> function. They both give you access to a workflow fitted on the training data but are situated somewhat differently in the modeling workflow.
&lt;a href="https://tune.tidymodels.org/reference/fit_best.html" target="_blank" rel="noopener">&lt;code>fit_best()&lt;/code>&lt;/a> picks up after a tuning function like
&lt;a href="https://tune.tidymodels.org/reference/tune_grid.html" target="_blank" rel="noopener">&lt;code>tune_grid()&lt;/code>&lt;/a> to take you from tuning results to fitted workflow, ready for you to predict and assess further.
&lt;a href="https://tune.tidymodels.org/reference/last_fit.html" target="_blank" rel="noopener">&lt;code>last_fit()&lt;/code>&lt;/a> assumes you have made your choice of hyperparameters and finalized your workflow to then take you from finalized workflow to fitted workflow and further to performance assessment on the test data. While
&lt;a href="https://tune.tidymodels.org/reference/fit_best.html" target="_blank" rel="noopener">&lt;code>fit_best()&lt;/code>&lt;/a> gives a fitted workflow,
&lt;a href="https://tune.tidymodels.org/reference/last_fit.html" target="_blank" rel="noopener">&lt;code>last_fit()&lt;/code>&lt;/a> gives you the performance results. If you want the fitted workflow, you can extract it from the result of
&lt;a href="https://tune.tidymodels.org/reference/last_fit.html" target="_blank" rel="noopener">&lt;code>last_fit()&lt;/code>&lt;/a> via
&lt;a href="https://hardhat.tidymodels.org/reference/hardhat-extract.html" target="_blank" rel="noopener">&lt;code>extract_workflow()&lt;/code>&lt;/a>.&lt;/p>
&lt;p>The newest release of the workflowsets package also includes a
&lt;a href="https://tune.tidymodels.org/reference/fit_best.html" target="_blank" rel="noopener">&lt;code>fit_best()&lt;/code>&lt;/a> method for workflow set objects. Given a set of tuning results, that method will sift through all of the possible models to find and fit the optimal model configuration.&lt;/p>
&lt;h2 id="interactive-issue-logging">Interactive issue logging
&lt;a href="#interactive-issue-logging">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Imagine, in the previous example, we made some subtle error in specifying the tuning process. For example, passing a function to &lt;code>extract&lt;/code> elements of the proposed workflows that injects some warnings and errors into the tuning process:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='nv'>raise_concerns&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='kr'>function&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>x&lt;/span>&lt;span class='o'>)&lt;/span> &lt;span class='o'>&amp;#123;&lt;/span>&lt;/span>
&lt;span> &lt;span class='kr'>&lt;a href='https://rdrr.io/r/base/warning.html'>warning&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"Ummm, wait. :o"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span> &lt;span class='kr'>&lt;a href='https://rdrr.io/r/base/stop.html'>stop&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='s'>"Eep! Nooo!"&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='o'>&amp;#125;&lt;/span>&lt;/span>
&lt;span>&lt;/span>
&lt;span>&lt;span class='nv'>tuning_res&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span>&lt;/span>
&lt;span> &lt;span class='nf'>&lt;a href='https://tune.tidymodels.org/reference/tune_grid.html'>tune_grid&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;/span>
&lt;span> &lt;span class='nv'>knn_model_spec&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>.&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nf'>bootstraps&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>, &lt;span class='m'>5&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> control &lt;span class='o'>=&lt;/span> &lt;span class='nf'>&lt;a href='https://tune.tidymodels.org/reference/control_grid.html'>control_grid&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>extract &lt;span class='o'>=&lt;/span> &lt;span class='nv'>raise_concerns&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span> &lt;span class='o'>)&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>Warnings and errors can come up in all sorts of places while tuning hyperparameters. Often, with obvious issues, we can raise errors early on and halt the tuning process, but with more subtle concerns, we don&amp;rsquo;t want to be too restrictive; it&amp;rsquo;s sometimes better to defer to the underlying modeling packages to decide what&amp;rsquo;s a dire issue versus something that can be worked around.&lt;/p>
&lt;p>In the past, we&amp;rsquo;ve raised warnings and issues as they occur, printing context on the issue to the console before logging the issue in the tuning result. In the above example, this would look like:&lt;/p>
&lt;pre>&lt;code>! Bootstrap1: preprocessor 1/1, model 1/1 (extracts): Ummm, wait. :o
x Bootstrap1: preprocessor 1/1, model 1/1 (extracts): Error in extractor(object): Eep! Nooo!
! Bootstrap2: preprocessor 1/1, model 1/1 (extracts): Ummm, wait. :o
x Bootstrap2: preprocessor 1/1, model 1/1 (extracts): Error in extractor(object): Eep! Nooo!
! Bootstrap3: preprocessor 1/1, model 1/1 (extracts): Ummm, wait. :o
x Bootstrap3: preprocessor 1/1, model 1/1 (extracts): Error in extractor(object): Eep! Nooo!
! Bootstrap4: preprocessor 1/1, model 1/1 (extracts): Ummm, wait. :o
x Bootstrap4: preprocessor 1/1, model 1/1 (extracts): Error in extractor(object): Eep! Nooo!
! Bootstrap5: preprocessor 1/1, model 1/1 (extracts): Ummm, wait. :o
x Bootstrap5: preprocessor 1/1, model 1/1 (extracts): Error in extractor(object): Eep! Nooo!
&lt;/code>&lt;/pre>
&lt;p>The above messages are super descriptive about where issues occur&amp;mdash;they note in which resample, from which proposed modeling workflow, and in which part of the fitting process the issues occurred in. At the same time, they are quite repetitive; if there&amp;rsquo;s an issue during hyperparameter tuning, it probably occurs in every resample, always in the same place. If, instead, we were evaluating this model against 1,000 resamples, or there were more than just two issues, this output could get very overwhelming very quickly.&lt;/p>
&lt;p>The new releases of our tuning packages include tools to determine which tuning issues are unique, and for each unique issue, only print out the message once while maintaining a dynamic count of how many times the issue occurred. With the new tune release, the same output would look like:&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;span>&lt;span class='c'>#&amp;gt; → &lt;span style='color: #BBBB00; font-weight: bold;'>A&lt;/span> | &lt;span style='color: #BBBB00;'>warning&lt;/span>: Ummm, wait. :o&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;span class='c'>#&amp;gt; → &lt;span style='color: #BB0000; font-weight: bold;'>B&lt;/span> | &lt;span style='color: #BB0000;'>error&lt;/span>: Eep! Nooo!&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; There were issues with some computations &lt;span style='color: #BBBB00; font-weight: bold;'>A&lt;/span>: x5 &lt;span style='color: #BB0000; font-weight: bold;'>B&lt;/span>: x5&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>This interface is hopefully less overwhelming for users. When the messages attached to these issues aren&amp;rsquo;t enough to debug the issue, the complete set of information about the issues lives inside of the tuning result object, and can be retrieved with &lt;code>collect_notes(tuning_res)&lt;/code>. To turn off the interactive logging, set the &lt;code>verbose&lt;/code> control option to &lt;code>TRUE&lt;/code>.&lt;/p>
&lt;h2 id="speedups">Speedups
&lt;a href="#speedups">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Each of these three releases, as well as releases of core tidymodels packages they depend on like parsnip, recipes, and hardhat, include a plethora of changes meant to optimize computational performance. Especially for modeling practitioners who work with many resamples and/or small data sets, our modeling workflows will feel a whole lot snappier:&lt;/p>
&lt;p>&lt;img src="https://simonpcouch.com/blog/speedups-2023/index_files/figure-html/unnamed-chunk-10-1.png" alt="A ggplot2 line graph plotting relative change in time to evaluate model fits with the tidymodels packages. Fits on datasets with 100 training rows are 2 to 3 times faster, while fits on datasets with 100,000 or more rows take about the same amount of time as they used to.">&lt;/p>
&lt;p>With 100-row training data sets, the time to resample models with tune and friends has been at least halved. These releases are the first iteration of a set of changes to reduce the evaluation time of tidymodels code, and users can expect further optimizations in coming releases! See
&lt;a href="https://www.simonpcouch.com/blog/speedups-2023/" target="_blank" rel="noopener">this post on my blog&lt;/a> for more information about those speedups.&lt;/p>
&lt;h2 id="bonus-points">Bonus points
&lt;a href="#bonus-points">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Although they&amp;rsquo;re smaller in scope, we wanted to highlight two additional developments in tuning hyperparameters with tidymodels.&lt;/p>
&lt;h3 id="workflow-set-support-for-tidyclust">Workflow set support for tidyclust
&lt;a href="#workflow-set-support-for-tidyclust">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h3>&lt;p>The recent tidymodels package
&lt;a href="github.com/tidymodels/tidyclust">tidyclust&lt;/a> introduced support for fitting and tuning clustering models in tidymodels. That package&amp;rsquo;s function
&lt;a href="https://tidyclust.tidymodels.org/reference/tune_cluster.html" target="_blank" rel="noopener">&lt;code>tune_cluster()&lt;/code>&lt;/a> is now an option for tuning in
&lt;a href="https://workflowsets.tidymodels.org/reference/workflow_map.html" target="_blank" rel="noopener">&lt;code>workflow_map()&lt;/code>&lt;/a>, meaning that users can fit sets of clustering models and preprocessors using workflow sets. These changes further integrate the tidyclust package into tidymodels framework.&lt;/p>
&lt;h3 id="refined-retrieval-of-intermediate-results">Refined retrieval of intermediate results
&lt;a href="#refined-retrieval-of-intermediate-results">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h3>&lt;p>The &lt;code>.Last.tune.result&lt;/code> helper stores the most recent tuning result in the object &lt;code>.Last.tune.result&lt;/code> as a fail-safe in cases of interrupted tuning, uncaught tuning errors, and simply forgetting to assign tuning results to an object.&lt;/p>
&lt;div class="highlight">
&lt;pre class='chroma'>&lt;code class='language-r' data-lang='r'>&lt;span>&lt;span class='c'># be a silly goose and forget to assign results&lt;/span>&lt;/span>
&lt;span>&lt;span class='nf'>&lt;a href='https://tune.tidymodels.org/reference/tune_grid.html'>tune_grid&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>&lt;/span>
&lt;span> &lt;span class='nv'>knn_model_spec&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nv'>mpg&lt;/span> &lt;span class='o'>~&lt;/span> &lt;span class='nv'>.&lt;/span>,&lt;/span>
&lt;span> &lt;span class='nf'>bootstraps&lt;/span>&lt;span class='o'>(&lt;/span>&lt;span class='nv'>mtcars&lt;/span>, &lt;span class='m'>5&lt;/span>&lt;span class='o'>)&lt;/span>,&lt;/span>
&lt;span> control &lt;span class='o'>=&lt;/span> &lt;span class='nf'>&lt;a href='https://tune.tidymodels.org/reference/control_grid.html'>control_grid&lt;/a>&lt;/span>&lt;span class='o'>(&lt;/span>save_workflow &lt;span class='o'>=&lt;/span> &lt;span class='kc'>TRUE&lt;/span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='o'>)&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; # Tuning results&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; # Bootstrap sampling &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 5 × 4&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; splits id .metrics .notes &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/11]&amp;gt;&lt;/span> Bootstrap1 &lt;span style='color: #555555;'>&amp;lt;tibble [18 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>2&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/14]&amp;gt;&lt;/span> Bootstrap2 &lt;span style='color: #555555;'>&amp;lt;tibble [18 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>3&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/13]&amp;gt;&lt;/span> Bootstrap3 &lt;span style='color: #555555;'>&amp;lt;tibble [18 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>4&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/12]&amp;gt;&lt;/span> Bootstrap4 &lt;span style='color: #555555;'>&amp;lt;tibble [18 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>5&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/11]&amp;gt;&lt;/span> Bootstrap5 &lt;span style='color: #555555;'>&amp;lt;tibble [18 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;/span>
&lt;span>&lt;span class='c'># all is not lost!&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>.Last.tune.result&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; # Tuning results&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; # Bootstrap sampling &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'># A tibble: 5 × 4&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; splits id .metrics .notes &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;chr&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;span style='color: #555555; font-style: italic;'>&amp;lt;list&amp;gt;&lt;/span> &lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>1&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/11]&amp;gt;&lt;/span> Bootstrap1 &lt;span style='color: #555555;'>&amp;lt;tibble [18 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>2&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/14]&amp;gt;&lt;/span> Bootstrap2 &lt;span style='color: #555555;'>&amp;lt;tibble [18 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>3&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/13]&amp;gt;&lt;/span> Bootstrap3 &lt;span style='color: #555555;'>&amp;lt;tibble [18 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>4&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/12]&amp;gt;&lt;/span> Bootstrap4 &lt;span style='color: #555555;'>&amp;lt;tibble [18 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;span class='c'>#&amp;gt; &lt;span style='color: #555555;'>5&lt;/span> &lt;span style='color: #555555;'>&amp;lt;split [32/11]&amp;gt;&lt;/span> Bootstrap5 &lt;span style='color: #555555;'>&amp;lt;tibble [18 × 5]&amp;gt;&lt;/span> &lt;span style='color: #555555;'>&amp;lt;tibble [0 × 3]&amp;gt;&lt;/span>&lt;/span>&lt;/span>
&lt;span>&lt;/span>&lt;span>&lt;/span>
&lt;span>&lt;span class='c'># assign to object after the fact&lt;/span>&lt;/span>
&lt;span>&lt;span class='nv'>res&lt;/span> &lt;span class='o'>&amp;lt;-&lt;/span> &lt;span class='nv'>.Last.tune.result&lt;/span>&lt;/span>&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>These three releases introduce support for the &lt;code>.Last.tune.result&lt;/code> object in more settings and refine support in existing implementations.&lt;/p>
&lt;h2 id="acknowledgements">Acknowledgements
&lt;a href="#acknowledgements">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Thanks to
&lt;a href="https://github.com/walrossker" target="_blank" rel="noopener">@walrossker&lt;/a>,
&lt;a href="https://github.com/Freestyleyang" target="_blank" rel="noopener">@Freestyleyang&lt;/a>, and
&lt;a href="https://github.com/Jeffrothschild" target="_blank" rel="noopener">@Jeffrothschild&lt;/a> for their contributions to these packages since their last releases.&lt;/p>
&lt;p>Happy modeling, y&amp;rsquo;all!&lt;/p></description></item><item><title>New tidymodels releases for July 2021</title><link>https://www.tidyverse.org/blog/2021/07/tidymodels-july-2021/</link><pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2021/07/tidymodels-july-2021/</guid><description>&lt;!--
TODO:
* [ ] Look over / edit the post's title in the yaml
* [ ] Edit (or delete) the description; note this appears in the Twitter card
* [ ] Pick category and tags (see existing with `hugodown::tidy_show_meta()`)
* [ ] Find photo &amp; update yaml metadata
* [ ] Create `thumbnail-sq.jpg`; height and width should be equal
* [ ] Create `thumbnail-wd.jpg`; width should be >5x height
* [ ] `hugodown::use_tidy_thumbnails()`
* [ ] Add intro sentence, e.g. the standard tagline for the package
* [ ] `usethis::use_tidy_thanks()`
-->
&lt;p>The
&lt;a href="https://www.tidymodels.org/" target="_blank" rel="noopener">tidymodels&lt;/a> framework is a collection of R packages for modeling and machine learning using tidyverse principles. Earlier this year, we
&lt;a href="https://www.tidyverse.org/blog/2021/03/tidymodels-2021-q1/" target="_blank" rel="noopener">started regular updates&lt;/a> here on the tidyverse blog summarizing recent developments in the tidymodels ecosystem. You can check out the
&lt;a href="https://www.tidyverse.org/tags/tidymodels/" target="_blank" rel="noopener">&lt;code>tidymodels&lt;/code> tag&lt;/a> to find all tidymodels blog posts here, including those that focus on a single package or more major releases. The purpose of these roundup posts is to keep you informed about any releases you may have missed and useful new functionality as we maintain these packages.&lt;/p>
&lt;p>Recently, we had a series of CRAN releases:
&lt;a href="https://hardhat.tidymodels.org/news/index.html#hardhat-0-1-6-2021-07-14" target="_blank" rel="noopener">hardhat&lt;/a>,
&lt;a href="https://workflows.tidymodels.org/news/#workflows-0-2-3-2021-07-15" target="_blank" rel="noopener">workflows&lt;/a>,
&lt;a href="https://parsnip.tidymodels.org/news/#parsnip-0-1-7-2021-07-21" target="_blank" rel="noopener">parsnip&lt;/a>,
&lt;a href="https://tune.tidymodels.org/news/#tune-0-1-6-2021-07-21" target="_blank" rel="noopener">tune&lt;/a>,
&lt;a href="https://finetune.tidymodels.org/news/#finetune-0-1-0-unreleased" target="_blank" rel="noopener">finetune&lt;/a>,
&lt;a href="https://workflowsets.tidymodels.org/news/#workflowsets-0-1-0-unreleased" target="_blank" rel="noopener">workflowsets&lt;/a>, and
&lt;a href="https://discrim.tidymodels.org/news/#discrim-0-1-3-unreleased" target="_blank" rel="noopener">discrim&lt;/a>. These were coordinated because of some cross-package improvements. This blog post summarizes the changes.&lt;/p>
&lt;h2 id="object-extraction">Object extraction
&lt;a href="#object-extraction">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>The tidymodels team decided that we needed a consistent set of APIs for extracting things from objects. For example, a parsnip model contains the underlying model fit based on the engine. A &lt;code>linear_reg()&lt;/code> model with the &lt;code>&amp;quot;lm&amp;quot;&lt;/code> engine contains an &lt;code>lm&lt;/code> object. There were some existing functions to do this (mostly named &lt;code>pull_*()&lt;/code>) but they were fairly inconsistent and were not generics.&lt;/p>
&lt;p>We added the following functions: &lt;code>extract_fit_engine()&lt;/code>, &lt;code>extract_fit_parsnip()&lt;/code>, &lt;code>extract_mold()&lt;/code>, &lt;code>extract_numeric()&lt;/code>, &lt;code>extract_preprocessor()&lt;/code>, &lt;code>extract_recipe()&lt;/code>, &lt;code>extract_spec_parsnip()&lt;/code>, &lt;code>extract_workflow()&lt;/code>, and &lt;code>extract_workflow_set_result()&lt;/code>.&lt;/p>
&lt;p>The nice thing about this change is that a function such as &lt;code>extract_recipe()&lt;/code> can be used with objects created by the tune, workflows, or workflowsets packages.&lt;/p>
&lt;p>The existing &lt;code>pull_*()&lt;/code> methods have been soft-deprecated and will stick around for a while.&lt;/p>
&lt;h2 id="better-model-documentation">Better model documentation
&lt;a href="#better-model-documentation">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>One issue that we&amp;rsquo;ve seen in the parsnip documentation is that there is just &lt;em>so much&lt;/em> on each model page. It can be intimidating and difficult to find that one piece of information that you were looking for.&lt;/p>
&lt;p>We&amp;rsquo;ve reorganized the model pages so that there are now sub-packages for each engine. For example, when you use &lt;code>?linear_reg&lt;/code>, the help page has a &lt;em>dynamic&lt;/em> list of engines from parsnip or any parsnip-adjacent package that has been loaded. Here is what the
&lt;a href="https://parsnip.tidymodels.org/reference/linear_reg.html" target="_blank" rel="noopener">pkgdown site&lt;/a> looks like:&lt;/p>
&lt;p>&lt;img src="linear_reg.png" title="plot of chunk parsnip" alt="plot of chunk parsnip" width="90%" style="display: block; margin: auto;" />&lt;/p>
&lt;p>There is a similar dynamic list in the &lt;code>See Also&lt;/code> section.&lt;/p>
&lt;p>Each engine page provides basic information about tuning parameters, modes, preprocessing requirements, and anything else that we thing is relevant. For example, for the C5.0 engine for &lt;code>boost_tree()&lt;/code>:&lt;/p>
&lt;p>&lt;img src="C5.0.png" title="plot of chunk C50" alt="plot of chunk C50" width="90%" style="display: block; margin: auto;" />&lt;/p>
&lt;p>Finally, the existing parsnip documentation didn&amp;rsquo;t show the actual fitting and/or prediction in action. A
&lt;a href="https://parsnip.tidymodels.org/articles/articles/Examples.html" target="_blank" rel="noopener">new pkgdown article&lt;/a> has worked examples demonstrating the use of parsnip models on real data. Here is a screen shot for MARS regression via the earth package:&lt;/p>
&lt;p>&lt;img src="earth.png" title="plot of chunk earth" alt="plot of chunk earth" width="90%" style="display: block; margin: auto;" />&lt;/p>
&lt;p>We think that these changes will greatly improve the whole parsnip experience, especially for new users.&lt;/p>
&lt;h2 id="simpler-parsnip-and-workflows-interfaces">Simpler parsnip and workflows interfaces
&lt;a href="#simpler-parsnip-and-workflows-interfaces">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Our good friend and colleague
&lt;a href="https://twitter.com/drob" target="_blank" rel="noopener">David Robinson&lt;/a> had
&lt;a href="http://varianceexplained.org/r/sliced-ml/#where-tidymodels-can-improve" target="_blank" rel="noopener">some great ideas&lt;/a> for specific improvements for our APIs. After some discussion, both of his suggestions were implemented.&lt;/p>
&lt;p>First, we enabled a default engine for parsnip models (you may have noticed this in the screen shots above). This produces simpler code for some model functions and, if a model has a single mode, fitting is as concise as&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="c1"># use lm() for regression&lt;/span>
&lt;span class="nf">linear_reg&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span> &lt;span class="nf">fit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mpg&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">.,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mtcars&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Another nice feature is more succinct piping for workflows. A preprocessor, such as a formula or recipe, can be piped into &lt;code>workflow()&lt;/code> now. Also, there is an optional second argument in that function for the model specification.&lt;/p>
&lt;p>Instead of&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">car_rec&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">recipe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mpg&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">.,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mtcars&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">step_ns&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">disp&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">deg_free&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">car_wflow&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">workflow&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">add_recipe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">car_rec&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">add_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">linear_reg&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>you can now use&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">car_wflow&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">recipe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mpg&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">.,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mtcars&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">step_ns&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">disp&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">deg_free&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">5&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">workflow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">linear_reg&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you might be on the fence about using tidymodels,
&lt;a href="http://varianceexplained.org/r/sliced-ml/" target="_blank" rel="noopener">David&amp;rsquo;s blog post&lt;/a> does an excellent job encapsulating the benefits of our approach, so give it a read.&lt;/p>
&lt;h2 id="other-changes">Other changes
&lt;a href="#other-changes">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>parsnip now has a generalized additive model function
&lt;a href="https://parsnip.tidymodels.org/reference/gen_additive_mod.html" target="_blank" rel="noopener">&lt;code>gen_additive_mod()&lt;/code>&lt;/a>! There is currently one engine (&lt;code>mgcv&lt;/code>).&lt;/p>
&lt;p>The tune package has better control over random numbers since, in some cases, the
&lt;a href="https://github.com/tidymodels/tune/issues/389" target="_blank" rel="noopener">RNGkind was changed&lt;/a> after tuning a model.&lt;/p>
&lt;p>The discrim package has the new parsnip-like documentation and new model engines. Also, the shrunken discriminant analysis method of Ahdesmaki and Strimmer (2010) was added as an engine to &lt;code>discrim_linear()&lt;/code>. The newly resurrected sparsediscrim package allowed use to include new engines for
&lt;a href="https://discrim.tidymodels.org/reference/details_discrim_linear_sparsediscrim.html" target="_blank" rel="noopener">&lt;code>discrim_linear()&lt;/code>&lt;/a> and
&lt;a href="https://discrim.tidymodels.org/reference/details_discrim_quad_sparsediscrim.html" target="_blank" rel="noopener">&lt;code>discrim_quad()&lt;/code>&lt;/a>.&lt;/p>
&lt;h2 id="acknowledgements">Acknowledgements
&lt;a href="#acknowledgements">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>We&amp;rsquo;d like to thank everyone who has contributed to these packages since their last release:&lt;/p>
&lt;p>&lt;strong>hardhat&lt;/strong>:
&lt;a href="https://github.com/cregouby" target="_blank" rel="noopener">@cregouby&lt;/a>,
&lt;a href="https://github.com/DavisVaughan" target="_blank" rel="noopener">@DavisVaughan&lt;/a>,
&lt;a href="https://github.com/DiabbZegpi" target="_blank" rel="noopener">@DiabbZegpi&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/jwijffels" target="_blank" rel="noopener">@jwijffels&lt;/a>,
&lt;a href="https://github.com/LasWin" target="_blank" rel="noopener">@LasWin&lt;/a>, and
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>.&lt;/p>
&lt;p>&lt;strong>workflows&lt;/strong>:
&lt;a href="https://github.com/DavisVaughan" target="_blank" rel="noopener">@DavisVaughan&lt;/a>,
&lt;a href="https://github.com/dgrtwo" target="_blank" rel="noopener">@dgrtwo&lt;/a>,
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/LiamBlake" target="_blank" rel="noopener">@LiamBlake&lt;/a>, and
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>.&lt;/p>
&lt;p>&lt;strong>parsnip&lt;/strong>:
&lt;a href="https://github.com/cgoo4" target="_blank" rel="noopener">@cgoo4&lt;/a>,
&lt;a href="https://github.com/dgrtwo" target="_blank" rel="noopener">@dgrtwo&lt;/a>,
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/graysonwhite" target="_blank" rel="noopener">@graysonwhite&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/juliasilge" target="_blank" rel="noopener">@juliasilge&lt;/a>,
&lt;a href="https://github.com/mdancho84" target="_blank" rel="noopener">@mdancho84&lt;/a>,
&lt;a href="https://github.com/RaymondBalise" target="_blank" rel="noopener">@RaymondBalise&lt;/a>,
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>, and
&lt;a href="https://github.com/yutannihilation" target="_blank" rel="noopener">@yutannihilation&lt;/a>.&lt;/p>
&lt;p>&lt;strong>tune&lt;/strong>:
&lt;a href="https://github.com/amazongodman" target="_blank" rel="noopener">@amazongodman&lt;/a>,
&lt;a href="https://github.com/brshallo" target="_blank" rel="noopener">@brshallo&lt;/a>,
&lt;a href="https://github.com/dpanyard" target="_blank" rel="noopener">@dpanyard&lt;/a>,
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/juliasilge" target="_blank" rel="noopener">@juliasilge&lt;/a>,
&lt;a href="https://github.com/klin333" target="_blank" rel="noopener">@klin333&lt;/a>,
&lt;a href="https://github.com/mbac" target="_blank" rel="noopener">@mbac&lt;/a>,
&lt;a href="https://github.com/PathosEthosLogos" target="_blank" rel="noopener">@PathosEthosLogos&lt;/a>,
&lt;a href="https://github.com/tjcason" target="_blank" rel="noopener">@tjcason&lt;/a>,
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>, and
&lt;a href="https://github.com/yogat3ch" target="_blank" rel="noopener">@yogat3ch&lt;/a>.&lt;/p>
&lt;p>&lt;strong>finetune&lt;/strong>:
&lt;a href="https://github.com/DavisVaughan" target="_blank" rel="noopener">@DavisVaughan&lt;/a>,
&lt;a href="https://github.com/hfrick" target="_blank" rel="noopener">@hfrick&lt;/a>,
&lt;a href="https://github.com/hnagaty" target="_blank" rel="noopener">@hnagaty&lt;/a>,
&lt;a href="https://github.com/lukasal" target="_blank" rel="noopener">@lukasal&lt;/a>,
&lt;a href="https://github.com/Mayalaroz" target="_blank" rel="noopener">@Mayalaroz&lt;/a>,
&lt;a href="https://github.com/mrkaye97" target="_blank" rel="noopener">@mrkaye97&lt;/a>,
&lt;a href="https://github.com/shinyquant" target="_blank" rel="noopener">@shinyquant&lt;/a>,
&lt;a href="https://github.com/skeydan" target="_blank" rel="noopener">@skeydan&lt;/a>, and
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>.&lt;/p>
&lt;p>&lt;strong>workflowsets&lt;/strong>:
&lt;a href="https://github.com/amazongodman" target="_blank" rel="noopener">@amazongodman&lt;/a>,
&lt;a href="https://github.com/jonthegeek" target="_blank" rel="noopener">@jonthegeek&lt;/a>,
&lt;a href="https://github.com/juliasilge" target="_blank" rel="noopener">@juliasilge&lt;/a>,
&lt;a href="https://github.com/oskasf" target="_blank" rel="noopener">@oskasf&lt;/a>,
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>, and
&lt;a href="https://github.com/yogat3ch" target="_blank" rel="noopener">@yogat3ch&lt;/a>.&lt;/p>
&lt;p>&lt;strong>discrim&lt;/strong>:
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>.&lt;/p></description></item><item><title>finetune 0.0.1</title><link>https://www.tidyverse.org/blog/2020/12/finetune-0-0-1/</link><pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2020/12/finetune-0-0-1/</guid><description>&lt;!--
TODO:
* [ ] Pick category and tags (see existing with `post_tags()`)
* [ ] Find photo &amp; update yaml metadata
* [ ] Create `thumbnail-sq.jpg`; height and width should be equal
* [ ] Create `thumbnail-wd.jpg`; width should be >5x height
* [ ] `hugodown::use_tidy_thumbnail()`
* [ ] Add intro sentence
* [ ] `use_tidy_thanks()`
-->
&lt;p>We&amp;rsquo;re thrilled to announce the first release of the
&lt;a href="https://finetune.tidymodels.org/" target="_blank" rel="noopener">finetune&lt;/a> package. finetune adds two additional approaches for model tuning.&lt;/p>
&lt;p>You can install it from CRAN with:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">install.packages&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;finetune&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This blog post will describe the two new tools in the package.&lt;/p>
&lt;h2 id="racing">Racing
&lt;a href="#racing">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Tuning parameters are unknown quantities of a model that cannot be directly estimated from the data. The number of neighbors in a K nearest neighbor model is a good example.&lt;/p>
&lt;p>Grid search is a common method to find good values for model tuning parameters. A pre-defined set of parameters are created and often resampled so that good estimates of model performance are available. The user then choses a tuning parameter value that has acceptable results.&lt;/p>
&lt;p>The problem with this approach is that it requires all of the results to be able to make a decision. For example, if we evaluate 50 tuning parameter values on 10 resamples, 500 model fits are evaluated before any analysis of the results takes place.&lt;/p>
&lt;p>Racing methods, devised by
&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C7&amp;amp;q=Hoeffding&amp;#43;races%3A&amp;#43;Accelerating&amp;#43;model&amp;#43;selection&amp;#43;search&amp;#43;for&amp;#43;classification&amp;#43;and&amp;#43;function&amp;#43;approximation&amp;amp;btnG=" target="_blank" rel="noopener">Maron and Moore (1994)&lt;/a>, enables a sequential type of grid search. All model parameters are evaluated on a few resamples. Racing methods analyze the initial results to determine if any of the tuning parameters are unacceptable enough to discard. If the analysis discards any parameters, they are not resampled further. This process can considerably reduce the total number of model evaluations. finetune has functions &lt;code>tune_race_anova()&lt;/code> and &lt;code>tune_race_win_loss()&lt;/code> for this purpose (with syntax similar to &lt;code>tune_grid()&lt;/code>). Their analysis details are described in
&lt;a href="https://arxiv.org/abs/1405.6974" target="_blank" rel="noopener">Kuhn (2014)&lt;/a>.&lt;/p>
&lt;p>As an example, we&amp;rsquo;ll tune a K nearest neighbor (KNN) model on the sonar data. The grid will consist of 20 tuning parameters values in conjunction with 25 bootstrap resamples.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tidymodels&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">finetune&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mlbench&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nf">data&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Sonar&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># create resamples&lt;/span>
&lt;span class="nf">set.seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">100&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">resamp&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">bootstraps&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Sonar&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># create a model specification&lt;/span>
&lt;span class="n">model&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">nearest_neighbor&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">neighbors&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">tune&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">weight_func&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">tune&lt;/span>&lt;span class="p">(),&lt;/span>
&lt;span class="n">dist_power&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">tune&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">set_engine&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;kknn&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">set_mode&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;classification&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># center and scale the data using a recipe&lt;/span>
&lt;span class="n">norm_rec&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">recipe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Class&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">.,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Sonar&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">step_normalize&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">all_predictors&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="n">ctrl&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">control_race&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">verbose_elim&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">TRUE&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nf">set.seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">101&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">sonar_race&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="n">model&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">tune_race_anova&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">norm_rec&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">resamples&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">resamp&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">grid&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">control&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ctrl&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## ℹ Racing will maximize the roc_auc metric.
## ℹ Resamples are analyzed in a random order.
## ℹ Bootstrap23: 9 eliminated; 11 candidates remain.
## ℹ Bootstrap18: 4 eliminated; 7 candidates remain.
## ℹ Bootstrap05: 1 eliminated; 6 candidates remain.
## ℹ Bootstrap06: 0 eliminated; 6 candidates remain.
## ℹ Bootstrap08: 1 eliminated; 5 candidates remain.
## ℹ Bootstrap01: 0 eliminated; 5 candidates remain.
## ℹ Bootstrap19: 0 eliminated; 5 candidates remain.
## ℹ Bootstrap15: 0 eliminated; 5 candidates remain.
## ℹ Bootstrap10: 0 eliminated; 5 candidates remain.
## ℹ Bootstrap07: 0 eliminated; 5 candidates remain.
## ℹ Bootstrap16: 2 eliminated; 3 candidates remain.
## ℹ Bootstrap09: 0 eliminated; 3 candidates remain.
## ℹ Bootstrap04: 0 eliminated; 3 candidates remain.
## ℹ Bootstrap24: 0 eliminated; 3 candidates remain.
## ℹ Bootstrap21: 0 eliminated; 3 candidates remain.
## ℹ Bootstrap12: 0 eliminated; 3 candidates remain.
## ℹ Bootstrap03: 0 eliminated; 3 candidates remain.
## ℹ Bootstrap13: 0 eliminated; 3 candidates remain.
## ℹ Bootstrap17: 0 eliminated; 3 candidates remain.
## ℹ Bootstrap11: 0 eliminated; 3 candidates remain.
## ℹ Bootstrap25: 0 eliminated; 3 candidates remain.
## ℹ Bootstrap14: 0 eliminated; 3 candidates remain.
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">show_best&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sonar_race&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;roc_auc&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 3 x 9
## neighbors weight_func dist_power .metric .estimator mean n std_err
## &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 14 triweight 0.902 roc_auc binary 0.938 25 0.00647
## 2 11 biweight 1.62 roc_auc binary 0.937 25 0.00627
## 3 10 biweight 0.501 roc_auc binary 0.934 25 0.00563
## # … with 1 more variable: .config &amp;lt;chr&amp;gt;
&lt;/code>&lt;/pre>&lt;p>Using this approach, we evaluated 156 models (less than half of the full set of 500). The
&lt;a href="https://finetune.tidymodels.org/reference/tune_race_anova.html#details" target="_blank" rel="noopener">help file&lt;/a> describes how parallel processing can also be used to further speed up the racing process.&lt;/p>
&lt;p>There is also a handy plotting function that demonstrates how models are eliminated in the racing process:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">plot_race&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sonar_race&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nf">theme_bw&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/race-1.svg" alt="plot of chunk race">&lt;/p>
&lt;p>Each line corresponds to a tuning parameter combination. Models with suboptimal ROC scores are eliminated quickly.&lt;/p>
&lt;h2 id="simulated-annealing">Simulated Annealing
&lt;a href="#simulated-annealing">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Simulated annealing is an old global search method that does a controlled random walk. In our application, the walk is through the tuning parameter space. finetune uses it as an iterative search method where new tuning parameter values are created during the process (as opposed to a pre-defined grid). The &lt;code>tune_sim_anneal()&lt;/code> function has syntax that is very similar to the &lt;code>tune_bayes()&lt;/code> function.&lt;/p>
&lt;p>For our KNN model:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">ctrl&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">control_sim_anneal&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">verbose&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">TRUE&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nf">set.seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">102&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">sonar_sa&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="n">model&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">tune_sim_anneal&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">norm_rec&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">resamples&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">resamp&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">iter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">control&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ctrl&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## &amp;gt; Generating a set of 1 initial parameter results
## ✓ Initialization complete
##
## Optimizing roc_auc
## Initial best: 0.91295
## 1 ◯ accept suboptimal roc_auc=0.86702 (+/-0.009415)
## 2 + better suboptimal roc_auc=0.89481 (+/-0.007461)
## 3 ♥ new best roc_auc=0.91818 (+/-0.006982)
## 4 ♥ new best roc_auc=0.93033 (+/-0.006978)
## 5 ♥ new best roc_auc=0.93181 (+/-0.006744)
## 6 ◯ accept suboptimal roc_auc=0.87504 (+/-0.009216)
## 7 + better suboptimal roc_auc=0.8849 (+/-0.00875)
## 8 ♥ new best roc_auc=0.93647 (+/-0.00611)
## 9 ◯ accept suboptimal roc_auc=0.92365 (+/-0.006366)
## 10 ─ discard suboptimal roc_auc=0.88774 (+/-0.007586)
## 11 + better suboptimal roc_auc=0.92405 (+/-0.006807)
## 12 ◯ accept suboptimal roc_auc=0.92211 (+/-0.006764)
## 13 + better suboptimal roc_auc=0.9297 (+/-0.006814)
## 14 ─ discard suboptimal roc_auc=0.86171 (+/-0.008326)
## 15 ─ discard suboptimal roc_auc=0.88501 (+/-0.007397)
## 16 x restart from best roc_auc=0.92734 (+/-0.006484)
## 17 ◯ accept suboptimal roc_auc=0.93554 (+/-0.006326)
## 18 ◯ accept suboptimal roc_auc=0.92682 (+/-0.006275)
## 19 + better suboptimal roc_auc=0.93057 (+/-0.006371)
## 20 ♥ new best roc_auc=0.94017 (+/-0.006516)
## 21 ◯ accept suboptimal roc_auc=0.92589 (+/-0.006573)
## 22 + better suboptimal roc_auc=0.92809 (+/-0.006609)
## 23 + better suboptimal roc_auc=0.93439 (+/-0.006754)
## 24 ◯ accept suboptimal roc_auc=0.9314 (+/-0.00656)
## 25 ◯ accept suboptimal roc_auc=0.93076 (+/-0.007003)
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">show_best&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sonar_sa&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;roc_auc&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 5 x 10
## neighbors weight_func dist_power .metric .estimator mean n std_err
## &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 10 triweight 1.50 roc_auc binary 0.940 25 0.00652
## 2 11 biweight 1.78 roc_auc binary 0.936 25 0.00611
## 3 10 biweight 1.92 roc_auc binary 0.936 25 0.00633
## 4 8 triweight 1.32 roc_auc binary 0.934 25 0.00675
## 5 7 cos 1.59 roc_auc binary 0.932 25 0.00674
## # … with 2 more variables: .config &amp;lt;chr&amp;gt;, .iter &amp;lt;int&amp;gt;
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">autoplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sonar_sa&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">type&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;performance&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;roc_auc&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nf">theme_bw&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/sa-best-1.svg" alt="plot of chunk sa-best">&lt;/p>
&lt;p>We&amp;rsquo;ll have more information on both these methods in a next release of chapters for
&lt;a href="https://www.tmwr.org/" target="_blank" rel="noopener">&lt;em>Tidy Modeling with R&lt;/em>&lt;/a>.&lt;/p></description></item><item><title>Parallel processing with tune</title><link>https://www.tidyverse.org/blog/2020/11/tune-parallel/</link><pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2020/11/tune-parallel/</guid><description>&lt;!--
TODO:
* [ ] Pick category and tags (see existing with `post_tags()`)
* [ ] Find photo &amp; update yaml metadata
* [ ] Create `thumbnail-sq.jpg`; height and width should be equal
* [ ] Create `thumbnail-wd.jpg`; width should be >5x height
* [ ] `hugodown::use_tidy_thumbnail()`
* [ ] Add intro sentence
* [ ] `use_tidy_thanks()`
-->
&lt;p>This is the third post related to version 0.1.2 of the tune package. The
&lt;a href="https://www.tidyverse.org/blog/2020/11/tune-0-1-2/" target="_blank" rel="noopener">first post&lt;/a> discussed various new features while the
&lt;a href="https://www.tidyverse.org/blog/2020/11/tidymodels-sparse-support/" target="_blank" rel="noopener">second post&lt;/a> describes sparse matrix support. This post is an excerpt from an upcoming chapter in
&lt;a href="https://www.tmwr.org/" target="_blank" rel="noopener">&lt;em>Tidy Modeling with R&lt;/em>&lt;/a> and is focused on parallel processing.&lt;/p>
&lt;p>Previously, the tune package allowed for parallel processing of calculations in a few different places:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Simple model resampling via &lt;code>resample_fit()&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Model tuning via &lt;code>tune_grid()&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>During Bayesian optimization (&lt;code>tune_bayes()&lt;/code>)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>In the new version of tune, there are more options related to how parallelism occurs. It&amp;rsquo;s a little complicated and we&amp;rsquo;ll start by describing the most basic method.&lt;/p>
&lt;h2 id="parallelizing-the-resampling-loop">Parallelizing the resampling loop
&lt;a href="#parallelizing-the-resampling-loop">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>For illustration, let&amp;rsquo;s suppose that we are tuning a set of model parameters (e.g. not recipe parameters). In tidymodels, we always use
&lt;a href="https://www.tmwr.org/resampling.html" target="_blank" rel="noopener">out-of-sample predictions to measure performance&lt;/a>. With grid search, pseudo-code that illustrates the computations are:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">for &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">resample&lt;/span> &lt;span class="n">in&lt;/span> &lt;span class="n">resamples&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1"># Create analysis and assessment sets&lt;/span>
&lt;span class="c1"># Preprocess data (e.g. formula or recipe)&lt;/span>
&lt;span class="nf">for &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span> &lt;span class="n">in&lt;/span> &lt;span class="n">configurations&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1"># Fit {model} to the {resample} analysis set&lt;/span>
&lt;span class="c1"># Predict the {resample} assessment set&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Prior to the new version of tune, the only option was to run the outer resampling loop in parallel. The inner modeling loop is run sequentially. The rationale for this was this: if you are doing any significant preprocessing of the data (e.g., a complex recipe), you only have to do that as many times as you have resamples. Since the model tuning is conditional on the preprocessed data, this is pretty computationally efficient.&lt;/p>
&lt;p>There were two downsides to this approach:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Suppose you have 10 resamples but access to 20 cores. The maximum core utilization would be 10 and using 10 cores might not maximize the computational efficiency.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Since tidymodels treats validation sets as a single resample, you can&amp;rsquo;t parallel process at all.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Parallel processing is somewhat unpredictable. While you might have a lot of cores (or machines) to throw at the problem, adding more might not help. This really depends on the model, the size of the data, and the parallel strategy used (i.e. forking vs socket).&lt;/p>
&lt;p>To illustrate how this approach utilizes parallel workers, we&amp;rsquo;ll use a case where there are 7 model tuning parameter values along with 5-fold cross-validation. This visualization shows how the tasks are allocated to the worker processes:&lt;/p>
&lt;p>&lt;img src="figure/grid-logging-rs-1.svg" title="plot of chunk grid-logging-rs" alt="plot of chunk grid-logging-rs" width="70%" />&lt;/p>
&lt;p>The code assigns each of the five resamples to their own worker process which, in this case, is a core on a single desktop machine. That worker conducts the preprocessing then loops over the models. The preprocessing happens once per resample.&lt;/p>
&lt;p>In the new version of tune, there is a control option called &lt;code>parallel_over&lt;/code>. Setting this to a value of &lt;code>&amp;quot;resamples&amp;quot;&lt;/code> will select this scheme to parallelize the computations.&lt;/p>
&lt;h2 id="parallelizing-everything">Parallelizing everything
&lt;a href="#parallelizing-everything">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Another option that we can pursue is to take the two loops shown above and merge them into a single loop.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">all_tasks&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">crossing&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">resamples&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">configurations&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nf">for &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">iter&lt;/span> &lt;span class="n">in&lt;/span> &lt;span class="n">all_tasks&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="c1"># Create analysis and assessment sets for {iter}&lt;/span>
&lt;span class="c1"># Preprocess data (e.g. formula or recipe)&lt;/span>
&lt;span class="c1"># Fit model {iter} to the {iter} analysis set&lt;/span>
&lt;span class="c1"># Predict the {iter} assessment set&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>With seven models and five resamples there are a total of 35 separate tasks that can be given to the worker processes. For this example, that would allow up to 35 cores/machines to run simultaneously. If we use a validation set, this would also enable the model loop to run in parallel.&lt;/p>
&lt;p>The downside to this approach is that the preprocessing is unnecessarily repeated multiple times (depending on how tasks are allocated to the worker processes).&lt;/p>
&lt;p>Taking our previous example, here is what the allocations look like if the 35 tasks are run across 10 cores:&lt;/p>
&lt;p>&lt;img src="figure/grid-logging-all-1.svg" alt="plot of chunk grid-logging-all">&lt;/p>
&lt;p>For each resample, the preprocessing is needlessly run six additional times. If the preprocessing is fast, this might be the best approach.&lt;/p>
&lt;p>To enable this approach, the control option is set to &lt;code>parallel_over = &amp;quot;everything&amp;quot;&lt;/code>.&lt;/p>
&lt;h2 id="automatic-strategy-detection">Automatic strategy detection
&lt;a href="#automatic-strategy-detection">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>The default for &lt;code>parallel_over&lt;/code> is &lt;code>NULL&lt;/code>. This allows us to check and see if there are multiple resamples. If that is the case, it uses a value of &lt;code>&amp;quot;resamples&amp;quot;&lt;/code>; otherwise, &lt;code>&amp;quot;everything&amp;quot;&lt;/code> is used.&lt;/p>
&lt;h2 id="how-much-faster-are-the-computations">How much faster are the computations?
&lt;a href="#how-much-faster-are-the-computations">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>As an example, we tuned a boosted tree with the &lt;code>xgboost&lt;/code> engine on a data set of 4,000 samples. Five-fold cross-validation was used with 10 candidate models. These data required some baseline preprocessing that did not require any estimation. The preprocessing was handled three different ways:&lt;/p>
&lt;ol>
&lt;li>Preprocess the data prior to modeling using a &lt;code>dplyr&lt;/code> pipeline (labeled as &amp;ldquo;none&amp;rdquo; in the plots below).&lt;/li>
&lt;li>Conduct the same preprocessing using a recipe (shown as &amp;ldquo;light&amp;rdquo; preprocessing).&lt;/li>
&lt;li>With a recipe, add an additional step that has a high computational cost (labeled as &amp;ldquo;expensive&amp;rdquo;).&lt;/li>
&lt;/ol>
&lt;p>The first and second preprocessing options are designed to measure the computational cost of the recipe. The third option measures the cost of performing redundant computations with &lt;code>parallel_over = &amp;quot;everything&amp;quot;&lt;/code>.&lt;/p>
&lt;p>We evaluated this process using variable number of worker processes and using the two &lt;code>parallel_over&lt;/code> options. The computer has 10 physical cores and 20 virtual cores (via hyper threading).&lt;/p>
&lt;p>Let&amp;rsquo;s consider the raw execution times:&lt;/p>
&lt;p>&lt;img src="figure/grid-par-times-1.svg" alt="plot of chunk grid-par-times">&lt;/p>
&lt;p>Since there were only five resamples, the number of cores used when &lt;code>parallel_over = &amp;quot;resamples&amp;quot;&lt;/code> is limited to five.&lt;/p>
&lt;p>Comparing the curves in the first two panels for &amp;ldquo;none&amp;rdquo; and &amp;ldquo;light&amp;rdquo;:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>There is little difference in the execution times between the panels. This indicates, for these data, there is no real computational penalty for doing the preprocessing steps in a recipe.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>There is some benefit for using &lt;code>parallel_over = &amp;quot;everything&amp;quot;&lt;/code> with many cores. However, as shown below, the majority of the benefit of parallel processing occurs in the first five workers.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>With the expensive preprocessing step, there is a considerable difference in execution times. Using &lt;code>parallel_over = &amp;quot;everything&amp;quot;&lt;/code> is problematic since, even using all cores, it never achieves the execution time that &lt;code>parallel_over = &amp;quot;resamples&amp;quot;&lt;/code> attains with five cores. This is because the costly preprocessing step is unnecessarily repeated in the computational scheme.&lt;/p>
&lt;h2 id="psock-clusters">PSOCK clusters
&lt;a href="#psock-clusters">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>The primary method for parallel processing on Windows computers uses a PSOCK cluster. From
&lt;a href="https://www.oreilly.com/library/view/parallel-r/9781449317850/" target="_blank" rel="noopener">&lt;em>Parallel R&lt;/em>&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>&amp;ldquo;The parallel package comes with two transports: &amp;lsquo;PSOCK&amp;rsquo; and &amp;lsquo;FORK&amp;rsquo;. The &amp;lsquo;PSOCK&amp;rsquo; transport is a streamlined version of
&lt;a href="https://biostats.bepress.com/uwbiostat/paper193/" target="_blank" rel="noopener">snow&lt;/a>&amp;lsquo;s &amp;lsquo;SOCK&amp;rsquo; transport. It starts workers using the Rscript command, and communicates between the master and workers using socket connections.&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;p>This method works on all major operating systems.&lt;/p>
&lt;p>Different parallel processing technologies work in different ways. About mid-year we started to receive a number of issue reports where PSOCK clusters were failing on Windows. This was due to how parallel workers are initialized; they really don&amp;rsquo;t know anything about the main R process (e.g., what packages are loaded, what data objects should have access, etc). Those problems are now solved with the most recent versions of the parsnip, recipes, and tune packages.&lt;/p></description></item><item><title>Sparse data structures in tidymodels</title><link>https://www.tidyverse.org/blog/2020/11/tidymodels-sparse-support/</link><pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2020/11/tidymodels-sparse-support/</guid><description>&lt;p>The new release of
&lt;a href="https://www.tidyverse.org/blog/2020/11/tune-0-1-2/" target="_blank" rel="noopener">tune&lt;/a> is chock full of improvements and new features. This blog post is the second of three posts exploring the updates available in tune 0.1.2. When combined with the latest releases of
&lt;a href="http://hardhat.tidymodels.org/" target="_blank" rel="noopener">hardhat&lt;/a> and
&lt;a href="https://parsnip.tidymodels.org/" target="_blank" rel="noopener">parsnip&lt;/a>, one upgrade that tidymodels users can now use in their day-to-day modeling work is some &lt;strong>support for sparse data structures&lt;/strong> during fitting and tuning.&lt;/p>
&lt;h2 id="why-sparse-data">Why sparse data?
&lt;a href="#why-sparse-data">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>In some subject matter domains, it is common to have lots and lots of zeroes after transforming data to a representation appropriate for analysis or modeling. Text data is one such example. The &lt;code>small_fine_foods&lt;/code> dataset of Amazon reviews of fine foods contains a column &lt;code>review&lt;/code> that we as humans can read and understand.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tidyverse&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tidymodels&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nf">data&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;small_fine_foods&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">training_data&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 4,000 x 3
## product review score
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;fct&amp;gt;
## 1 B000J0LSBG &amp;quot;this stuff is not stuffing its not good at all save your… other
## 2 B000EYLDYE &amp;quot;I absolutely LOVE this dried fruit. LOVE IT. Whenever I ha… great
## 3 B0026LIO9A &amp;quot;GREAT DEAL, CONVENIENT TOO. Much cheaper than WalMart and I… great
## 4 B00473P8SK &amp;quot;Great flavor, we go through a ton of this sauce! I discovere… great
## 5 B001SAWTNM &amp;quot;This is excellent salsa/hot sauce, but you can get it for $2… great
## 6 B000FAG90U &amp;quot;Again, this is the best dogfood out there. One suggestion: … great
## 7 B006BXTCEK &amp;quot;The box I received was filled with teas, hot chocolates, and… other
## 8 B002GWH5OY &amp;quot;This is delicious coffee which compares favorably with much … great
## 9 B003R0MFYY &amp;quot;Don't let these little tiny cans fool you. They pack a lot … great
## 10 B001EO5ZXI &amp;quot;One of the nicest, smoothest cup of chai I've made. Nice mix… great
## # … with 3,990 more rows
&lt;/code>&lt;/pre>&lt;p>Computers, on the other hand, need that &lt;code>review&lt;/code> variable to be heavily preprocessed and transformed in order for it to be ready for most modeling. We typically need to
&lt;a href="https://smltar.com/tokenization.html" target="_blank" rel="noopener">tokenize&lt;/a> the text, find word frequencies, and perhaps
&lt;a href="https://www.tidytextmining.com/tfidf.html" target="_blank" rel="noopener">compute tf-idf&lt;/a>. There are quite a number of different structures we can use to store the results of this preprocessing. We can keep the results in a long, tidy tibble, which is excellent for exploratory data analysis.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tidytext&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">tidy_reviews&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="n">training_data&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">unnest_tokens&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">review&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">count&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">product&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">bind_tf_idf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">product&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">tidy_reviews&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 208,306 x 6
## product word n tf idf tf_idf
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 B0000691JF and 1 0.1 0.234 0.0234
## 2 B0000691JF i 1 0.1 0.262 0.0262
## 3 B0000691JF in 1 0.1 0.654 0.0654
## 4 B0000691JF just 1 0.1 1.54 0.154
## 5 B0000691JF manner 1 0.1 5.52 0.552
## 6 B0000691JF ordered 1 0.1 2.76 0.276
## 7 B0000691JF prompt 1 0.1 5.81 0.581
## 8 B0000691JF the 1 0.1 0.206 0.0206
## 9 B0000691JF usual 1 0.1 5.04 0.504
## 10 B0000691JF what 1 0.1 2.27 0.227
## # … with 208,296 more rows
&lt;/code>&lt;/pre>&lt;p>We can also transform these results to a wide format, often a good fit when the next step is a modeling or machine learning algorithm.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">wide_reviews&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="n">tidy_reviews&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">select&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">product&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tf_idf&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">pivot_wider&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">names_from&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">names_prefix&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;word_&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">values_from&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf_idf&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">values_fill&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">wide_reviews&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 4,000 x 13,797
## product word_and word_i word_in word_just word_manner word_ordered word_prompt
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 B00006… 0.0234 0.0262 0.0654 0.154 0.552 0.276 0.581
## 2 B00008… 0.00780 0 0 0 0 0 0
## 3 B00008… 0.00177 0.00397 0.0198 0.0117 0 0 0
## 4 B00008… 0.00582 0.00489 0.00813 0 0 0 0
## 5 B00008… 0.00246 0.0166 0.0207 0.0162 0 0 0
## 6 B00008… 0.00334 0.00750 0.00935 0 0 0 0
## 7 B00008… 0.0114 0.00729 0.00909 0 0 0 0
## 8 B00008… 0.00768 0.0129 0 0 0 0 0
## 9 B00008… 0.00976 0 0 0 0 0 0
## 10 B00008… 0.0156 0 0 0 0 0 0
## 11 B00008… 0.00404 0.0181 0 0 0 0 0
## 12 B00008… 0.0142 0.00397 0 0 0 0 0
## 13 B00008… 0.0160 0.00596 0.0149 0.0351 0 0 0
## 14 B00009… 0.00439 0.00656 0.00818 0 0 0 0
## 15 B0000A… 0.00679 0.00380 0.0379 0 0 0.0401 0
## # … with 3,985 more rows, and 13,789 more variables: word_the &amp;lt;dbl&amp;gt;,
## # word_usual &amp;lt;dbl&amp;gt;, word_what &amp;lt;dbl&amp;gt;, word_a &amp;lt;dbl&amp;gt;, word_anymore &amp;lt;dbl&amp;gt;,
## # word_chocolate &amp;lt;dbl&amp;gt;, word_coat &amp;lt;dbl&amp;gt;, word_dogfood &amp;lt;dbl&amp;gt;, word_ears &amp;lt;dbl&amp;gt;,
## # word_fine &amp;lt;dbl&amp;gt;, word_for &amp;lt;dbl&amp;gt;, word_great &amp;lt;dbl&amp;gt;, word_hardly &amp;lt;dbl&amp;gt;,
## # word_he &amp;lt;dbl&amp;gt;, word_health &amp;lt;dbl&amp;gt;, word_his &amp;lt;dbl&amp;gt;, word_hot &amp;lt;dbl&amp;gt;,
## # word_is &amp;lt;dbl&amp;gt;, word_itching &amp;lt;dbl&amp;gt;, word_lab &amp;lt;dbl&amp;gt;, …
&lt;/code>&lt;/pre>&lt;p>Lots of zeroes! Instead of using a tibble, we can transform these results to a &lt;strong>sparse matrix&lt;/strong>, a specialized data structure that keeps track of only the non-zero elements instead of every element.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">sparse_reviews&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="n">tidy_reviews&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">cast_dfm&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">product&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tf_idf&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">sparse_reviews&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## Document-feature matrix of: 4,000 documents, 13,796 features (99.6% sparse).
&lt;/code>&lt;/pre>&lt;p>As is typical for text data, this document-feature matrix is extremely sparse, with many zeroes. Most documents do not contain most words. By using this kind of specialized structure instead of anything like a vanilla &lt;code>matrix&lt;/code> or &lt;code>data.frame&lt;/code>, we secure two benefits:&lt;/p>
&lt;ul>
&lt;li>We can taken advantage of the &lt;strong>speed&lt;/strong> gained from any specialized model algorithms built for sparse data.&lt;/li>
&lt;li>The amount of &lt;strong>memory&lt;/strong> this object requires decreases dramatically.&lt;/li>
&lt;/ul>
&lt;p>How big of a change in memory are we talking about?&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">lobstr&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="nf">obj_sizes&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">wide_reviews&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">sparse_reviews&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## * 443,539,792 B
## * 3,581,200 B
&lt;/code>&lt;/pre>
&lt;h2 id="a-blueprint-for-sparse-models">A blueprint for sparse models
&lt;a href="#a-blueprint-for-sparse-models">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Before the most recent releases of hardhat, parsnip, and tune, there was no support for sparse data structures within tidymodels. Now, you can specify a hardhat &lt;strong>blueprint&lt;/strong> for sparse data.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hardhat&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">sparse_bp&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">default_recipe_blueprint&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">composition&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;dgCMatrix&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>dgCMatrix&lt;/code> composition is from the
&lt;a href="https://cran.r-project.org/package=Matrix" target="_blank" rel="noopener">Matrix&lt;/a> package, and is the most standard class for sparse numeric matrices in modeling in R. (You can also specify a dense matrix composition with &lt;code>composition = &amp;quot;matrix&amp;quot;&lt;/code>.)&lt;/p>
&lt;h2 id="workflows-and-sparsity">Workflows and sparsity
&lt;a href="#workflows-and-sparsity">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>The blueprint is used under the hood by the hardhat functions to process data. To get ready to fit our model using the sparse blueprint, we can set up our preprocessing recipe:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">textrecipes&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">text_rec&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">recipe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">score&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">review&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">training_data&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">step_tokenize&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">review&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">step_stopwords&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">review&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">step_tokenfilter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">review&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">max_tokens&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">1e3&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">step_tfidf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">review&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And we set up our model as we would normally:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">lasso_spec&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">logistic_reg&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">penalty&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">0.02&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">mixture&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">set_engine&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;glmnet&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The regularized modeling of the glmnet package is an example of an algorithm that has specialized approaches for sparse data. If we pass in dense data with &lt;code>set_engine(&amp;quot;glmnet&amp;quot;)&lt;/code>, the underlying model will take one approach, but it will use a different, faster approach especially built for sparse data if we pass in a sparse matrix. Typically, we would recommend centering and scaling predictors using &lt;code>step_normalize()&lt;/code> before fitting a regularized model like glmnet. However, if we do this, we would no longer have all our zeroes and sparse data. Instead, we can &amp;ldquo;normalize&amp;rdquo; these text predictors using tf-idf so that they are all on the same scale.&lt;/p>
&lt;p>Let&amp;rsquo;s put together two workflows, one using the sparse blueprint and one using the default behavior.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">wf_sparse&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">workflow&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">add_recipe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text_rec&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">blueprint&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sparse_bp&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">add_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">lasso_spec&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">wf_default&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">workflow&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">add_recipe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text_rec&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">add_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">lasso_spec&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>
&lt;h2 id="comparing-model-results">Comparing model results
&lt;a href="#comparing-model-results">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Now let&amp;rsquo;s use &lt;code>fit_resamples()&lt;/code> to estimate how well this model fits with both options and measure performance for both.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">set.seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">123&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">food_folds&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">vfold_cv&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">training_data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">v&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">results&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="n">bench&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="nf">mark&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">iterations&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">check&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">FALSE&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">sparse&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">fit_resamples&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">wf_sparse&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">food_folds&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="n">default&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">fit_resamples&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">wf_default&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">food_folds&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="n">results&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 2 x 6
## expression min median `itr/sec` mem_alloc `gc/sec`
## &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt; &amp;lt;dbl&amp;gt;
## 1 sparse 7.78s 7.87s 0.127 788MB 0.127
## 2 default 1.19m 1.2m 0.0139 870MB 0.0139
&lt;/code>&lt;/pre>&lt;p>We see on the order of a 10x speed gain by using the sparse blueprint!&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">autoplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">results&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">type&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;ridge&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/unnamed-chunk-11-1.png" alt="plot of chunk unnamed-chunk-11">&lt;/p>
&lt;p>The model performance metrics are the same:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">fit_resamples&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">wf_sparse&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">food_folds&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">collect_metrics&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 2 x 5
## .metric .estimator mean n std_err
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.715 3 0.00399
## 2 roc_auc binary 0.797 3 0.00598
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">fit_resamples&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">wf_default&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">food_folds&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">collect_metrics&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 2 x 5
## .metric .estimator mean n std_err
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 accuracy binary 0.715 3 0.00399
## 2 roc_auc binary 0.797 3 0.00598
&lt;/code>&lt;/pre>&lt;p>To see a detailed text modeling example using this dataset of food reviews, &lt;em>without&lt;/em> sparse encodings but complete with tuning hyperparameters, check out
&lt;a href="https://www.tidymodels.org/learn/work/tune-text/" target="_blank" rel="noopener">our article on &lt;code>tidymodels.org&lt;/code>&lt;/a>.&lt;/p>
&lt;h2 id="current-limits">Current limits
&lt;a href="#current-limits">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>In tidymodels, the support for sparse data structures begins coming &lt;em>out&lt;/em> of a
&lt;a href="https://www.tmwr.org/recipes.html" target="_blank" rel="noopener">preprocessing recipe&lt;/a> and continues throughout the fitting and tuning process. We typically still expect the input &lt;em>into&lt;/em> a recipe to be a data frame, as shown in this text analysis example, and there is very limited support within tidymodels for starting with a sparse matrix, for example by using &lt;code>parsnip::fit_xy()&lt;/code>.&lt;/p>
&lt;p>There are currently three models in parsnip that support a sparse data encoding:&lt;/p>
&lt;ul>
&lt;li>the glmnet engine for linear and logistic regression (including multinomial regression),&lt;/li>
&lt;li>the XGBoost engine for boosted trees, and&lt;/li>
&lt;li>the ranger engine for random forests.&lt;/li>
&lt;/ul>
&lt;p>There is heterogeneity in how recipes themselves handle data internally; this is why we didn&amp;rsquo;t see a huge decrease in memory use when comparing &lt;code>wf_sparse&lt;/code> to &lt;code>wf_default&lt;/code>. The
&lt;a href="https://textrecipes.tidymodels.org/" target="_blank" rel="noopener">textrecipes&lt;/a> package internally adopts the idea of a
&lt;a href="https://textrecipes.tidymodels.org/reference/tokenlist.html" target="_blank" rel="noopener">tokenlist&lt;/a>, which is memory efficient for sparse data, but other recipe steps may handle data in a dense tibble structure. Keep these current limits in mind as you consider the memory requirements of your modeling projects!&lt;/p></description></item><item><title>tune 0.1.2</title><link>https://www.tidyverse.org/blog/2020/11/tune-0-1-2/</link><pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2020/11/tune-0-1-2/</guid><description>&lt;!--
TODO:
* [ ] Pick category and tags (see existing with `post_tags()`)
* [ ] Find photo &amp; update yaml metadata
* [ ] Create `thumbnail-sq.jpg`; height and width should be equal
* [ ] Create `thumbnail-wd.jpg`; width should be >5x height
* [ ] `hugodown::use_tidy_thumbnail()`
* [ ] Add intro sentence
* [ ] `use_tidy_thanks()`
-->
&lt;p>We&amp;rsquo;re pleased to announce the release of version 0.1.2 of the
&lt;a href="https://tune.tidymodels.org/" target="_blank" rel="noopener">tune&lt;/a> package. tune is a tidy interface for optimizing model tuning parameters.&lt;/p>
&lt;p>You can install it from CRAN with:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">install.packages&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;tune&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There is a lot to discuss! So much that this is the first of three blog posts. Here, we&amp;rsquo;ll show off most of the new features. The two other blog posts will talk about how to benefit from sparse matrices with tidymodels and improvements to parallel processing.&lt;/p>
&lt;h2 id="pick-a-class-level">Pick a class level
&lt;a href="#pick-a-class-level">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Deciding how to define the event of interest for two-class classification models is a major pain. Sometimes the second level of the factor is assumed to be the event of interest, but this is a vestigial notion almost entirely driven by how things were in The Old Days when outcome classes were encoded as zero and one. Thankfully, we&amp;rsquo;ve evolved significantly since those days. tidymodels assumes that the first factor level is the event as a default.&lt;/p>
&lt;p>However, we want to accommodate multiple preferences. Previously, there was a global option that you could set to decide whether the first or second factor level is the event. We have come to realize that this was not the best idea from a technical standpoint. The new approach uses control arguments to the tune functions to make this specification. For example, &lt;code>control_grid(event_level = &amp;quot;second&amp;quot;)&lt;/code> would change the default when using &lt;code>tune_grid()&lt;/code>.&lt;/p>
&lt;h2 id="adding-variables">Adding variables
&lt;a href="#adding-variables">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>There is a
&lt;a href="https://workflows.tidymodels.org/reference/add_variables.html" target="_blank" rel="noopener">new variable specification interface&lt;/a> in the workflows package called &lt;code>add_variables()&lt;/code>. This can be a good approach to use if you are not interested in using a recipe or formula to declare which columns are outcomes or predictors. You can now use this interface with the tune package.&lt;/p>
&lt;h2 id="gaussian-process-options">Gaussian process options
&lt;a href="#gaussian-process-options">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>For Bayesian optimization, you can now pass options to &lt;code>GPfit::GP_fit()&lt;/code> through &lt;code>tune_bayes()&lt;/code>. If you are a &amp;ldquo;Go Matérn covariance function or go home&amp;rdquo; person, this is a nice addition.&lt;/p>
&lt;h2 id="augmenting-tune-objects">Augmenting &lt;code>tune&lt;/code> objects
&lt;a href="#augmenting-tune-objects">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>There is now an
&lt;a href="https://broom.tidymodels.org/articles/broom.html" target="_blank" rel="noopener">&lt;code>augment()&lt;/code>&lt;/a> method for &lt;code>tune_*&lt;/code> objects. This method does not have a data argument and returns the &lt;em>out-of-sample&lt;/em> predictions for the object, different from other &lt;code>augment()&lt;/code> methods you may have used. For objects produced by &lt;code>last_fit()&lt;/code>, the function returns the test set results.&lt;/p>
&lt;h2 id="acknowledgements">Acknowledgements
&lt;a href="#acknowledgements">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Thanks to everyone who contributed code or filed issues since the last version:
&lt;a href="https://github.com/AndrewKostandy" target="_blank" rel="noopener">@AndrewKostandy&lt;/a>,
&lt;a href="https://github.com/bloomingfield" target="_blank" rel="noopener">@bloomingfield&lt;/a>,
&lt;a href="https://github.com/cespeleta" target="_blank" rel="noopener">@cespeleta&lt;/a>,
&lt;a href="https://github.com/cimentadaj" target="_blank" rel="noopener">@cimentadaj&lt;/a>,
&lt;a href="https://github.com/DavisVaughan" target="_blank" rel="noopener">@DavisVaughan&lt;/a>,
&lt;a href="https://github.com/dmalkr" target="_blank" rel="noopener">@dmalkr&lt;/a>,
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/hnagaty" target="_blank" rel="noopener">@hnagaty&lt;/a>,
&lt;a href="https://github.com/jcpsantiago" target="_blank" rel="noopener">@jcpsantiago&lt;/a>,
&lt;a href="https://github.com/juliasilge" target="_blank" rel="noopener">@juliasilge&lt;/a>,
&lt;a href="https://github.com/kbzsl" target="_blank" rel="noopener">@kbzsl&lt;/a>,
&lt;a href="https://github.com/kelseygonzalez" target="_blank" rel="noopener">@kelseygonzalez&lt;/a>,
&lt;a href="https://github.com/matthewrspiegel" target="_blank" rel="noopener">@matthewrspiegel&lt;/a>,
&lt;a href="https://github.com/mdneuzerling" target="_blank" rel="noopener">@mdneuzerling&lt;/a>,
&lt;a href="https://github.com/MxNl" target="_blank" rel="noopener">@MxNl&lt;/a>,
&lt;a href="https://github.com/SeeNewt" target="_blank" rel="noopener">@SeeNewt&lt;/a>,
&lt;a href="https://github.com/simonschoe" target="_blank" rel="noopener">@simonschoe&lt;/a>,
&lt;a href="https://github.com/Steviey" target="_blank" rel="noopener">@Steviey&lt;/a>,
&lt;a href="https://github.com/topepo" target="_blank" rel="noopener">@topepo&lt;/a>,
&lt;a href="https://github.com/trevorcampbell" target="_blank" rel="noopener">@trevorcampbell&lt;/a>, and
&lt;a href="https://github.com/UnclAlDeveloper" target="_blank" rel="noopener">@UnclAlDeveloper&lt;/a>&lt;/p></description></item><item><title>usemodels 0.0.1</title><link>https://www.tidyverse.org/blog/2020/09/usemodels-0-0-1/</link><pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2020/09/usemodels-0-0-1/</guid><description>&lt;p>We&amp;rsquo;re very excited to announce the first release of the
&lt;a href="https://usemodels.tidymodels.org/" target="_blank" rel="noopener">usemodels&lt;/a> package. The tidymodels packages are designed to provide modeling functions that are highly flexible and modular. This is powerful, but sometimes a template or skeleton showing how to start is helpful. The usemodels package creates templates for tidymodels analyses so you don&amp;rsquo;t have to write as much new code.&lt;/p>
&lt;p>You can install it from CRAN with:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">install.packages&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;usemodels&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This blog post will show how to use the package.&lt;/p>
&lt;p>Let&amp;rsquo;s start by creating a glmnet linear regression model for the &lt;code>mtcars&lt;/code> data using tidymodels. This model is usually tuned over the amount and type of regularization. In tidymodels, there are a few intermediate steps for a glmnet model:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Create a
&lt;a href="https://www.tmwr.org/models.html" target="_blank" rel="noopener">parsnip model object&lt;/a> and define the tuning parameters that we want to optimize.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>
&lt;a href="https://www.tmwr.org/recipes.html" target="_blank" rel="noopener">Create a recipe&lt;/a> that, at minimum, centers and scales the predictors. For some data sets, we also need to create dummy variables from any factor-encoded predictor columns.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Define a
&lt;a href="https://www.tmwr.org/resampling.html" target="_blank" rel="noopener">resampling scheme&lt;/a> for our data.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Choose a function from the
&lt;a href="https://tune.tidymodels.org/" target="_blank" rel="noopener">tune package&lt;/a>, such as &lt;code>tune_grid()&lt;/code>, to optimize the parameters. For grid search, we&amp;rsquo;ll also need a grid of candidate parameter values (or let the function choose one for us).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>We recognize that this might be more code than you would have had to write compared to a package like caret. However, the tidymodels ecosystem enables a wider variety of modeling techniques and is more versatile.&lt;/p>
&lt;p>The new usemodels package can automatically generate much of this code infrastructure. For example:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">usemodels&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">use_glmnet&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mpg&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">.,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mtcars&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>which produces the terminal output:&lt;/p>
&lt;pre>&lt;code>glmnet_recipe &amp;lt;-
recipe(formula = mpg ~ ., data = mtcars) %&amp;gt;%
step_zv(all_predictors()) %&amp;gt;%
step_normalize(all_predictors(), -all_nominal())
glmnet_spec &amp;lt;-
linear_reg(penalty = tune(), mixture = tune()) %&amp;gt;%
set_mode(&amp;quot;regression&amp;quot;) %&amp;gt;%
set_engine(&amp;quot;glmnet&amp;quot;)
glmnet_workflow &amp;lt;-
workflow() %&amp;gt;%
add_recipe(glmnet_recipe) %&amp;gt;%
add_model(glmnet_spec)
glmnet_grid &amp;lt;- tidyr::crossing(penalty = 10^seq(-6, -1, length.out = 20), mixture = c(0.05,
0.2, 0.4, 0.6, 0.8, 1))
glmnet_tune &amp;lt;-
tune_grid(glmnet_workflow, resamples = stop(&amp;quot;add your rsample object&amp;quot;), grid = glmnet_grid)
&lt;/code>&lt;/pre>&lt;p>This can be copied to the source window and edited. Some notes:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>For this model, it is possible to prescribe a default grid of candidate tuning parameter values that work well about 90% of the time. For other models, the grid might be data-driven. In these cases, the tune package functions can estimate an appropriate grid.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The extra recipes steps are the
&lt;a href="https://www.tmwr.org/pre-proc-table.html" target="_blank" rel="noopener">recommend preprocessing&lt;/a> for this model. Since this varies from model-to-model, the recipe template will contain the minimal required steps. Your data might require additional operations.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>One thing that &lt;em>should not be automated&lt;/em> is the choice of resampling method. The code templates require the user to choose the rsample function that is appropriate.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>In case you are unfamiliar with the model and its preprocessing needs, a &lt;code>verbose&lt;/code> option prints comments that explain &lt;em>why&lt;/em> some steps are included. For the glmnet model, the comments added to the recipe state:&lt;/p>
&lt;blockquote>
&lt;p>Regularization methods sum up functions of the model slope coefficients. Because of this, the predictor variables should be on the same scale. Before centering and scaling the numeric predictors, any predictors with a single unique value are filtered out.&lt;/p>
&lt;/blockquote>
&lt;p>Let&amp;rsquo;s look at another example. The &lt;code>ad_data&lt;/code> data set in the modeldata package has rows for 333 patients with a factor outcome for their level of cognitive impairment (e.g., Alzheimer&amp;rsquo;s disease). There is also a categorical predictor in the data, the Apolipoprotein E genotype, which has six levels. Let&amp;rsquo;s suppose the &lt;code>Genotype&lt;/code> column was encoded as character (instead of being a factor). This might be a problem if the resampling method samples out a level from the data used to fit the model.&lt;/p>
&lt;p>Let&amp;rsquo;s use a boosted tree model with the xgboost package and change the default prefix for the objects:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tidymodels&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">data&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ad_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">ad_data&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">Genotype&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">as.character&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ad_data&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">Genotype&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="o">&amp;gt;&lt;/span>
&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nf">use_xgboost&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Class&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">.,&lt;/span> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ad_data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">prefix&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;impairment&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>impairment_recipe &amp;lt;-
recipe(formula = Class ~ ., data = ad_data) %&amp;gt;%
step_string2factor(one_of(Genotype)) %&amp;gt;%
step_novel(all_nominal(), -all_outcomes()) %&amp;gt;%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %&amp;gt;%
step_zv(all_predictors())
impairment_spec &amp;lt;-
boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(),
loss_reduction = tune(), sample_size = tune()) %&amp;gt;%
set_mode(&amp;quot;classification&amp;quot;) %&amp;gt;%
set_engine(&amp;quot;xgboost&amp;quot;)
impairment_workflow &amp;lt;-
workflow() %&amp;gt;%
add_recipe(impairment_recipe) %&amp;gt;%
add_model(impairment_spec)
set.seed(64393)
impairment_tune &amp;lt;-
tune_grid(impairment_workflow, resamples = stop(&amp;quot;add your rsample object&amp;quot;),
grid = stop(&amp;quot;add number of candidate points&amp;quot;))
&lt;/code>&lt;/pre>&lt;p>Notice that the line&lt;/p>
&lt;pre>&lt;code>step_string2factor(one_of(Genotype))
&lt;/code>&lt;/pre>&lt;p>is included in the recipe along with a step to generate one-hot encoded dummy variables. xgboost is one of the few tree ensemble implementations that requires the user to create dummy variables. This step is only added to the template when it is required for that model.&lt;/p>
&lt;p>Also, for this particular model, we recommend using a
&lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C7&amp;amp;q=space&amp;#43;filling&amp;#43;design&amp;#43;of&amp;#43;experiments" target="_blank" rel="noopener">space-filling design&lt;/a> for the grid, but the user must choose the number of grid points.&lt;/p>
&lt;p>The current set of templates included in the inaugural version of the package are:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">ls&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;package:usemodels&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pattern&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;^use_&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## [1] &amp;quot;use_earth&amp;quot; &amp;quot;use_glmnet&amp;quot; &amp;quot;use_kknn&amp;quot; &amp;quot;use_ranger&amp;quot; &amp;quot;use_xgboost&amp;quot;
&lt;/code>&lt;/pre>&lt;p>We&amp;rsquo;ll likely add more but please file
&lt;a href="https://github.com/tidymodels/usemodels/issues" target="_blank" rel="noopener">an issue&lt;/a> if there are any that you see as a priority.&lt;/p></description></item><item><title>tune 0.1.1</title><link>https://www.tidyverse.org/blog/2020/07/tune-0-1-1/</link><pubDate>Mon, 13 Jul 2020 00:00:00 +0000</pubDate><guid>https://www.tidyverse.org/blog/2020/07/tune-0-1-1/</guid><description>&lt;p>We&amp;rsquo;re pleased to announce the release of
&lt;a href="https://tune.tidymodels.org/" target="_blank" rel="noopener">tune&lt;/a> 0.1.1. tune is a tidy interface for optimizing model tuning parameters.&lt;/p>
&lt;p>You can install it from CRAN with:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">install.packages&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;tune&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can see a full list of changes in the
&lt;a href="https://tune.tidymodels.org/news/index.html" target="_blank" rel="noopener">release notes&lt;/a>. The release was originally motivated by
&lt;a href="https://www.tidyverse.org/tags/dplyr-1-0-0" target="_blank" rel="noopener">dplyr 1.0.0 changes&lt;/a> although there are a lot of nice, new features to talk about.&lt;/p>
&lt;h2 id="better-autoplot">Better &lt;code>autoplot()&lt;/code>
&lt;a href="#better-autoplot">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>The previous plot method produces what we refer to as a &lt;em>marginal plot&lt;/em>; each predictor was plotted against performance. That is probably the best that we can do for non-regular grids (which tends to be the default in tune). Here&amp;rsquo;s an example using the
&lt;a href="https://bookdown.org/max/FES/chicago-intro.html" target="_blank" rel="noopener">Chicago train data&lt;/a>:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">library&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tidymodels&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nf">data&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Chicago&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">package&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;modeldata&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Time-series resampling&lt;/span>
&lt;span class="nf">set.seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">7898&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">data_folds&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">rolling_origin&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">Chicago&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">initial&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">364&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="m">15&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">assess&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">7&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="m">4&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">skip&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">7&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="m">4&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">cumulative&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">FALSE&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="n">svm_mod&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">svm_rbf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cost&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">tune&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">rbf_sigma&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">tune&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;kernel parameter&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">set_mode&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;regression&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">set_engine&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;kernlab&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">ctrl&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">control_grid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">save_pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">TRUE&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nf">set.seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">2893&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">non_regular_grid&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="n">svm_mod&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">tune_grid&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">ridership&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">Harlem&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">Archer_35th&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">resamples&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data_folds&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">grid&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">36&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">control&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ctrl&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">autoplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">non_regular_grid&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;rmse&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">ggtitle&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;old method, irregular grid&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/irreg-plot-old-1.svg" title="plot of chunk irreg-plot-old" alt="plot of chunk irreg-plot-old" style="display: block; margin: auto;" />&lt;/p>
&lt;p>Not bad but it could be improved in a few ways:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Both tuning parameters are generated on log scales. The data are shown above in the natural units and the data at the low end of the scale gets smashed together.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We could show its parameter label (e.g. &amp;ldquo;Radial Basis Function sigma&amp;rdquo;) when no parameter ID is given.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>What happens when a regular (i.e. factorial) grid is used?&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">grid&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="n">svm_mod&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">parameters&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">grid_regular&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">levels&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">c&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="m">12&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="n">grid&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 36 x 2
## cost `kernel parameter`
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 0.000977 0.0000000001
## 2 0.177 0.0000000001
## 3 32 0.0000000001
## 4 0.000977 0.000000000811
## 5 0.177 0.000000000811
## 6 32 0.000000000811
## 7 0.000977 0.00000000658
## 8 0.177 0.00000000658
## 9 32 0.00000000658
## 10 0.000977 0.0000000534
## # … with 26 more rows
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">set.seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">2893&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">regular_grid&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="n">svm_mod&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">tune_grid&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">ridership&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">Harlem&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">Archer_35th&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">resamples&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data_folds&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">grid&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">grid&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">control&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ctrl&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">autoplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">regular_grid&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;rmse&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">ggtitle&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;old method, regular grid&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/reg-plot-old-1.svg" title="plot of chunk reg-plot-old" alt="plot of chunk reg-plot-old" style="display: block; margin: auto;" />&lt;/p>
&lt;p>This visualization also could be improved, since there might be a pattern in one parameter for each value of the other.&lt;/p>
&lt;p>The new version of tune creates improved versions of both of these plots:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">autoplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">non_regular_grid&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;rmse&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">ggtitle&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;new method, irregular grid&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/ap-irr-new-1.svg" title="plot of chunk ap-irr-new" alt="plot of chunk ap-irr-new" style="display: block; margin: auto;" />&lt;/p>
&lt;p>This tells a completely different story than the previous version where the parameters were in their natural units.&lt;/p>
&lt;p>The regular grid results are also much better and tell a cleaner story:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">autoplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">regular_grid&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;rmse&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">ggtitle&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;new method, regular grid&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/ap-reg-new-1.svg" title="plot of chunk ap-reg-new" alt="plot of chunk ap-reg-new" style="display: block; margin: auto;" />&lt;/p>
&lt;p>Extra arguments can be passed when a numeric grouping column is used;l these are given to &lt;code>format()&lt;/code>. To avoid scientific notation:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">autoplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">regular_grid&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;rmse&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">digits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">scientific&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">FALSE&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">ggtitle&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;Formatting for coloring column&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/ap-reg-new-new-1.svg" title="plot of chunk ap-reg-new-new" alt="plot of chunk ap-reg-new-new" style="display: block; margin: auto;" />&lt;/p>
&lt;h2 id="a-ggplot2-coord-for-plotting-observed-and-predicted-values">A ggplot2 &lt;code>coord&lt;/code> for plotting observed and predicted values
&lt;a href="#a-ggplot2-coord-for-plotting-observed-and-predicted-values">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>One helpful visualization of the fit of a regression model is to plot the true outcome value against the predictions. These &lt;em>should&lt;/em> be on the same scale. Let&amp;rsquo;s look at such a plot:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">best_values&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">select_best&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">regular_grid&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;rmse&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">best_values&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 1 x 3
## cost `kernel parameter` .config
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;
## 1 32 0.0152 Model30
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">holdout_predictions&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="n">regular_grid&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">collect_predictions&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">parameters&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">best_values&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">holdout_predictions&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 224 x 7
## id .pred .row cost `kernel parameter` ridership .config
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;
## 1 Slice1 17.8 5461 32 0.0152 19.6 Model30
## 2 Slice1 18.9 5462 32 0.0152 20.0 Model30
## 3 Slice1 17.5 5463 32 0.0152 20.4 Model30
## 4 Slice1 8.88 5464 32 0.0152 20.4 Model30
## 5 Slice1 3.03 5465 32 0.0152 20.1 Model30
## 6 Slice1 6.07 5466 32 0.0152 4.78 Model30
## 7 Slice1 4.48 5467 32 0.0152 3.26 Model30
## 8 Slice1 12.6 5468 32 0.0152 19.3 Model30
## 9 Slice1 15.6 5469 32 0.0152 19.3 Model30
## 10 Slice1 15.4 5470 32 0.0152 19.9 Model30
## # … with 214 more rows
&lt;/code>&lt;/pre>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">ggplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">holdout_predictions&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nf">aes&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ridership&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">.pred&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">geom_abline&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">lty&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">geom_point&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">alpha&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">0.3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/obs-pred-old-1.svg" title="plot of chunk obs-pred-old" alt="plot of chunk obs-pred-old" style="display: block; margin: auto;" />&lt;/p>
&lt;p>This is very helpful but there are a few possible improvements. The new version of tune has &lt;code>coord_obs_pred()&lt;/code> that produces a square plot with the same axes:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">ggplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">holdout_predictions&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nf">aes&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ridership&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">.pred&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">geom_abline&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">lty&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">geom_point&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">alpha&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">0.3&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">coord_obs_pred&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/obs-pred-new-1.svg" title="plot of chunk obs-pred-new" alt="plot of chunk obs-pred-new" style="display: block; margin: auto;" />&lt;/p>
&lt;h2 id="tuning-engine-parameters">Tuning engine parameters
&lt;a href="#tuning-engine-parameters">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>
&lt;a href="https://github.com/brunaw" target="_blank" rel="noopener">Bruna Wundervald&lt;/a> (from Maynooth University) gave a
&lt;a href="https://brunaw.com/slides/rladies-helsinki/talk.html#1" target="_blank" rel="noopener">great presentation&lt;/a> that used tidymodels packages. She ran into the problem that, if you wanted to tune parameters that were specific to the engine, you&amp;rsquo;d have to go through a lot of trouble to do so. This used to work well in a previous version of tune. Unfortunately, we accidentally broke it, but now you can once again tune engine specific parameters. One feature in this version of tune, along with the new 0.0.8 version of the dials package, is that we have added dials &lt;code>parameter&lt;/code> objects for every parameter that users might tuned with the existing engines that we support (this was not as difficult as it sounds).&lt;/p>
&lt;p>To demonstrate, we&amp;rsquo;ll use the time series data above, but this time we&amp;rsquo;ll optimize the ranger parameters that Bruna was interested in.&lt;/p>
&lt;p>Since parsnip has a pre-defined list of models and engines, we&amp;rsquo;ve gone ahead and set up the infrastructure for tuning most engine-specific values. For example, in the above example we could tune two regularization parameters specific to ranger.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">rf_mod&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="nf">rand_forest&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">min_n&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">tune&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">set_mode&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;regression&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">set_engine&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;ranger&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">regularization.factor&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">tune&lt;/span>&lt;span class="p">(),&lt;/span>
&lt;span class="n">regularization.usedepth&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">tune&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="c1"># Are there dials objects to work with these? &lt;/span>
&lt;span class="n">rf_param&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span> &lt;span class="nf">parameters&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">rf_mod&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">rf_param&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## Collection of 3 parameters for tuning
##
## id parameter type object class
## min_n min_n nparam[+]
## regularization.factor regularization.factor nparam[+]
## regularization.usedepth regularization.usedepth dparam[+]
&lt;/code>&lt;/pre>&lt;p>There are parameter objects for these (and they keep their original names). You can adjust the ranges and values for these parameters using the &lt;code>update()&lt;/code> function as you would for others. To see their underlying functions:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">rf_param&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="n">object[[2]]&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## Gain Penalization (quantitative)
## Range: [0, 1]
&lt;/code>&lt;/pre>&lt;p>From here, the standard tools in the tune package can be used. You can use one of the &lt;code>grid_*()&lt;/code> functions to create a grid of values, let &lt;code>tune_grid()&lt;/code> create a set for you, or use Bayesian optimization to find appropriate values sequentially.&lt;/p>
&lt;p>The new &lt;code>autoplot()&lt;/code> method can also be used to produce nice visualizations of the relationship between performance and the parameters.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="nf">set.seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="m">4976&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">ranger_params&lt;/span> &lt;span class="o">&amp;lt;-&lt;/span>
&lt;span class="n">rf_mod&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">tune_grid&lt;/span>&lt;span class="p">(&lt;/span>
&lt;span class="n">ridership&lt;/span> &lt;span class="o">~&lt;/span> &lt;span class="n">Harlem&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">Archer_35th&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">resamples&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data_folds&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">grid&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="m">10&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="n">control&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ctrl&lt;/span>
&lt;span class="p">)&lt;/span>
&lt;span class="nf">autoplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ranger_params&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;rmse&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span>
&lt;span class="nf">theme&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">legend.position&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s">&amp;#34;top&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="figure/rf-tune-1.svg" title="plot of chunk rf-tune" alt="plot of chunk rf-tune" style="display: block; margin: auto;" />&lt;/p>
&lt;p>Note that the tuning parameter labels (i.e. &amp;ldquo;Gain Penalization&amp;rdquo; instead of &amp;ldquo;&lt;code>regularization.factor&lt;/code>&amp;rdquo;) are used.&lt;/p>
&lt;p>I&amp;rsquo;m sure that we missed someone&amp;rsquo;s favorite engine-specific parameter so please put in a
&lt;a href="https://github.com/tidymodels/dials/issues" target="_blank" rel="noopener">GitHub issue for dials&lt;/a> to let us know.&lt;/p>
&lt;h2 id="config-columns">&lt;code>.config&lt;/code> columns
&lt;a href="#config-columns">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>When model tuning is conducted, the tune package now saves a new column in the output called &lt;code>.config&lt;/code>. This column is a qualitative identification column for unique tuning parameter combinations. It often reflects what is being tuned. A value of &lt;code>.config = &amp;quot;Recipe1_Model3&amp;quot;&lt;/code> indicates that the first recipe tuning parameter set is being evaluated in conjunction with the third set of model parameters. Here&amp;rsquo;s an example from the random forest model that we just fit:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-r" data-lang="r">&lt;span class="n">ranger_params&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">collect_metrics&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="c1"># get the unique tuning parameter combinations:&lt;/span>
&lt;span class="nf">select&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">min_n&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">regularization.factor&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">regularization.usedepth&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">.config&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&amp;gt;%&lt;/span>
&lt;span class="nf">distinct&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>## # A tibble: 10 x 4
## min_n regularization.factor regularization.usedepth .config
## &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt;
## 1 7 0.288 TRUE Model01
## 2 20 0.322 FALSE Model02
## 3 25 0.703 FALSE Model03
## 4 14 0.0781 FALSE Model04
## 5 36 0.882 TRUE Model05
## 6 29 0.192 FALSE Model06
## 7 35 0.404 TRUE Model07
## 8 24 0.687 TRUE Model08
## 9 3 0.580 FALSE Model09
## 10 10 0.968 TRUE Model10
&lt;/code>&lt;/pre>
&lt;h2 id="other-changes">Other changes
&lt;a href="#other-changes">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>&lt;code>conf_mat_resampled()&lt;/code> is a new function that computes the average confusion matrix across resampling statistics for a single model.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>show_best()&lt;/code> and the &lt;code>select_*()&lt;/code> functions will now use the first metric in the metric set if no metric is supplied.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>filter_parameters()&lt;/code> can trim the &lt;code>.metrics&lt;/code> column of unwanted results (as well as columns &lt;code>.predictions&lt;/code> and &lt;code>.extracts&lt;/code>) from &lt;code>tune_*&lt;/code> objects.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If a grid is given, parameters do not need to be finalized to be used in the &lt;code>tune_*()&lt;/code> functions.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="acknowledgements">Acknowledgements
&lt;a href="#acknowledgements">
&lt;svg class="anchor-symbol" aria-hidden="true" height="26" width="26" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg">
&lt;path d="M0 0h24v24H0z" fill="currentColor">&lt;/path>
&lt;path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z">&lt;/path>
&lt;/svg>
&lt;/a>
&lt;/h2>&lt;p>Thanks to everyone who contributed code or filed issues since the last version:
&lt;a href="https://github.com/cimentadaj" target="_blank" rel="noopener">@cimentadaj&lt;/a>,
&lt;a href="https://github.com/connor-french" target="_blank" rel="noopener">@connor-french&lt;/a>,
&lt;a href="https://github.com/cwchang-nelson" target="_blank" rel="noopener">@cwchang-nelson&lt;/a>,
&lt;a href="https://github.com/DavisVaughan" target="_blank" rel="noopener">@DavisVaughan&lt;/a>,
&lt;a href="https://github.com/dcossyleon" target="_blank" rel="noopener">@dcossyleon&lt;/a>,
&lt;a href="https://github.com/EmilHvitfeldt" target="_blank" rel="noopener">@EmilHvitfeldt&lt;/a>,
&lt;a href="https://github.com/jg43b" target="_blank" rel="noopener">@jg43b&lt;/a>,
&lt;a href="https://github.com/JHucker" target="_blank" rel="noopener">@JHucker&lt;/a>,
&lt;a href="https://github.com/juliasilge" target="_blank" rel="noopener">@juliasilge&lt;/a>,
&lt;a href="https://github.com/karaesmen" target="_blank" rel="noopener">@karaesmen&lt;/a>,
&lt;a href="https://github.com/kbzsl" target="_blank" rel="noopener">@kbzsl&lt;/a>,
&lt;a href="https://github.com/kylegilde" target="_blank" rel="noopener">@kylegilde&lt;/a>,
&lt;a href="https://github.com/LucyMcGowan" target="_blank" rel="noopener">@LucyMcGowan&lt;/a>,
&lt;a href="https://github.com/mdancho84" target="_blank" rel="noopener">@mdancho84&lt;/a>,
&lt;a href="https://github.com/py9mrg" target="_blank" rel="noopener">@py9mrg&lt;/a>,
&lt;a href="https://github.com/realauggieheschmeyer" target="_blank" rel="noopener">@realauggieheschmeyer&lt;/a>,
&lt;a href="https://github.com/robyjos" target="_blank" rel="noopener">@robyjos&lt;/a>,
&lt;a href="https://github.com/rorynolan" target="_blank" rel="noopener">@rorynolan&lt;/a>,
&lt;a href="https://github.com/simonpcouch" target="_blank" rel="noopener">@simonpcouch&lt;/a>,
&lt;a href="https://github.com/ThomasWolf0701" target="_blank" rel="noopener">@ThomasWolf0701&lt;/a>, and
&lt;a href="https://github.com/UnclAlDeveloper" target="_blank" rel="noopener">@UnclAlDeveloper&lt;/a>.&lt;/p></description></item></channel></rss>